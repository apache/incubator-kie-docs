[id='dm-openshift-overview-con']
= Overview

If you have an OpenShift environment, you can deploy {PRODUCT} into this environment instead of a regular on-premises deployment. 

In this solution, {KIE_SERVER} is deployed as an OpenShift pod. You can scale the pod up and down, providing as few or as many containers as necessary. You can use all standard OpenShift methods to manage the pod, balance the load, and deploy new versions.

You can also deploy {CENTRAL} on the OpenShift infrastructure together with {KIE_SERVER}. In this case, you can use {CENTRAL} to manage the {KIE_SERVER} and to develop new rules.

Alternatively, you can deploy {KIE_SERVER} without {CENTRAL}. To manage {KIE_SERVER} in this case, you have two options:

* Use the _source to image_ (S2I) template and provide a Git repository with the source of your decision service. OpenShift automatically builds the source, installs the decision service into the {KIE_SERVER} image, and starts the service. No further management of the image is required. If you want to use a new version of the decision service, you can build a new image. This option is often preferable for typical version management approaches (DevOps) in a containerized infrastructure.

* Use an instance of {CENTRAL} installed on-premises (without OpenShift) or a stand-alone management console installed on-premises to manage the {KIE_SERVER} that is deployed in OpenShift.

IMPORTANT: All calls to the {KIE_SERVER} that runs on OpenShift must be stateless. While the server accepts stateful calls, the state might not be saved between calls, because the server can be scaled to multiple containers or might be restarted by OpenShift automatically.
