[id='test-scenarios-create-proc']
= Creating and running a test scenario

You can create test scenarios in {CENTRAL} to test the functionality of business rule data before deployment. A basic test scenario must have at least the following data:

* Related data objects
* *GIVEN* facts
* *EXPECT* results

With this data, the test scenario can validate the expected and actual results for that rule instance based on the defined facts.

.Procedure
. Go to *Menu* -> *Design* -> *Projects* and click the project name.
. Click *Create New Asset* -> *Test Scenario*.
. Enter an informative *Test Scenario* name and select the appropriate *Package*. The package that you specify must be the same package where the required data objects and rule assets have been assigned or will be assigned.
+
. Click *Ok* to create the test scenario.
+
The new test scenario is now listed in the *Test Scenarios* panel of the *Project Explorer*,
+
. Click the *Data Objects* tab to verify that all data objects needed for the rules that you want to test are listed. If not, click *New item* to import the needed data objects from other packages, or
ifeval::["{context}" == "test-scenarios"]
xref:data-objects-create-proc_test-scenarios[create data objects]
endif::[]
ifeval::["{context}" == "chap-test-scenarios"]
xref:data-objects-create-proc_chap-data-models[create data objects]
endif::[]
within your package.
. After all data objects are in place, return to the *Editor* tab of the test scenarios designer and define the *GIVEN* and *EXPECT* data for the scenario, based on the available data objects.
+
.The test scenarios designer
image::test-scenario-edit.png[]
+
The *GIVEN* section defines the input facts for the test. For example, if an "Underage" rule in the project declines loan applications for applicants under the age of 21, then the *GIVEN* facts in the test scenario could be `Applicant` with `age` set to some integer less than 21.
+
The *EXPECT* section defines the expected results based on the *GIVEN* input facts. That is, *GIVEN* the input facts, *EXPECT* these other facts to be valid or entire rules to be activated. For example, with the given facts of an applicant under the age of 21 in the scenario, the *EXPECT* results could be `LoanApplication` with `approved` set to `false` (as a result of the underage applicant), or could be the activation of the "Underage" rule as a whole.
+
. Optionally, add a *CALL METHOD* and any *globals* to the test scenario:
+
--
* *CALL METHOD:* Use this to invoke a method from another fact when the rule execution is initiated. Click *CALL METHOD*, select a fact, and click image:6187.png[] to select the method to invoke.
* *globals:* Use this to add any global variables in the project to the test scenario. Click *globals* to select the variable to be validated, and then in the test scenarios designer, click the global name and define field values to be applied to the global variable. If no global variables are available, then they need to be created as new assets in {CENTRAL}. Global variables are named objects that are visible to the rule engine but are different from the objects for facts. Changes in the object of a global do not trigger the re-evaluation of rules.
--
+
*<@Toni (1 of 3): Am I even close on my descriptions of call method and globals above? I'm still not clear myself on what exactly a call method does and what globals do. Any thoughts?>*
+
. Click *More* at the bottom of the test scenarios designer to add other data blocks to the same scenario file as needed.
. After you have defined the *GIVEN* input and *EXPECT* results for the scenario, click *Run scenario* in the upper-right corner to run the test, or click *Run all scenarios* to run all `.scenario` files in the project package at once (if there are multiple).
+
*<@Toni (2 of 3): Is the above correct about "Run all scenarios"? Seems to be the case when I test it, but the problem is that I intentionally made a bogus test that fails when run individually but all scenarios pass when I run all. That is, I have 5 good scenarios and 1 bad one, but when I run all, it says all 6 scenarios pass. Do you think it's a bug or am I missing something?>*
+
If the test fails, address any problems described in the *Reporting* message at the bottom of the window, review all components in the scenario, and try again to validate the scenario until the scenario passes.
+
. Click *Save* in the test scenarios designer to save your work.

For more details about adding GIVEN facts to test scenarios, see xref:test-scenarios-GIVEN-proc[].

For more details about adding EXPECT results to test scenarios, see xref:test-scenarios-EXPECT-proc[].
