[id='test_scenarios_create_proc']
= Creating and Running a Test Scenario

A basic test scenario requires, at minimum, the following data:

* Related data objects
* *GIVEN* facts
* *EXPECT* facts

With this data, the test scenario can compare given facts with expected results, according to the related data objects, and validate the configured rules.

For information on adding more advanced test scenario settings, see <<test_scenarios_advanced_con>>.

.Procedure
. In {CENTRAL}, go to *Authoring* -> *Project Authoring* and click the project name.
. Click *Create New Asset* -> *Test Scenario*.
. Enter the test scenario name, select the package, and click *OK*.
+
The Test Scenario editor appears.
+
.Test Scenario Editor
image::test-scenario-edit.png[]

. Click the *Data Objects* tab to verify that all data objects needed for the rules you want to test are listed. If not, click *New item* to import the needed data objects from other packages.
+
Data objects from the same package are available by default, but data objects in other packages must be imported.
+
For example, consider the package structure `org.company.project` with these data objects:
+
--
* `Fact1` in package `org.company`
* `Fact2` in package `org.company.project`
--
If you create your test scenario in `org.company`, then `Fact1` is available but you must import `Fact2`.
+
. After confirming or importing the data objects, return to the *Editor* tab and define the *GIVEN* and *EXPECT* data by clicking image:5686.png[] next to each label. Click *Save* in the editor after you make any changes.
+
The *GIVEN* section defines the input facts for the test. You can select a particular data object from the model and give it a variable name, called *Fact Name* in the window, or choose to activate a rule flow group instead. Activating a rule flow group allows rules from the specified rule flow group to be tested by activating the group in advance.
+
.Define GIVEN
image::test-scenario-facts.png[]
+
NOTE: For information about adding advanced values to *GIVEN* fields, see <<test_scenarios_advanced_proc>>.

+
The *EXPECT* section defines the expected results based on the *GIVEN* input facts. That is, *GIVEN* the input parameters, *EXPECT* these rules to be activated or fired. You can also *EXPECT* facts to be present and to have specific field values, or *EXPECT* rules not to fire at all.
+
.Define EXPECT
image::test-scenario-expected-rules.png[]
+
You can provide one of three expectations, depending on the data in the *GIVEN* section:
+
--
* *Rule:* Enables you to check for firing of a particular rule. Either type the name of a rule that is expected to be fired or select it from the list of rules. Click *OK*.
* *Fact value:* Enables you to check a specific object instance and its values. In the following example, given a `Customer` object with the `hasInternetService` boolean set to `true`, we expect the same object to have the `hasPhoneService` boolean set to `true`:
--
+
image::factvalues.png[]
+
--
* *Any fact that matches:* Enables you to check any objects in the working memory and the values of their field. In the following example, given a `Customer` object which has Internet service, a new object `RecurringPayment` is expected to be inserted into the working memory with the `amount` field set to `5`:
--
+
image::amount-field.png[]

. After you have defined the *GIVEN* input and *EXPECT* results and saved all changes, click *Run scenario* in the upper-right corner to execute your test. If you created more tests in one file, click *Run all scenarios* run all the tests in a sequence.
+
The test results are displayed in the *Reporting* panel at the bottom of the screen.
+
.Test Scenario Report
image::test-scenario-reporting.png[]

. Open the *Audit log* to view test scenario details.
+
.Test Scenario Audit Log
image::auditlog.png[]

.Multiple Test Scenarios in One File
[NOTE]
====
When you create more tests in one file, be sure to delete facts inserted by previous tests. When you insert a new *GIVEN* fact, notice the following fields:

* *Modify an existing fact* enables you to edit a fact between knowledge base executions.
* *Delete an existing fact* enables you to remove facts between executions.
+
.Modifying and Deleting Existing Facts
image::modify-facts.png[Modify and Delete and existing fact options for JBoss BRMS Test Scenarios]
====


*Use this or lose it.*

After you run all test scenarios, the status of the scenarios is reported in a *Messages* panel of the test scenarios designer to help you address any reported problems.

.Speed test scenario screen
image::speed-test-scenario.png[Speed test Scenario screen]
