[id="chap-kogito-developing-process-services"]
= Developing process services with {PRODUCT}
ifdef::context[:parent-context: {context}]
:context: kogito-developing-process-services

// Purpose statement for the assembly
[role="_abstract"]
As a developer of business processes, you can use {PRODUCT} business automation to develop process services using Business Process Model and Notation (BPMN) 2.0 models. BPMN process models are graphical representations of the steps required to achieve a business goal. You can design your BPMN processes with the {PRODUCT} BPMN modeler in VSCode or import existing BPMN processes into your {PRODUCT} projects for deployment and execution.

For more information about BPMN, see the Object Management Group (OMG) https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification].

// Modules - concepts, procedures, refs, etc.
include::../creating-running/chap-kogito-creating-running.adoc[tags=ref-kogito-app-examples]

[id="con-bpmn_{context}"]
== Business Process Model and Notation (BPMN) 2.0

[role="_abstract"]
Business Process Model and Notation (BPMN) 2.0 is a standard established by the Object Management Group (OMG) for describing and modeling business processes. BPMN defines an XML schema that enables BPMN models to be shared between BPMN-compliant platforms and across organizations so that business analysts and business process developers can collaborate in designing and implementing BPMN process services. The BPMN standard is similar to and can be used together with the Decision Model and Notation (DMN) standard for designing and modeling business decisions.

For more information about BPMN, see the Object Management Group (OMG) https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification].

[id="ref-bpmn-model-example_{context}"]
=== BPMN model example

[role="_abstract"]
A typical BPMN business process consists of the following basic components:

* Start events to initiate the process
* Tasks or other steps that are completed as part of the process
* Connectors to link the process nodes and create a sequence flow
* End events to terminate the process

The following example is a real-world BPMN model scenario that demonstrates how you can use process modeling to reach a business goal based on business decisions, tasks, or other services. In this scenario, an order service uses business processes for ordering items, for verifying the order, and for evaluating customer age.

NOTE: This example is based on the `process-quarkus-example` application in the https://github.com/apache/incubator-kie-kogito-examples[`kogito-examples`] repository in GitHub. However, this example may differ from the exact example source code as {PRODUCT} continues to be developed. Be sure to explore this and other {PRODUCT} examples in GitHub to help you develop your own applications.

The `orders.bpmn2` process in the example describes the steps that need to be followed when ordering items. The process includes a script task for writing debug information and a call activity for invoking a subprocess, using a custom `Order` data object.

.Example `orders.bpmn2` process
image::kogito/bpmn/bpmn-model-example-orders.png[Image of `orders.bpmn` example process]

The `Add items` subprocess invokes the following `orderItems.bpmn2` process, which uses a `CalculationService.calculateTotal` custom Java service and a user task to verify the order.

.Example `orderItems.bpmn2` process invoked as a subprocess
image::kogito/bpmn/bpmn-model-example-order-items.png[Image of `orderItems.bpmn` example process]

The `persons.bpmn2` process invokes a Decision Model and Notation (DMN) model in a business rule task to determine customer age, followed by a user task for special handling requirements for children, if applicable.

.Example `persons.bpmn2` process invoked as a subprocess
image::kogito/creating-running/kogito-bpmn-example-person.png[Image of `persons.bpmn` example process]

Based on these processes and on application configurations, {PRODUCT} generates a set of REST operations to create new orders, to list and delete active orders, and to determine the age of a specified person.

For example, the following REST operations use the endpoint `/orders` to interact with customer orders. You can use a REST client, curl utility, or the Swagger UI configured for the application (such as \http://localhost:8080/q/swagger-ui or \http://localhost:8080/swagger-ui.html) to send API requests to interact with the running application.

.Swagger UI to interact with all application endpoints (such as \http://localhost:8080/q/swagger-ui or \http://localhost:8080/swagger-ui.html)
image::kogito/creating-running/kogito-swagger-example-jbpm.png[Image of Swagger UI for example application]

NOTE: For the predefined {PRODUCT} example applications, the Swagger UI for interacting with service endpoints is available only on Quarkus examples that you run in
development mode or in native mode.

.Example POST request body to create an order (JSON)
[source,json]
----
{
  "approver": "john",
  "order": {
    "orderNumber": "12345",
    "shipped": false
  }
}
----

.Example curl command to create an order
[source]
----
curl -X POST http://localhost:8080/orders -H 'content-type: application/json' -H 'accept: application/json' -d '{"approver" : "john", "order" : {"orderNumber" : "12345", "shipped" : false}}'
----

The returned order displays an `"id"` field with a generated UUID that you can use to retrieve details about this specific order, if needed.

.Example curl command to view active orders
[source]
----
curl -X GET http://localhost:8080/orders -H 'content-type: application/json' -H 'accept: application/json'
----

.Example curl command to view order details by returned UUID
[source]
----
curl -X GET http://localhost:8080/orders/6b53c227-6d5e-40b7-8c8c-a541a2a47d58 -H 'content-type: application/json' -H 'accept: application/json'
----

You use the `"id"` value for the order that was returned when you created the order or when you retrieved active orders.

.Example curl command to cancel the order by returned UUID
[source]
----
curl -X DELETE http://localhost:8080/orders/6b53c227-6d5e-40b7-8c8c-a541a2a47d58 -H 'content-type: application/json' -H 'accept: application/json'
----

The following is the BPMN source file for the `orders.bpmn2` process model, as an example:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<!-- origin at X=0.0 Y=0.0 -->
<bpmn2:definitions xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:bpmn2="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:bpmn20="http://www.omg.org/bpmn20" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:bpsim="http://www.bpsim.org/schemas/1.0" xmlns:dc="http://www.omg.org/spec/DD/20100524/DC" xmlns:di="http://www.omg.org/spec/DD/20100524/DI" xmlns:drools="http://www.jboss.org/drools" xmlns="http://www.jboss.org/drools" xmlns:ns="http://www.w3.org/2001/XMLSchema" xsi:schemaLocation="http://www.omg.org/spec/BPMN/20100524/MODEL BPMN20.xsd http://www.jboss.org/drools drools.xsd http://www.bpsim.org/schemas/1.0 bpsim.xsd" id="_gfw8oEcJEemyodG9iPy-Bw" exporter="org.eclipse.bpmn2.modeler.core" exporterVersion="1.5.0.Final-v20180515-1642-B1" targetNamespace="http://www.omg.org/bpmn20">
  <bpmn2:itemDefinition id="_OrderItem" isCollection="false" structureRef="org.kie.kogito.examples.demo.Order"/>
  <bpmn2:itemDefinition id="_approverItem" isCollection="false" structureRef="String"/>
  <bpmn2:itemDefinition id="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputXItem" isCollection="false" structureRef="org.kie.kogito.examples.demo.Order"/>
  <bpmn2:itemDefinition id="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputXItem" isCollection="false" structureRef="org.kie.kogito.examples.demo.Order"/>
  <bpmn2:process id="demo.Orders" drools:packageName="org.kie.kogito.examples" drools:version="1.0" drools:adHoc="false" name="Orders" isExecutable="true">
    <bpmn2:documentation id="_gfw8oUcJEemyodG9iPy-Bw"><![CDATA[Deals with orders created by customer]]></bpmn2:documentation>
    <bpmn2:property id="order" itemSubjectRef="_OrderItem" name="order"/>
    <bpmn2:property id="approver" itemSubjectRef="_approverItem" name="approver"/>
    <bpmn2:sequenceFlow id="_8216C810-34D8-4BFA-B814-1AA01907810F" sourceRef="_9484CB12-FE52-434C-AE9F-3C3C267D1C96" targetRef="_2D876EF2-93F4-4CBE-959A-04EF7BFA9CED"/>
    <bpmn2:sequenceFlow id="_58684613-0155-48B2-8746-7675AFF24439" sourceRef="_0617D7DF-047A-4EC4-85E7-E201D640F4F5" targetRef="_9484CB12-FE52-434C-AE9F-3C3C267D1C96">
      <bpmn2:extensionElements>
        <drools:metaData name="isAutoConnection.target">
          <drools:metaValue><![CDATA[true]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
    </bpmn2:sequenceFlow>
    <bpmn2:sequenceFlow id="_B7B4282B-F317-4BF9-95E9-962B046EE815" sourceRef="_B44545AB-8B78-4FE4-B6B9-1D467954C070" targetRef="_0617D7DF-047A-4EC4-85E7-E201D640F4F5"/>
    <bpmn2:scriptTask id="_0617D7DF-047A-4EC4-85E7-E201D640F4F5" name="Dump order" scriptFormat="http://www.java.com/java">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[Dump order]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:incoming>_B7B4282B-F317-4BF9-95E9-962B046EE815</bpmn2:incoming>
      <bpmn2:outgoing>_58684613-0155-48B2-8746-7675AFF24439</bpmn2:outgoing>
      <bpmn2:script>System.out.println(&quot;Order has been created &quot; + order + &quot; with assigned approver &quot; + approver.toUpperCase());</bpmn2:script>
    </bpmn2:scriptTask>
    <bpmn2:endEvent id="_2D876EF2-93F4-4CBE-959A-04EF7BFA9CED">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:incoming>_8216C810-34D8-4BFA-B814-1AA01907810F</bpmn2:incoming>
    </bpmn2:endEvent>
    <bpmn2:callActivity id="_9484CB12-FE52-434C-AE9F-3C3C267D1C96" drools:independent="false" drools:waitForCompletion="true" name="Add items" calledElement="demo.orderItems">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[Add items]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:incoming>_58684613-0155-48B2-8746-7675AFF24439</bpmn2:incoming>
      <bpmn2:outgoing>_8216C810-34D8-4BFA-B814-1AA01907810F</bpmn2:outgoing>
      <bpmn2:ioSpecification id="_gfw8okcJEemyodG9iPy-Bw">
        <bpmn2:dataInput id="_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputX" drools:dtype="org.kie.kogito.examples.demo.Order" itemSubjectRef="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputXItem" name="order"/>
        <bpmn2:dataOutput id="_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputX" drools:dtype="org.kie.kogito.examples.demo.Order" itemSubjectRef="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputXItem" name="order"/>
        <bpmn2:inputSet id="_gfw8o0cJEemyodG9iPy-Bw">
          <bpmn2:dataInputRefs>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputX</bpmn2:dataInputRefs>
        </bpmn2:inputSet>
        <bpmn2:outputSet id="_gfw8pEcJEemyodG9iPy-Bw">
          <bpmn2:dataOutputRefs>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputX</bpmn2:dataOutputRefs>
        </bpmn2:outputSet>
      </bpmn2:ioSpecification>
      <bpmn2:dataInputAssociation id="_gfw8pUcJEemyodG9iPy-Bw">
        <bpmn2:sourceRef>order</bpmn2:sourceRef>
        <bpmn2:targetRef>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputX</bpmn2:targetRef>
      </bpmn2:dataInputAssociation>
      <bpmn2:dataOutputAssociation id="_gfw8pkcJEemyodG9iPy-Bw">
        <bpmn2:sourceRef>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputX</bpmn2:sourceRef>
        <bpmn2:targetRef>order</bpmn2:targetRef>
      </bpmn2:dataOutputAssociation>
    </bpmn2:callActivity>
    <bpmn2:startEvent id="_B44545AB-8B78-4FE4-B6B9-1D467954C070">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:outgoing>_B7B4282B-F317-4BF9-95E9-962B046EE815</bpmn2:outgoing>
    </bpmn2:startEvent>
  </bpmn2:process>
  <bpmndi:BPMNDiagram id="_gfw8p0cJEemyodG9iPy-Bw">
    <bpmndi:BPMNPlane id="_gfw8qEcJEemyodG9iPy-Bw" bpmnElement="demo.Orders">
      <bpmndi:BPMNShape id="shape__B44545AB-8B78-4FE4-B6B9-1D467954C070" bpmnElement="_B44545AB-8B78-4FE4-B6B9-1D467954C070">
        <dc:Bounds height="56.0" width="56.0" x="100.0" y="100.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNShape id="shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96" bpmnElement="_9484CB12-FE52-434C-AE9F-3C3C267D1C96" isExpanded="true">
        <dc:Bounds height="101.0" width="153.0" x="458.5" y="78.0"/>
        <bpmndi:BPMNLabel>
          <dc:Bounds height="11.0" width="41.0" x="514.0" y="123.0"/>
        </bpmndi:BPMNLabel>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNShape id="shape__2D876EF2-93F4-4CBE-959A-04EF7BFA9CED" bpmnElement="_2D876EF2-93F4-4CBE-959A-04EF7BFA9CED">
        <dc:Bounds height="56.0" width="56.0" x="712.0" y="100.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNShape id="shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5" bpmnElement="_0617D7DF-047A-4EC4-85E7-E201D640F4F5">
        <dc:Bounds height="102.0" width="154.0" x="236.0" y="77.0"/>
        <bpmndi:BPMNLabel>
          <dc:Bounds height="11.0" width="48.0" x="289.0" y="122.0"/>
        </bpmndi:BPMNLabel>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNEdge id="edge_shape__B44545AB-8B78-4FE4-B6B9-1D467954C070_to_shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5" bpmnElement="_B7B4282B-F317-4BF9-95E9-962B046EE815" sourceElement="shape__B44545AB-8B78-4FE4-B6B9-1D467954C070" targetElement="shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5">
        <di:waypoint xsi:type="dc:Point" x="156.0" y="128.0"/>
        <di:waypoint xsi:type="dc:Point" x="236.0" y="128.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNEdge>
      <bpmndi:BPMNEdge id="edge_shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5_to_shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96" bpmnElement="_58684613-0155-48B2-8746-7675AFF24439" sourceElement="shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5" targetElement="shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96">
        <di:waypoint xsi:type="dc:Point" x="313.0" y="128.0"/>
        <di:waypoint xsi:type="dc:Point" x="458.5" y="128.5"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNEdge>
      <bpmndi:BPMNEdge id="edge_shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96_to_shape__2D876EF2-93F4-4CBE-959A-04EF7BFA9CED" bpmnElement="_8216C810-34D8-4BFA-B814-1AA01907810F" sourceElement="shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96" targetElement="shape__2D876EF2-93F4-4CBE-959A-04EF7BFA9CED">
        <di:waypoint xsi:type="dc:Point" x="535.0" y="128.5"/>
        <di:waypoint xsi:type="dc:Point" x="740.0" y="128.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNEdge>
    </bpmndi:BPMNPlane>
  </bpmndi:BPMNDiagram>
</bpmn2:definitions>
----

[id="ref-bpmn-support_{context}"]
=== BPMN2 support in {PRODUCT}

[role="_abstract"]
{PRODUCT} currently supports a subset of the https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification]. Although the {PRODUCT} BPMN modeler displays many BPMN components in the canvas palette, the {PROCESS_ENGINE} (process runtime component) in {PRODUCT} currently executes only the supported subset of components. If you use any BPMN components from the {PRODUCT} BPMN modeler palette that are not supported by the {PROCESS_ENGINE}, your {PRODUCT} project might fail to compile or execute. Additional BPMN components are added to {PRODUCT} runtime support with every release.

The following tables list the components from the BPMN2 specification that are currently supported by the {PRODUCT} runtime:

.Support status icons
[cols="30%,70%" options="header"]
|===
|Key
|Description

a|image:kogito/bpmn/grn_check.png[] | Supported by {PRODUCT} runtime
a|image:kogito/bpmn/bk_x.png[] | Not supported by {PRODUCT} runtime
|===

.BPMN2 components
[cols="25%,25%,30%,20%" options="header"]
|===
2+|Component type
|Component
|Support status

2.12+|Start events  |None              |image:kogito/bpmn/grn_check.png[]
                    |Message           |image:kogito/bpmn/grn_check.png[]
                    |Timer             |image:kogito/bpmn/grn_check.png[]
                    |Signal            |image:kogito/bpmn/grn_check.png[]
                    |Compensation      |image:kogito/bpmn/grn_check.png[]
                    |Error             |image:kogito/bpmn/bk_x.png[]
                    |Escalation        |image:kogito/bpmn/bk_x.png[]
                    |Cancel            |image:kogito/bpmn/bk_x.png[]
                    |Conditional       |image:kogito/bpmn/bk_x.png[]
                    |Link              |image:kogito/bpmn/bk_x.png[]
                    |Multiple          |image:kogito/bpmn/bk_x.png[]
                    |Parallel multiple |image:kogito/bpmn/bk_x.png[]
1.32+|Intermediate events  .11+|Catching    |Message           |image:kogito/bpmn/grn_check.png[]
                                            |Timer             |image:kogito/bpmn/grn_check.png[]
                                            |Signal            |image:kogito/bpmn/grn_check.png[]
                                            |Link              |image:kogito/bpmn/grn_check.png[]
                                            |Compensation      |image:kogito/bpmn/grn_check.png[]
                                            |Error             |image:kogito/bpmn/bk_x.png[]
                                            |Escalation        |image:kogito/bpmn/bk_x.png[]
                                            |Cancel            |image:kogito/bpmn/bk_x.png[]
                                            |Conditional       |image:kogito/bpmn/bk_x.png[]
                                            |Multiple          |image:kogito/bpmn/bk_x.png[]
                                            |Parallel multiple |image:kogito/bpmn/bk_x.png[]
                          .10+|Boundary     |Message           |image:kogito/bpmn/grn_check.png[]
                                            |Timer             |image:kogito/bpmn/grn_check.png[]
                                            |Signal            |image:kogito/bpmn/grn_check.png[]
                                            |Compensation      |image:kogito/bpmn/grn_check.png[]
                                            |Error             |image:kogito/bpmn/bk_x.png[]
                                            |Escalation        |image:kogito/bpmn/bk_x.png[]
                                            |Cancel            |image:kogito/bpmn/bk_x.png[]
                                            |Conditional       |image:kogito/bpmn/bk_x.png[]
                                            |Multiple          |image:kogito/bpmn/bk_x.png[]
                                            |Parallel multiple |image:kogito/bpmn/bk_x.png[]
                          .11+|Throwing     |Message           |image:kogito/bpmn/grn_check.png[]
                                            |Timer             |image:kogito/bpmn/bk_x.png[]
                                            |Signal            |image:kogito/bpmn/bk_x.png[]
                                            |Error             |image:kogito/bpmn/bk_x.png[]
                                            |Escalation        |image:kogito/bpmn/bk_x.png[]
                                            |Cancel            |image:kogito/bpmn/bk_x.png[]
                                            |Compensation      |image:kogito/bpmn/bk_x.png[]
                                            |Conditional       |image:kogito/bpmn/bk_x.png[]
                                            |Link              |image:kogito/bpmn/bk_x.png[]
                                            |Multiple          |image:kogito/bpmn/bk_x.png[]
                                            |Parallel multiple |image:kogito/bpmn/bk_x.png[]
2.9+|End events    |None              |image:kogito/bpmn/grn_check.png[]
                    |Message           |image:kogito/bpmn/grn_check.png[]
                    |Error             |image:kogito/bpmn/grn_check.png[]
                    |Terminate         |image:kogito/bpmn/grn_check.png[]
                    |Compensation      |image:kogito/bpmn/grn_check.png[]
                    |Signal            |image:kogito/bpmn/bk_x.png[]
                    |Escalation        |image:kogito/bpmn/bk_x.png[]
                    |Cancel            |image:kogito/bpmn/bk_x.png[]
                    |Multiple          |image:kogito/bpmn/bk_x.png[]
2.6+|Tasks    |Business rule    |image:kogito/bpmn/grn_check.png[]
              |Script           |image:kogito/bpmn/grn_check.png[]
              |User             |image:kogito/bpmn/grn_check.png[]
              |Service          |image:kogito/bpmn/grn_check.png[]
              |Send             |image:kogito/bpmn/bk_x.png[]
              |Receive          |image:kogito/bpmn/bk_x.png[]
2.4+|Subprocesses   |Embedded           |image:kogito/bpmn/grn_check.png[]
                    a|Reusable
                    (call activity)   |image:kogito/bpmn/grn_check.png[]
                    |Ad hoc             |image:kogito/bpmn/grn_check.png[]
                    |Event              |image:kogito/bpmn/bk_x.png[]
2.6+|Gateways   |Inclusive      |image:kogito/bpmn/grn_check.png[]
                |Exclusive      |image:kogito/bpmn/grn_check.png[]
                |Parallel       |image:kogito/bpmn/grn_check.png[]
                |Event-based    |image:kogito/bpmn/grn_check.png[]
                |Complex        |image:kogito/bpmn/bk_x.png[]
                |Chaining       |image:kogito/bpmn/bk_x.png[]

2.3+|Connectors   |Sequence flow     |image:kogito/bpmn/grn_check.png[]
                  |Message flow      |image:kogito/bpmn/bk_x.png[]
                  |Association       |image:kogito/bpmn/bk_x.png[]
2.2+|Collaborators    |Lane             |image:kogito/bpmn/bk_x.png[]
                      |Pool             |image:kogito/bpmn/bk_x.png[]
2.3+|Artifacts        |Group            |image:kogito/bpmn/bk_x.png[]
                      |Text annotation  |image:kogito/bpmn/bk_x.png[]
                      |Data object      |image:kogito/bpmn/bk_x.png[]
|===

For more information about BPMN components, see the Object Management Group (OMG) https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification].

[id="ref-bpmn-start-events_{context}"]
=== Start events supported in {PRODUCT}

[role="_abstract"]
BPMN start events initiate a business process. A start event cannot have an incoming sequence flow and must have only one outgoing sequence flow. You can use start events in top-level processes, embedded subprocess, and callable subprocesses where applicable.

//All start events, with the exception of the `None` start event, are catch events.  For example, a `Signal` start event starts the process only when the referenced signal (event trigger) is received.  You can configure start events in event subprocesses to be interrupting or non-interrupting. An interrupting start event for an event subprocess stops or interrupts the execution of the containing or parent process. A non-interrupting start event does not stop or interrupt the execution of the containing or parent process.

{PRODUCT} currently supports the following start events:

.Supported start events
[cols="25%,25%,25%,25%" options="header"]
|===
|Start event type
|Top-level processes
2+|Subprocesses

|
|
h|Interrupt
h|Non-interrupt

|None
|image:kogito/bpmn/bpmn-start-node.png[]
|Not applicable
|Not applicable

|Message
|image:kogito/bpmn/bpmn-message-node.png[]
|image:kogito/bpmn/bpmn-message-node.png[]
|image:kogito/bpmn/bpmn-message-non-interrupt.png[]

|Timer
|image:kogito/bpmn/bpmn-timer-start.png[]
|image:kogito/bpmn/bpmn-timer-start.png[]
|image:kogito/bpmn/bpmn-timer-non-interrupt.png[]

|Signal
|image:kogito/bpmn/bpmn-signal-start.png[]
|image:kogito/bpmn/bpmn-signal-start.png[]
|image:kogito/bpmn/bpmn-signal-non-interrupt.png[]
|===

////
|Conditional
|image:kogito/bpmn/bpmn-conditional-start.png[]
|image:kogito/bpmn/bpmn-conditional-start.png[]
|image:kogito/bpmn/bpmn-conditional-non-interrupt.png[]

|Compensation
|image:kogito/bpmn/bpmn-compensation-start.png[]
|image:kogito/bpmn/bpmn-compensation-start.png[]
|

|Error
|
|image:kogito/bpmn/bpmn-error-start.png[]
|

|Escalation
|image:kogito/bpmn/bpmn-escalation-start.png[]
|image:kogito/bpmn/bpmn-escalation-start.png[]
|image:kogito/bpmn/bpmn-escalation-non-interrupt.png[]
////

None::
+
--
The none start event is a start event without a trigger condition. A process or a subprocess can contain at most one none start event, which is triggered on process or subprocess start by default, and the outgoing flow is taken immediately.

When you use a none start event in a subprocess, the execution of the process flow is transferred from the parent process into the subprocess and the none start event is triggered. This means that the token (the current location within the process flow) is passed from the parent process into the subprocess activity and the none start event of the subprocess generates a token of its own.
--

Message::
+
--
A process can contain multiple message start events, which are triggered by a particular message. The process instance with a message start event starts its execution from this event after it has received the respective message. After the message is received, the process is instantiated and its message start event is executed immediately (its outgoing flow is taken).

Because a message can be consumed by an arbitrary number of processes and process elements, including no elements, one message can trigger multiple message start events and therefore instantiate multiple processes.
--

Timer::
+
--
The timer start event is a start event with a timing mechanism that is triggered at the start of the process. A process can contain multiple timer start events.

When you use a timer start event in a subprocess, execution of the process flow is transferred from the parent process into the subprocess and the timer start event is triggered. The token is taken from the parent subprocess activity and the timer start event of the subprocess is triggered and waits for the timer to trigger.

After the time defined by the timer definition is reached, the outgoing flow is taken.
--

Signal::
+
--
The signal start event is triggered by a signal with a particular signal code. The signal start event is triggered when the process instance receives the required signal, and then the signal start event is executed and its outgoing flow is taken. A process can contain multiple signal start events.
--

////
.Conditional

The conditional start event is a start event with a Boolean condition definition. The execution is triggered when the condition is first evaluated to `false` and then to ``true``. The process execution starts only if the condition is evaluated to `true` after the start event has been instantiated.

A process can contain multiple conditional start events.

.Compensation

A compensation start event is used to start a compensation event subprocess when using a subprocess as the target activity of a compensation intermediate event.

.Error
A process or subprocess can contain multiple error start events, which are triggered when an error object with a particular `ErrorRef` property is received.
The error object can be produced by an error end event. It indicates an incorrect process ending. The process instance with the error start event starts execution after it has received the respective error object. The error start event is executed immediately upon receiving the error object and its outgoing flow is taken.

.Escalation


The escalation start event is a start event that is triggered by an escalation with a particular escalation code. Processes can contain multiple escalation start events. The process instance with an escalation start event starts its execution when it receives the defined escalation object. The process is instantiated and the escalation start event is executed immediately and its outgoing flow is taken.
////

[id="ref-bpmn-intermediate-events_{context}"]
=== Intermediate events supported in {PRODUCT}

[role="_abstract"]
BPMN intermediate events drive the flow of a business process. Intermediate events catch or throw an event during the execution of the business process. You can add these events between start and end events or as a catch event on the boundary of an activity, such as a subprocess or a user task. You can configure boundary catch events as interrupting or non-interrupting events. An interrupting boundary catch event cancels the bound activity whereas a non-interrupting event does not.

An intermediate event handles a particular situation that occurs during process execution. The situation is a trigger for an intermediate event. In a process, you can add an intermediate event with one outgoing flow to an activity boundary.

If the event occurs while the activity is being executed, the event triggers its execution to the outgoing flow. One activity may have multiple boundary intermediate events. Note that depending on the behavior you require from the activity with the boundary intermediate event, you can use either of the following intermediate event types:

* Interrupting: The activity execution is interrupted and the execution of the intermediate event is triggered.
* Non-interrupting: The intermediate event is triggered and the activity execution continues.

{PRODUCT} currently supports the following intermediate events:

.Supported intermediate events
[cols="20%,20%,20%,20%,20%", options="header"]
|===
|Intermediate event type
|Catching
|Boundary
|
|Throwing

h|
h|
h|Interrupt
h|Non-interrupt
h|

|Message
|image:kogito/bpmn/bpmn-intermediate-message.png[]
|image:kogito/bpmn/bpmn-intermediate-message.png[]
|image:kogito/bpmn/bpmn-message-noninterrupt.png[]
|image:kogito/bpmn/bpmn-message-throwing.png[]

|Timer
|image:kogito/bpmn/bpmn-intermediate-timer.png[]
|image:kogito/bpmn/bpmn-intermediate-timer.png[]
|image:kogito/bpmn/bpmn-timer-noninterrupt.png[]
|Not applicable

|Signal
|image:kogito/bpmn/bpmn-intermediate-signal.png[]
|image:kogito/bpmn/bpmn-intermediate-signal.png[]
|image:kogito/bpmn/bpmn-signal-noninterrupt.png[]
|Not applicable
//image:kogito/bpmn/bpmn-signal-throwing.png[]  (@comment: Use for Throwing here when supported. Stetson, 17 Mar 2020)

|Link
|image:kogito/bpmn/bpmn-link-catching.png[]
|Not applicable
|Not applicable
|image:kogito/bpmn/bpmn-link-throwing.png[]

|Compensation
|image:kogito/bpmn/bpmn-intermediate-catch.png[]
|image:kogito/bpmn/bpmn-intermediate-catch.png[]
|Not applicable
|image:kogito/bpmn/bpmn-intermediate-compensation-throwing.png[]
|===

////
|Error
|
|image:kogito/bpmn/bpmn-intermediate-error.png[]
|
|

|Conditional
|image:kogito/bpmn/bpmn-intermediate-conditional.png[]
|image:kogito/bpmn/bpmn-intermediate-conditional.png[]
|image:kogito/bpmn/bpmn-conditional-noninterrupt.png[]
|

|Escalation
|image:kogito/bpmn/bpmn-intermediate-escalation.png[]
|image:kogito/bpmn/bpmn-intermediate-escalation.png[]
|image:kogito/bpmn/bpmn-intermediate-escalation-non-interrupting.png[]
|image:kogito/bpmn/bpmn-intermediate-escalation-throwing.png[]
////

Message::
+
--
A message intermediate event is an intermediate event that enables you to manage a message object. Use one of the following events:

* A throwing message intermediate event produces a message object based on the defined properties.
* A catching message intermediate event listens for a message object with the defined properties.
--

Timer::
+
--
A timer intermediate event enables you to delay workflow execution or to trigger the workflow execution periodically. It represents a timer that can trigger one or multiple times after a specified period of time. When the timer intermediate event is triggered, the defined timer condition is checked and the outgoing flow is taken.

When you add a timer intermediate event in the process workflow, it has one incoming flow and one outgoing flow. Its execution starts when the incoming flow transfers to the event. When you add a timer intermediate event on an activity boundary, the execution is triggered at the same time as the activity execution.

The timer is canceled if the timer element is canceled, for example, by completing or aborting the enclosing process instance.
--

Signal::
+
--
A signal intermediate event enables you to produce or consume a signal object. Use either of the following options:

* A throwing signal intermediate event produces a signal object based on the defined properties.
* A catching signal intermediate event listens for a signal object with the defined properties.
--

Link::
+
--
A link intermediate event enables you to jump from one place of the diagram to another. A link intermediate event is equivalent to the `goto` functionality in older programming languages.

Use throwing and catching link intermediate events together, where each functions in the following way:

* A throwing link intermediate event refers to the target catching node.
* A catching link intermediate event refers to the source throwing node.
--

Compensation::
+
--
A compensation intermediate event is a boundary event attached to an activity in a transaction subprocess. It can finish with a compensation end event or a cancel end event. The compensation intermediate event must be associated with a flow, which is connected to the compensation activity.

The activity associated with the boundary compensation intermediate event is executed if the transaction subprocess finishes with the compensation end event. The execution continues with the respective flow.
--

////
.Conditional

A conditional intermediate event is an intermediate event with a boolean condition as its trigger. The event triggers further workflow execution when the condition evaluates to `true` and its outgoing flow is taken.

The event must define the [property]``Expression`` property. When a conditional intermediate event is placed in the process workflow, it has one incoming flow, one outgoing flow, and its execution starts when the incoming flow transfers to the event. When a conditional intermediate event is placed on an activity boundary, the execution is triggered at the same time as the activity execution. Note that if the event is non-interrupting, the event triggers continuously while the condition is ``true``.


.Error

An error intermediate event is an intermediate event that can be used only on an activity boundary. It enables the process to react to an error end event in the respective activity.
The activity must not be atomic. When the activity finishes with an error end event that produces an error object with the respective `ErrorCode` property, the error intermediate event catches the error object and execution continues to its outgoing flow.



.Escalation

An escalation intermediate event is an intermediate event that enables you to produce or consume an escalation object. Depending on the action the event element should perform, you need to use either of the following options:

* A throwing escalation intermediate event produces an escalation object based on the defined properties.
* A catching escalation intermediate event listens for an escalation object with the defined properties.
////

[id="ref-bpmn-end-events_{context}"]
=== End events supported in {PRODUCT}

[role="_abstract"]
BPMN end events terminate a business process. An end event has one or more incoming sequence flows and typically has no outgoing flows. A business process can contain multiple end events. All end events, with the exception of the none and terminate end events, are throw events. A process must contain at least one end event.

During runtime, an end event finishes the process workflow. The end event can finish only the workflow that reached it, or all workflows in the process instance, depending on the end event type.

{PRODUCT} currently supports the following end events:

.Supported end events
[cols="30%,70%" options="header"]

|===
h|End event type
h|Icon

|None
|image:kogito/bpmn/bpmn-end-node.png[]

|Message
|image:kogito/bpmn/bpmn-end-message.png[]

|Error
|image:kogito/bpmn/bpmn-end-error.png[]

|Terminate
|image:kogito/bpmn/bpmn-end-terminate.png[]

|Compensation
|image:kogito/bpmn/bpmn-end-compensation.png[]
|===

////
|Escalation
|image:kogito/bpmn/bpmn-end-escalation.png[]

|Signal
|image:kogito/bpmn/bpmn-end-signal.png[]
////

None::
+
--
The none end event specifies that no other special behavior is associated with the end of the process.
--

Message::
+
--
When a flow enters a message end event, the flow finishes and the end event produces a message as defined in its properties.
--

Error::
+
--
The throwing error end event finishes the incoming workflow (consumes the incoming token) and produces an error object. Any other running workflows in the process or subprocess remain uninfluenced.
--

Terminate::
+
--
The terminate end event finishes all execution flows in the specified process or subprocess instance. Activities being executed are canceled. A terminate end event inside a subprocess ends the subprocess instance but does not automatically end the parent process instance.
--

Compensation::
+
--
A compensation end event is used to finish a transaction subprocess and trigger the compensation defined by the compensation intermediate event attached to the boundary of the subprocess activities.
--

////
.Signal

A throwing signal end event is used to finish a process or subprocess flow. When the execution flow enters the element, the execution flow finishes and produces a signal identified by its `SignalRef` property.

.Escalation

The escalation end event finishes the incoming workflow, which means consumes the incoming token, and produces an escalation signal as defined in its properties, triggering the escalation process.
////

[id="ref-bpmn-tasks_{context}"]
=== Tasks supported in {PRODUCT}

[role="_abstract"]
BPMN tasks identify actions to be completed in a business process model and are the smallest unit of work in a process flow.

{PRODUCT} currently supports the following tasks:

.Supported tasks
[cols="40%,60%", options="header"]
|===
| Task type
| Task node

| Business rule task
| image:kogito/bpmn/bpmn-business-rule-task.png[]

| Script task
| image:kogito/bpmn/bpmn-script-task.png[]

| User task
| image:kogito/bpmn/bpmn-user-task.png[]

| Service task
| image:kogito/bpmn/bpmn-service-task.png[]
|===

////
//@comment: Currently unavailable in VSCode. (Stetson, 26 Mar 2020)
In addition, the BPMN2 specification provides the ability to create custom tasks. The following predefined custom tasks are included with {PRODUCT}:

* Rest service tasks: Used to invoke a remote RESTful service
* Email service tasks: Used to send an email
* Log service tasks: Used to log a message
* Java service tasks: Used to call Java code
* WebService service tasks: Used to invoke a remote WebService call
* DecisionTask tasks: Used to execute a DMN diagram
////

[id="ref-bpmn-businessruletask_{context}"]
Business rule task::
+
--
A business rule task specifies a business decision to be executed either through a Decision Model and Notation (DMN) model or a Drools Rule Language (DRL) rule unit.

When a process reaches a business rule task defined by a DMN model, the {PROCESS_ENGINE} executes the DMN model decision with the inputs provided.

When a process reaches a business rule task defined by a DRL rule unit, the {PROCESS_ENGINE} begins executing the rules in the designated rule unit group. When there are no more active rules in the rule unit, the execution continues to the next element. During the rule unit execution, new activations in the rule unit are added to the {DECISION_ENGINE} agenda because these activations are changed by other rules.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected business rule task:

.Business rule task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Rule Language*
| Determines whether the task invokes a decision from a Decision Model and Notation (DMN) model or a Drools Rule Language (DRL) rule unit.

| *Rule Flow Group* (for DRL)
| Defines the DRL rule unit in the format `unit:__PACKAGE_NAME__.__UNIT_NAME__`, such as `unit:org.acme.PersonRules`. This rule unit syntax specifies that you are using a rule unit instead of a traditional rule flow group.

| *Namespace*, *Decision Name*, *DMN Model Name* (for DMN)
| Identifies the relevant DMN model as found in the DMN model file.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the task, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the task, and is currently available only in distributions of the BPMN modeler in jBPM.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall task.
|===
--

Script task::
+
--
A script task represents a script to be executed during the process execution. The associated script can access process variables. When a script task is reached during execution, the script is executed and the outgoing flow is taken.

Review the following list of suggestions before using a script task:

* Avoid low-level implementation details in the process. Although you can use a script task to manipulate variables, consider using a service task when modeling more complex operations.
* Ensure that the script is executed immediately. If the script is not intended to be executed immediately, consider using an asynchronous service task.
* Avoid contacting external services through a script task. Use a service task to model communication with an external service.
* Ensure scripts do not generate exceptions. Runtime exceptions should be caught and managed inside the script or transformed into signals or errors that can then be handled inside the process.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected script task:

.Script task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Script*
| Defines a Java, JavaScript, or MVEL script to be executed by the task and specifies the script type.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall task.
|===
--

User task::
+
--
A user task is an activity in the process workflow that cannot be performed automatically by the system and therefore requires the intervention of a human user, or _actor_.

On execution, the user task element is instantiated as a task that appears in the list of tasks of one or more actors. If a user task element defines the `Groups` property, the task is displayed in task lists of all users that are members of the group. Any user who is a member of the group can claim the task. After a user task is claimed, the task disappears from the task list of the other users.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected user task:

.User task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Task Name*
| Identifies the name of the task as it is displayed to human user (actor).

| *Subject*
| Defines the subject for the task.

| *Actors*
| Specifies the authorized human users (actors) who can complete the user task. Click *Add* to add a row and then select an actor from the list or click *New* to add a new actor.

| *Groups*
| Specifies the authorized group of human users (actors) who can complete the user task. Click *Add* to add a row and then select a group from the list or click *New* to add a new group. Any actor in the group can complete the user task.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.

| *Reassignments*
| Specifies a different actor to complete the task.

| *Notifications*
| Defines notifications associated with the task.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *Skippable*
| Determines whether the task is optional and can be skipped.

| *Priority*
| Defines a priority for the task.

| *Description*
| Describes the task as it is displayed to a human user (actor).

| *Created By*
| Specifies the human user (actor) who created the task. Click *Add* to add a row and then select a user from the list or click *New* to add a new user.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *Multiple Instance*
| Determines whether this task has multiple instances.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the task, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the task, and is currently available only in distributions of the BPMN modeler in jBPM.

| *Content*
| Defines the content of the script.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall task.
|===
--

Service task::
+
--
A service task is an activity that is completed automatically by an external software service and does not require human interaction.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected service task:

.Service task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Implementation*
| Determines whether the task is implemented in Java or is a web service.

| *Interface*
| Defines the class used to implement the script, for example, `org.xyz.HelloWorld`.

| *Operation*
| Defines the method called by the interface, for example, `sayHello()`.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *Multiple Instance*
| Determines whether this task has multiple instances.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the task, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the task, and is currently available only in distributions of the BPMN modeler in jBPM.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall task.
|===
--

A service task also allows you to add a parameter of type `org.kie.kogito.internal.process.runtime.KogitoProcessContext` in your method signature to receive the process context, in which the task is executed. The following is an example of a service task using the process context:

.Example service task using process context
[source,java]
----
@ApplicationScoped
public class CalculationService {

    public Order calculateTotal(Order order, KogitoProcessContext context) {
        System.out.println("Process Id = " + context.getProcessInstance().getStringId());
    }
}
----

////
.None task
None tasks are completed on activation. This is a conceptual model only. A none task is never actually executed by an IT system.

image::kogito/bpmn/bpmn-none-task.png[]
////

[id="ref-bpmn-custom-tasks_{context}"]
=== Custom tasks supported in {PRODUCT}

[role="_abstract"]
The BPMN specification supports the ability to extend the `bpmn2:task` element to create custom tasks in a software implementation. Similar to standard BPMN tasks, custom tasks identify actions to be completed in a business process model, but they also include specialized functionality, such as compatibility with an external service of a specific type (REST, email, or web service) or checkpoint behavior within a process (milestone).

{PRODUCT} provides predefined custom tasks under *Custom Tasks* in the BPMN modeler palette, but currently does not support the ability for you to define your own custom task extensions.

{PRODUCT} currently supports the following predefined custom tasks:

.Supported custom tasks
[cols="40%,60%", options="header"]
|===
| Custom task type
| Custom task node

| Milestone
| image:kogito/bpmn/bpmn-milestone.png[]
|===


Milestone::
+
--
A milestone represents a single point of achievement within a process instance. You can use milestones to flag certain events to trigger other tasks or track the progress of the process. Milestones are useful for Key Performance Indicator (KPI) tracking or for identifying the tasks that are still to be completed. Milestones can occur at the end of a stage in a process or they can be the result of achieving other milestones.

A milestone typically uses a defined input condition that must be met in order to complete the milestone. If no input condition is defined, the milestone is completed automatically when the process reaches the milestone. You can also configure milestones with the `AdHoc Autostart` property to be triggered automatically when the process starts or you can set the *Signal* definition in a signal event in the process to trigger the milestone explicitly. Milestones can be triggered as many times as required. A milestone is achieved when the condition is met or is achieved automatically if no condition is defined.

In the following example process, several milestones control the process for IT hardware orders. For example, when the condition for the `Order placed` milestone is met, the completed milestone triggers a notification script task and leads to an end signal event that triggers the next `Order shipped` milestone, and so on to subsequent milestones until the process is complete.

.Example process with milestones
image::kogito/bpmn/bpmn-milestone-example.png[Image of example process with milestones]

.Example end signal event configured to trigger the next milestone
image::kogito/bpmn/bpmn-milestone-example-signal.png[Image of example signal configuration with a milestone]

Milestones can reach the following states during process execution:

* `Active`: A milestone condition has been defined for the milestone node but it has not been met.
* `Completed`: A milestone condition has been met (if applicable), the milestone has been achieved, and the process can proceed to the next task or can end.
//* `Terminated`: The milestone is no longer a part of the process and is no longer required.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected milestone:

.Milestone properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the milestone.

| *Documentation*
| Describes the milestone. The text in this field is included in the process documentation, if applicable.

| *Is Async*
|  Determines whether this milestone is invoked asynchronously. Make milestones asynchronous if they cannot be executed instantaneously, such as in a process performed by an outside service.

| *AdHoc Autostart*
| Determines whether this is an ad hoc milestone that is started automatically. This option enables the milestone to automatically start when the process is created instead of being started by a signal event.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the milestone, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the milestone, and is currently available only in distributions of the BPMN modeler in jBPM.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Assignments*
a| Defines data input and output for the milestone. Click to open the *Data I/O* window and add data input and output as required. A milestone typically uses a defined input condition that must be met in order to complete the milestone. If no input condition is defined, the milestone is completed automatically when the process reaches the milestone.

For each milestone that requires a condition, enter at least one input data assignment with the following values:

* *Name*: `Condition`
* *Data Type*: `String`
* *Source*: Enter a Java expression for the condition to be met, such as `order.isShipped()` in a process that uses an `order` process variable.

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall task.
|===
--

[id="ref-bpmn-subprocesses_{context}"]
=== Subprocesses supported in {PRODUCT}

[role="_abstract"]
BPMN subprocesses are portions of a parent process that contain process nodes. You can embed part of the parent process within a subprocess. You can also include variable definitions within the subprocess. These variables are accessible to all nodes inside the subprocess.

A subprocess must have one incoming connection and one outgoing connection. A terminate end event inside a subprocess ends the subprocess instance but does not automatically end the parent process instance. A subprocess ends when there are no more active elements in it.

//@comment: Excluded for now until multiple-instance subprocesses are officially supported in Kogito. (Stetson, 19 June 2020)
//A multiple-instance subprocess is instantiated multiple times when its execution is triggered. The instances are created sequentially. A new subprocess instance is created only after the previous instance has finished. A multiple-instance subprocess has one incoming connection and one outgoing connection.

In the following example, the `Place order` subprocess checks whether sufficient stock is available to place the order and updates the stock information if the order can be placed. The customer is then notified through the main process based on whether the order was placed.

.Example subprocess
image::kogito/bpmn/subprocess.png[]

{PRODUCT} currently supports the following subprocesses:

.Supported subprocesses
[cols="40%,60%", options="header"]
|===
| Subprocess type
| Subprocess node

| Embedded subprocess
| image:kogito/bpmn/bpmn-embedded-subprocess.png[]

| Ad hoc subprocess
| image:kogito/bpmn/bpmn-adhoc-subprocess.png[]

| Reusable subprocess
| image:kogito/bpmn/bpmn-reusable-subprocess.png[]
|===

Embedded subprocess::
+
--
An embedded subprocess encapsulates a part of the parent process and shares the parent process data. This subprocess must contain a start event and at least one end event. You can define local subprocess variables that are accessible to all elements inside this container.

NOTE: Multiple-instance behavior is currently not supported for embedded subprocesses in {PRODUCT}.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected embedded subprocess:

.Embedded subprocess properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the subprocess.

| *Documentation*
| Describes the subprocess. The text in this field is included in the process documentation, if applicable.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM.

| *Is Async*
|  Determines whether this subprocess is invoked asynchronously. Make subprocesses asynchronous if they cannot be executed instantaneously, such as a subprocess performed by an outside service.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Process Variables*
| Defines any process variables for the subprocess. Process variables are visible within the specific subprocess instance. Process variables are initialized at subprocess creation and destroyed on subprocess completion. Variable *Tags* provide greater control over the variable behavior, such as whether the variable is `required` or `internal`. For more information about variable tags, see xref:con-bpmn-variables_kogito-developing-process-services[].

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall subprocess.
|===
--

Ad hoc subprocess::
+
--
An ad hoc subprocess contains embedded inner activities and is intended to be executed with a more flexible ordering compared to the typical routing of processes. Unlike typical processes, an ad hoc subprocess does not contain a complete, structured BPMN diagram description, such as from a start event to an end event. Instead, the ad hoc subprocess contains only activities, sequence flows, gateways, and intermediate events. An ad hoc subprocess can also contain data objects and data associations.

The activities within ad hoc subprocesses are not required to have incoming and outgoing sequence flows. However, you can specify sequence flows between some of the contained activities. Sequence flows provide the same ordering constraints in ad hoc subprocesses as in a typical process. Any intermediate events must have outgoing sequence flows and they can be triggered multiple times while the ad hoc subprocess is active.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected ad hoc subprocess:

.Ad hoc subprocess properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the subprocess.

| *Documentation*
| Describes the subprocess. The text in this field is included in the process documentation, if applicable.

| *AdHocActivationCondition*
a| Defines a Java expression that determines when the subprocess is activated, such as `order.isShipped()` in a process that uses an `order` process variable. To activate the subprocess automatically when the parent process starts, leave this field empty with no condition specified.

NOTE: This field supports only Java expressions and does not support Drools expressions as indicated in the field label. This label will be updated in a future release.

| *AdHocCompletionCondition*
a| Defines a Java expression that determines when the subprocess is completed, such as `order.isDelivered()` in a process that uses an `order` process variable. By default, this field contains the value `autocomplete` to complete the subprocess automatically when the subprocess ends.

NOTE: This field supports only Java expressions and does not support Drools and MVEL expressions as indicated in the field label. This label will be updated in a future release.

| *AdHocOrdering*
| Not supported in {PRODUCT}. This property specifies whether the subprocess is executed in *Sequential* or *Parallel* order in the parent process, and is currently available only in distributions of the BPMN modeler in jBPM.

| *AdHoc Autostart*
| Determines whether this ad hoc subprocess is started automatically. This option enables the subprocess to automatically start when the subprocess is created instead of being started by the completion of the previous node or by a signal event.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM.

| *Is Async*
|  Determines whether this subprocess is invoked asynchronously. Make subprocesses asynchronous if they cannot be executed instantaneously, such as a subprocess performed by an outside service.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Process Variables*
| Defines any process variables for the subprocess. Process variables are visible within the specific subprocess instance. Process variables are initialized at subprocess creation and destroyed on subprocess completion. Variable *Tags* provide greater control over the variable behavior, such as whether the variable is `required` or `internal`. For more information about variable tags, see xref:con-bpmn-variables_kogito-developing-process-services[].

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall subprocess.
|===
--

Reusable subprocess::
+
--
A reusable subprocess calls another process or subprocess instance to be used within a parent process. This subprocess enables you to reuse the same process repeatedly without manually duplicating the subprocess.  This subprocess typically appears collapsed within the parent process.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected reusable subprocess:

.Reusable subprocess properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the subprocess.

| *Documentation*
| Describes the subprocess. The text in this field is included in the process documentation, if applicable.

| *Called Element*
| Specifies the ID of the process or subprocess that the activity calls and instantiates.

| *Independent*
| Determines whether the subprocess is started and completed independently of the parent process or whether the subprocess is canceled when the parent process is terminated.

| *Abort Parent*
| (Available only when *Independent* is not selected.) Determines whether a dependent reusable subprocess can abort the parent process when the subprocess is aborted or when an error occurs during the subprocess execution.

| *Wait for completion*
| Determines whether the parent process must wait for this subprocess to complete before continuing.

| *Is Async*
|  Determines whether this subprocess is invoked asynchronously. Make subprocesses asynchronous if they cannot be executed instantaneously, such as a subprocess performed by an outside service.

| *Multiple Instance*
a| Determines whether the subprocess is executed multiple times. When you select this option, the following additional options appear:

* *MI Execution mode*: Specifies whether the multiple subprocess instances are executed in *Sequential* or *Parallel* order as each instance is triggered. In sequential order, a triggered subprocess starts only after the previous subprocess instance completes. In parallel order, a subprocess instance starts whenever it is triggered and can run in parallel with any other triggered subprocesses.
* *MI Collection input*: Specifies the process variable that represents a collection of elements for which new instances are created. The subprocess is instantiated as many times as needed according to the size of the collection.
* *MI Data Input*: Specifies the name of the process variable that contains the selected element in the collection. The variable is used to access elements in the collection.
* *MI Collection output*: (Optional) Specifies the process variable that represents the collection of elements that gather the output of the multi-instance node.
* *MI Data Output*: Specifies the name of the process variable that is added to the output collection that you selected in the *MI Collection output* property.
* *MI Completion Condition*: Not supported in {PRODUCT}. This property defines a Java expression that is evaluated on each completed subprocess instance, and is currently available only in distributions of the BPMN modeler in jBPM.

////
//@comment: MI Completion Condition description for when it is supported. (Stetson, 1 July 2020)
Defines a Java expression that is evaluated on each completed subprocess instance to verify if the specified multi-instance node can complete, such as `order.isShipped()` in a process that uses an `order` process variable. When the completion condition is met, in sequential execution mode, no other subprocess instances are created, and in parallel execution mode, any running subprocess instances are cancelled.

NOTE: The *MI Completion Condition* field supports only Java expressions and does not support MVEL expressions as indicated in the field label. This label will be updated in a future release.
////

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.

| *Metadata Attributes*
| Defines custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

The *Metadata Attributes* enable the new `metaData` extensions to BPMN diagrams and modify the behavior of the overall subprocess.
|===
--

////
.Event subprocess


An event subprocess becomes active when its start event is triggered. It can interrupt the parent process context or run in parallel with it.

With no outgoing or incoming connections, only an event or a timer can trigger the subprocess. The subprocess is not part of the regular control flow.
Although self-contained, it is executed in the context of the bounding process.

Use an event subprocess within a process flow to handle events that happen outside of the main process flow.
For example, while booking a flight, two events may occur:

* Cancel booking (interrupting)
* Check booking status (non-interrupting)

You can model both of these events using the event subprocess.
////

[id="ref-bpmn-gateways_{context}"]
=== Gateways supported in {PRODUCT}

[role="_abstract"]
BPMN gateways create or synchronize branches in a process workflow using a set of conditions in a gating mechanism. BPMN2 supports _converging gateways_ that merge multiple flows into one flow, and _diverging gateways_ that split one flow into multiple flows. One gateway cannot have multiple incoming and multiple outgoing flows.

In the following business process diagram, the exclusive (XOR) gateway evaluates only the incoming flow whose condition evaluates to true:

.Example process with exclusive gateway
image::kogito/bpmn/gateway.png[]

In this example, the customer details are verified by a user and the process is assigned to a user for approval. If the request is approved, an approval notification is sent to the user. If the request is rejected, a rejection notification is sent to the user.

{PRODUCT} currently supports the following gateways:

.Supported gateways
[cols="30%,70%" options="header"]
|===
h|Gateway type
h|Icon

|Exclusive (XOR)
|image:kogito/bpmn/bpmn-gateway-exclusive.png[]

|Inclusive (OR)
|image:kogito/bpmn/bpmn-gateway-inclusive.png[]

|Parallel (AND)
|image:kogito/bpmn/bpmn-gateway-parallel.png[]

|Event (AND)
|image:kogito/bpmn/bpmn-gateway-event.png[]
|===

Exclusive::
+
--
A diverging exclusive gateway selects only the first incoming flow that evaluates to true and that contains the lowest `priority` number, if applicable. A converging exclusive gateway activates the next node for each triggered incoming flow.

[IMPORTANT]
====
Ensure that at least one of the outgoing flows evaluates to true at runtime. If no outgoing flows evaluate to true, the process instance terminates with a runtime exception.

Although priorities are evaluated in {PRODUCT}, the BPMN2 specification does not guarantee the priority order. Avoid depending on the `priority` attribute in your workflow.
====

A converging exclusive gateway also enables a workflow branch to continue to its outgoing flow as soon as it reaches the gateway. When one of the incoming flows triggers the gateway, the workflow continues to the outgoing flow of the gateway. If a gateway is triggered by more than one incoming flow, the gateway activates the next node for each trigger.
--

Inclusive::
+
--
A diverging inclusive gateway selects the incoming flow and all outgoing flows that evaluate to true. Connections with lower `priority` numbers are triggered before triggering higher `priority` connections. Although priorities are evaluated, the BPMN2 specification does not guarantee the priority order. Avoid depending on the `priority` attribute in your workflow.

[IMPORTANT]
====
Ensure that at least one of the outgoing flows evaluates to true at runtime. If no outgoing flows evaluate to true, the process instance terminates with a runtime exception.

Although priorities are evaluated in {PRODUCT}, the BPMN2 specification does not guarantee the priority order. Avoid depending on the `priority` attribute in your workflow.
====
A converging inclusive gateway also merges all incoming flows previously created by an inclusive diverging gateway. A converging inclusive gateway acts as a synchronizing entry point for the inclusive gateway branches.
--

Parallel::
+
--
A parallel gateway synchronizes and creates parallel flows. A diverging parallel gateway selects the incoming flow and all outgoing flows simultaneously. A converging parallel gateway waits until all incoming flows have entered and then triggers the outgoing flow.
--

Event::
+
--
An event gateway is only diverging and reacts to possible events, as opposed to the data-based exclusive gateway that reacts to the process data. An event gateway selects the outgoing flow based on the event that occurs, and selects only one outgoing flow at a time. An event gateway might act as a start event, where the process is instantiated only if one of the intermediate events connected to the event-based gateway occurs.
--

[id="ref-bpmn-connectors_{context}"]
=== Connectors supported in {PRODUCT}

[role="_abstract"]
BPMN connectors create an association between two components in a process. When a connector is directed, the association is sequential and indicates that one of the elements is executed immediately before the other within an instance of the process. Connectors can start and end at the top, bottom, right, or left of the process components being associated. The BPMN2 specification allows you to use your discretion, placing connectors in a way that makes the process behavior easy to follow and understand.

{PRODUCT} currently supports only sequence flow connectors. A sequence flow connects elements of a process and defines the order in which those elements are executed within an instance.

////
* Sequence flows: Connect elements of a process and define the order in which those elements are executed within an instance.
* Association flows: Connect the elements of a process without execution semantics. Association flows can be undirected or unidirectional.

NOTE: The new process modeler supports only undirected association flows. The legacy modeler supports one direction and Unidirection flows.
////

[id="proc-bpmn-model-creating_{context}"]
== Creating and editing BPMN models in the {PRODUCT} BPMN modeler

[role="_abstract"]
You can use the *{VSCODE_EXTENSION}* in VSCode to design BPMN process models and define process logic for a complete and functional BPMN model.

{PRODUCT} currently supports a subset of the https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification]. Although the {PRODUCT} BPMN modeler displays many BPMN components in the canvas palette, the {PROCESS_ENGINE} (process runtime component) in {PRODUCT} currently executes only the supported subset of components. If you use any BPMN components from the {PRODUCT} BPMN modeler palette that are not supported by the {PROCESS_ENGINE}, your {PRODUCT} project might fail to compile or execute. Additional BPMN components are added to {PRODUCT} runtime support with every release.

For more information about BPMN2 support in {PRODUCT}, see xref:ref-bpmn-support_kogito-developing-process-services[].

.Prerequisites
* https://code.visualstudio.com/[VSCode]  is installed.
* The *{VSCODE_EXTENSION}* VSCode extension is installed and enabled in your VSCode IDE. For information about enabling the VSCode extension, see {URL_CREATING_RUNNING}#proc-kogito-vscode-extension_kogito-creating-running[_{CREATING_RUNNING}_].
* You have created a {PRODUCT} project and have included any Java objects required for your {PRODUCT} service. For information about creating a project, see {URL_CREATING_RUNNING}#chap-kogito-creating-running[_{CREATING_RUNNING}_].

.Procedure
. In your VSCode IDE, create or import a BPMN file in the relevant folder of your {PRODUCT} project, typically in `src/main/resources`.
+
NOTE: When you finish creating your process model, you can click *Download* in the *Apache KIE Sandbox* page to import your BPMN file into your {PRODUCT} project.

. Open the new or imported BPMN file to view the process diagram in the {PRODUCT} BPMN modeler.
+
--
If the process diagram does not open in the {PRODUCT} BPMN modeler, ensure that you have installed and enabled the *{VSCODE_EXTENSION}* VSCode extension.

If the {PRODUCT} BPMN modeler opens only the XML source of the BPMN file and displays an error message, review the reported errors and the BPMN model file to ensure that all BPMN elements are correctly defined.
--
. Select the background of the BPMN modeler canvas and, in the upper-right corner of the modeler, click *Properties* to add or verify information for the BPMN file as described in the following table:
+
--
.General process properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Enter the name of the process.

| *Documentation*
| Describes the process. The text in this field is included in the process documentation, if applicable.

| *ID*
| Enter an identifier for this process, such as `orderItems`.

| *Package*
| Enter the package location for this process in your {PRODUCT} project, such as `org.acme`.

| *ProcessType*
| Specify whether the process is public or private (or null, if not applicable).

| *Version*
| Enter the artifact version for the process.

| *Ad hoc*
| Select this option if this process is a flexible process that uses other ad hoc auto-start fragments and that does not require strict start and end events.

| *Process Instance Description*
| Enter a description of the process purpose.

| *Imports*
| Click to open the *Imports* window and add any data object classes required for your process.

| *Executable*
| Select this option to make the process executable as part of your {PRODUCT} project.

| *SLA Due Date*
| Enter the date when the service level agreement (SLA) expires.

| *Process Variables*
| Add any process variables for the process. Process variables are visible within the specific process instance. Process variables are initialized at process creation and destroyed on process completion. Variable *Tags* provide greater control over the variable behavior, such as whether the variable is `required` or `internal`. For more information about variable tags, see xref:con-bpmn-variables_kogito-developing-process-services[].

| *Metadata Attributes*
| Add any custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

You can also use this field to configure role-based access to the process. To configure role-based access, set the attribute *Name* to `securityRoles` and set the attribute value to the relevant group or groups defined for the process, such as `employees,managers`.

| *Global Variables*
|  Not supported in {PRODUCT}. Global variables are visible to all process instances and assets in a project, and apply only to distributions of the BPMN modeler in jBPM.
|===

The *Metadata Attributes* entries are similar to *Process Variables* tags in that they enable new `metaData` extensions to BPMN diagrams. However, process variable tags modify the behavior of specific process variables, such as whether a certain variable is `required` or `internal`, whereas metadata attributes are key-value definitions that modify the behavior of the overall process, such as whether the process contains `securityRoles` or is used in conjunction with a custom event listener.

For example, the following custom metadata attribute `riskLevel` and value `low` in a BPMN process correspond to a custom event listener for starting the process:

.Example metadata attribute and value in the BPMN modeler
image::kogito/bpmn/bpmn-metadata-attributes-custom.png[Image of custom metadata attribute and value]

.Example metadata attribute and value in the BPMN file
[source,xml]
----
<bpmn2:process id="approvals" name="approvals" isExecutable="true" processType="Public">
  <bpmn2:extensionElements>
    <tns:metaData name="riskLevel">
      <tns:metaValue><![CDATA[low]]></tns:metaValue>
    </tns:metaData>
  </bpmn2:extensionElements>
----

.Example event listener with metadata value
[source,java]
----
public class MyListener implements ProcessEventListener {
    ...
    @Override
    public void beforeProcessStarted(ProcessStartedEvent event) {
        Map < String, Object > metadata = event.getProcessInstance().getProcess().getMetaData();
        if (metadata.containsKey("low")) {
            // Implement some action for that metadata attribute
        }
    }
}
----
--
. Begin adding components to your new or imported BPMN process model by clicking and dragging one of the BPMN nodes from the left palette:
+
--
.Adding BPMN components
image::kogito/bpmn/bpmn-drag-nodes.png[]

Although the {PRODUCT} BPMN modeler displays many BPMN components in the canvas palette, the {PROCESS_ENGINE} (process runtime component) in {PRODUCT} currently supports only the following BPMN components:

* *Start events*
** *Start*
** *Start Signal*
** *Start Timer*
** *Start Message*
* *Intermediate events*
** *Intermediate Signal* (catching and boundary)
** *Intermediate Timer* (catching and boundary)
** *Intermediate Message* (catching, boundary, and throwing)
* *End events*
** *End*
** *End Error*
** *End Terminate*
** *End Message*
* *Tasks*
** *Business Rule*
** *User*
** *Service*
** *Script*
* *Subprocesses*
** *Embedded*
** *Reusable*
* *Gateways*
** *Parallel*
** *Event*
** *Exclusive*
** *Inclusive*

--
. In the BPMN modeler canvas, for each new BPMN component that you add, select the new node, and in the upper-right corner of the BPMN modeler, click *Properties* to define the node identity and behavior.
+
--
For more information about BPMN component properties, see xref:ref-bpmn-support_kogito-developing-process-services[].

For this example, use a business rule task based on a Decision Model and Notation (DMN) decision model as your first activity node.

This example assumes that you have the following assets in your {PRODUCT} project:

* A Java object `org.acme.Person`
* A DMN model `PersonDecisions.dmn` with the namespace `https://kie.org/dmn/_F322E39A-1EF2-470E-BD8C-960352D1EA36`
--
. In the left palette, select *Activities* -> *Business Rule*, drag the task to the canvas, and link to it from a start event.
. Select the business rule task and define the following properties:

* *General*: Name the rule task `Evaluate person`.
* *Implementation/Execution*: Set the following values:
** *Rule Language*: `DMN`
** *Namespace*: `https://kie.org/dmn/_F322E39A-1EF2-470E-BD8C-960352D1EA36`
** *Decision Name*: `isAdult`
** *DMN Model Name*: `PersonDecisions`
* *Data Assignments*: Add the following assignments:
** *Data Input*: Add a data input with the name `Person`, with the type `org.acme.Person`, and with the source `person`.
** *Data Output*: Add a data output with the name `isAdult`, with the type `Boolean`, and with the source `isAdult`.
. In the left palette, select *Gateways* -> *Exclusive*, drag the gateway to the canvas, and link to it from the rule task.
. In the left palette, select *Activities* -> *User*, drag the user task to the canvas, and link to it from the exclusive gateway.
. Select the user task and define the following properties:

* *General*: Name the user task `Special handling for children`.
* *Implementation/Execution*: Set the task name to `ChildrenHandling`, and add a data input with the name `person`, the type `org.acme.Person`, and the source `person`.
. In the left palette, select *End Events* -> *End*, drag two end events to the canvas, and link to one end event from the user task and to the other end event from the exclusive gateway.
. Select the connector that connects the exclusive gateway to the end event and for the *Implementation/Execution* property, set the *Condition Expression* to `Java` and enter the condition `return isAdult == true;`.
. Select the connector that connects the exclusive gateway to the user task and for the *Implementation/Execution* property, set the *Condition Expression* to `Java` and enter the condition to `return isAdult == false;`
. Save the BPMN process file.
+
--
The following is the BPMN model for applicant age evaluation in this example:

.Example `persons.bpmn2` BPMN process
image::kogito/creating-running/kogito-bpmn-example-person.png[Image of `persons.bpmn2` process diagram]

You can continue adding or modifying any remaining components and properties of your BPMN process or create a separate example.

The following are additional BPMN models that are used with the `persons.bpmn2` process as part of the same example application:

.Example `orders.bpmn2` process
image::kogito/bpmn/bpmn-model-example-orders.png[Image of `orders.bpmn2` example process]

.Example `orderItems.bpmn2` process invoked as a subprocess
image::kogito/bpmn/bpmn-model-example-order-items.png[Image of `orderItems.bpmn` example process]

As an illustration of a more complex use case, the following is an example BPMN model from a separate mortgage loan application for determining loan approval:

.Example business process for a mortgage loan application
image::kogito/bpmn/bpmn-model-example-mortgage-application.png[Image of mortgage application business process.]

For more {PRODUCT} examples and instructions for using them, see the https://github.com/apache/incubator-kie-kogito-examples[`kogito-examples`] repository in GitHub.
--

[id="con-bpmn-variables_{context}"]
== Variables in {PRODUCT} processes

[role="_abstract"]
Variables in {PRODUCT} processes store data that is used during runtime. The {PRODUCT} BPMN modeler supports the following types of variables:

//@comment: Currently not supported/applicable in Kogito. (Stetson, 24 June 2020)
//* *Global variables*: Variables that are visible to all process instances and assets in a project. Global variables are typically used by business rules and constraints, and are created dynamically by the rules or constraints.
* *Process variables*: Variables that are visible within a specific process instance. Process variables are initialized at process creation and destroyed on process completion.
* *Local variables*: Variables that are visible within a specific process component, such as a task. Local variables are initialized when the element context is initialized (when the execution workflow enters the node and execution of the `onEntry` action has finished, if applicable). Local variables are destroyed when the element context is destroyed (when the execution workflow leaves the element).

A BPMN component, such as a process, subprocess, or task, can only access variables in its own context or in its parent context. A component cannot access a variable defined in a child component. When a BPMN component requires access to a variable during runtime, its own context is searched first.

If the variable cannot be found directly in the component context, the immediate parent context is searched. The search continues until the process context is reached.

If the variable cannot be found, a read access request returns `null`, a write access produces an error message, and the process continues its execution. Variables are searched for based on their unique ID.

=== Variable tags in BPMN process files

For greater control over variable behavior, you can tag process variables and local variables in the  BPMN process file. Tags are simple string values that you add as metadata to a specific variable.

{PRODUCT} supports the following tags for process variables and local variables:

* `internal`: Sets the variable as internal only for a process instance and hides the variable from the exposed REST model. For example, you can use this tag with intermediate variables that help hold some state during the execution of the process but are not part of the domain.
* `required`: Sets the variable as a requirement in order to start a process instance. If a process instance starts without the required variable, {PRODUCT} generates a `VariableViolationException` error.
* `readonly`: Indicates that the variable is for informational purposes only and can be set only once during process instance execution. If the value of a read-only variable is modified at any time, {PRODUCT} generates a `VariableViolationException` error.
* `input`: Sets the variable as an input of the process and therefore is not exposed in the returned data model. As a result, the value of an input variable is not returned in response to REST requests.
* `output`: Sets the variable as an output of the process and therefore is not expected for a process start and is included in the returned data model. As a result, the value of an output variable is returned in response to REST requests.
* `business-relevant`: Indicates that the variable is relevant for a particular item of business value. This tag is helpful for monitoring purposes or for implying that the variable is relevant to another application.
* `tracked`: Sets a variable to be tracked for changes so that {PRODUCT} generates events anytime the value of this variable is changed. Events are published to the `kogito-variables-events` topic in {PRODUCT}, where you can access the previous and new values.

You can define a variable tag in the {KOGITO} BPMN modeler in VSCode, or you can add the tag directly in the BPMN process source file as a `customTags` metadata property with the tag value defined in the format `![CDATA[__TAG_NAME__]]`.

For example, the following BPMN process applies the `required` tag to an `approver` process variable:

.Example variable tagged in the BPMN modeler
image::kogito/bpmn/bpmn-variable-tags-ui.png[Image of variable tags in BPMN modeler]

.Example variable tagged in a BPMN file
[source,xml]
----
<bpmn2:property id="approver" itemSubjectRef="ItemDefinition_9" name="approver">
  <bpmn2:extensionElements>
    <tns:metaData name="customTags">
      <tns:metaValue><![CDATA[required]]></tns:metaValue>
    </tns:metaData>
  </bpmn2:extensionElements>
</bpmn2:property>
----

You can use multiple tags for a variable where applicable, but use caution and ensure that the tags are logical and do not conflict. For example, avoid tagging a variable as both `internal` and `required`.

By default, if a process variable has no tag assigned to it, {PRODUCT} assigns an `input` and an `output` tag to it.

You can also define custom variable tags in your BPMN files to make variable data available to {PRODUCT} process event listeners. Custom tags do not influence the {PRODUCT} runtime as the standard variable tags do and are for informational purposes only. You define custom variable tags in the same `customTags` metadata property format that you use for standard {PRODUCT} variable tags.

////
//@comment: Currently not supported/applicable for Kogito. (Stetson, 24 June 2020)
[id="proc-bpmn-variables-global_{context}"]
=== Defining global variables in {PRODUCT} processes

[role="_abstract"]
Global variables are visible to all process instances and assets in a project, and pass information to the {PROCESS_ENGINE}. Global variables are typically used by business rules and constraints, and are created dynamically by the rules or constraints. Every global variable defines its unique ID and item subject reference. The ID serves as the variable name and must be unique within the process definition. The item subject reference defines the data type that the variable stores.

IMPORTANT: Business rules are evaluated at the moment the fact is inserted. Therefore, if you are using a global variable to constrain a fact pattern and the global is not set, the system returns a `NullPointerException`.

Values of global variables can typically be changed during an assignment, which is a mapping between a process variable and an activity variable. The global variable is then associated with the local activity context, local activity variable, or by a direct call to the variable from a child context.

.Procedure
. In your VSCode IDE, open the relevant BPMN process file to view the process in the {PRODUCT} BPMN modeler.
. Select the background of the BPMN modeler canvas and, in the upper-right corner of the modeler, click *Properties*.
. Under *Process* -> *Global Variables*, click the plus icon to add a new global variable and enter the following values:

* *Name*: Enter the name of the global variable, such as `person` for a global variable with person information shared by all assets.
* *Data Type*: Enter a custom or standard data type of the variable, such as `org.acme.Person`.
+
.Example global variable in BPMN modeler
image::kogito/bpmn/bpmn-global-variables.png[Image of global variable example]
////

[id="proc-bpmn-variables-process_{context}"]
=== Defining process variables in {PRODUCT} processes

[role="_abstract"]
Process variables are visible within a specific process instance. Process variables are initialized at process creation and destroyed on process completion. You can map process variables to local variables.

.Procedure
. In your VSCode IDE, open the relevant BPMN process file to view the process in the {PRODUCT} BPMN modeler.
. Select the background of the BPMN modeler canvas and, in the upper-right corner of the modeler, click *Properties*.
. Under *Process Data* -> *Process Variables*, click the plus icon to add a new process variable and enter the following values:

* *Name*: Enter the name of the process variable, such as `order` for a process variable with order information shared by all applicable nodes in the process.
* *Data Type*: Enter a custom or standard data type of the variable, such as `org.acme.Order`.
+
.Example process variables in BPMN modeler
image::kogito/bpmn/bpmn-process-variables.png[Image of process variable example]

[id="proc-bpmn-variables-local_{context}"]
=== Defining local variables in {PRODUCT} processes

[role="_abstract"]
Local variables are visible within a specific process component, typically a task. Local variables are initialized when the element context is initialized (when the execution workflow enters the node and execution of the `onEntry` action has finished, if applicable). Local variables are destroyed when the element context is destroyed (when the execution workflow leaves the element).

You can map local variables to global or process variables. This mapping enables you to maintain relative independence from the parent context that accommodates the local variable. This isolation helps prevent technical exceptions.

For tasks, with the exception of script tasks, you define local variables as data input or output assignments under *Assignments* in the task properties. Data input assignments define variables that enter the task and provide the entry data required for the task execution. Data output assignments refer to the context of the task after execution to acquire output data.

User tasks present data related to the actor who is completing the user task. User tasks also require the actor to provide result data related to the execution.

//To request and provide the data, use task forms and map the data in the Data Input Assignment parameter to a variable. Map the data provided by the user in the Data Output Assignment parameter if you want to preserve the data as output.

.Procedure
. In your VSCode IDE, open the relevant BPMN process file to view the process in the {PRODUCT} BPMN modeler.
. Select the relevant task (non-script task) and, in the upper-right corner of the modeler, click *Properties*.
. Under *Assignments*, click the edit icon to open the *Data I/O* window, and click *Add* to begin adding local variables as data input or output:

* *Name*: Enter the name of the data input or output, such as `person` for a local variable with person information as the input and `isAdult` for a local variable with adult status as the output.
* *Data Type*: Enter a custom or standard data type of the data input or output, such as `org.acme.Person`.
* *Source* or *Target*: Enter the source object for the data input or the target object for the data output, such as `person` for a Java class with person information.
+
.Example local variables in BPMN modeler
image::kogito/bpmn/bpmn-local-variables.png[Image of local variable example]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=con-persistence]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-jdbc-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-infinispan-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-mongodb-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-kafka-streams-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-locking-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-messaging-enabling]

[id="con-knative-eventing_{context}"]
== Knative Eventing in {PRODUCT} services

[role="_abstract"]
https://knative.dev/docs/eventing/[Knative Eventing] is a serverless platform that enables you to create event producers and consumers for your applications. Knative Eventing uses standard HTTP POST requests to send and receive events between event producers and consumers. These events conform to the https://github.com/cloudevents/spec[CloudEvents specification], which enables creating, parsing, sending, and receiving events in any programming language.

{PRODUCT} provides the https://github.com/apache/incubator-kie-kogito-runtimes/tree/main/addons/common/knative/eventing[Knative Eventing add-on] that enables you to use Knative Eventing with {PRODUCT} services that consume or publish messages within a Business Process Model and Notation (BPMN) process model, Serverless Workflow, or decisions. {PRODUCT} runtime events for messages, processes, tasks, and other application activities are published in https://cloudevents.io/[CloudEvents] format so that they can be consumed efficiently by other entities, such as the Knative Eventing system.

NOTE: Knative Eventing is currently supported for {PRODUCT} services on Quarkus only.

For example, the following `handle-travelers.bpmn2` process uses messaging start and end events to communicate with travelers:

.Example process with messaging start and end events
image::kogito/bpmn/bpmn-messaging-example.png[Image of BPMN process receiving and publishing messages]

When the Knative Eventing add-on is enabled in the {PRODUCT} project that contains this example process, an event consumer is generated from the message start node and an event producer is generated from the message end node at build time.

The following diagram illustrates a scenario with Knative Eventing and a {PRODUCT} service that contains event consumers:

.Knative Eventing and a {PRODUCT} service with event consumers
image::kogito/bpmn/kogito-knative-impl-listening-event.png[{PRODUCT} service listening to events]

In this scenario, three Knative Eventing https://knative.dev/docs/eventing/triggers/[Triggers] are generated to filter the messages that are received by the {PRODUCT} service. These messages are sent to the default {PRODUCT} service port. A message-routing mechanism in the generated code redirects the message to an inner channel based on the name of the message start event in the BPMN process model. The names of message start and end events serve as unique CloudEvents https://github.com/cloudevents/spec/blob/v1.0/spec.md#type[`type` attribute] definitions in Knative Eventing.

In the example `handle-travlers.bpmn2` process, the message start node is named `travelers`, so a message with a `type` named `travelers` triggers the message start node, as shown in the following example curl request:

.Example request to trigger the `travelers` message start event
[source]
----
$ curl -X POST \
      -H "content-type: application/json"  \
      -H "ce-specversion: 1.0"  \
      -H "ce-source: /from/localhost"  \
      -H "ce-type: travelers"  \
      -H "ce-id: 12346"  \
      -d '{"firstName": "Jane", "lastName": "Doe", "email": "jane.doe@example.com", "nationality": "German"}' \
  http://localhost:8080
----

The following diagram illustrates a scenario with Knative Eventing and a {PRODUCT} service that contains event producers:

.Knative Eventing and a {PRODUCT} service with event producers
image::kogito/bpmn/kogito-knative-impl-producing-event.png[{PRODUCT} service producing events]

In this scenario, the {PRODUCT} service sends HTTP POST messages to the Knative Eventing https://knative.dev/docs/eventing/broker/[Broker] through the `SinkBinding` resource. The `SinkBinding` endpoint is generated by the Knative Eventing platform and is injected in the {PRODUCT} service container as an environment variable named `${K_SINK}`. Alternatively, you can use the Knative `KogitoSource`. For more information about the Knative Eventing component, see the https://github.com/knative-sandbox/eventing-kogito[project website].

The following example message is generated by the {PRODUCT} service:

.Example message generated by the {PRODUCT} service
[source]
----
Context Attributes,
  specversion: 1.0
  type: process/travelers/processedtravellers
  source: /process/Travelers/2f692fd9-fff8-4b0a-bb64-96d1a4772490
  id: 29e43b17-3a70-4b46-aca0-7ab8e2133eee
  time: 2020-08-10T20:52:39.383346Z
Extensions,
  knativearrivaltime: 2020-08-10T20:52:39.391404032Z
  knativehistory: default-kne-trigger-kn-channel.kogito.svc.cluster.local
  kogitoprocid: Travelers
  kogitoprocinstanceid: 2f692fd9-fff8-4b0a-bb64-96d1a4772490
  kogitoprocist: 1
Data,
  {"firstName":"Jan","lastName":"Kowalski","email":"jan.kowalski@example.com","nationality":"German","processed":true}
----

In this case, the CloudEvents `type` attribute uses the format `process/__PROCESS_ID__/__NODE_NAME__`. This format prevents the messages generated by the {PRODUCT} service from conflicting with other messages being generated within the cluster, and enables the Knative `Triggers` objects to filter these messages by a unique `type`. The generated CloudEvents message also contains information about the process instance, such as the process ID, process instance ID, and process instance state.

The following diagram illustrates the overall architecture of a {PRODUCT} service deployed in a Knative Eventing environment on a Kubernetes or OpenShift cluster:

.{PRODUCT} service deployed in Knative Eventing environment on Kubernetes or OpenShift
image::kogito/bpmn/kogito-knative-deployment-architecture.png[{PRODUCT} service deployed on Knative Eventing environment]

[id="proc-knative-eventing-process-services_{context}"]
=== Enabling Knative Eventing for {PRODUCT} services

[role="_abstract"]
You can enable https://knative.dev/docs/eventing/[Knative Eventing] support for {PRODUCT} services that consume or publish messages within a Business Process Model and Notation (BPMN) process model or Serverless Workflow. When you enable Knative Eventing for a {PRODUCT} project, event consumers and producers are generated from message start and end nodes in BPMN processes at build time. You can use these event consumers and producers as part of your {PRODUCT} service deployment in a Knative Eventing environment on Kubernetes or OpenShift clusters.

NOTE: Knative Eventing is currently supported for {PRODUCT} services on Quarkus only.

.Prerequisites
* You have installed and deployed Knative Eventing 0.20.0 or later on a Kubernetes or an OpenShift cluster. For information about Knative Eventing on OpenShift, see https://docs.openshift.com/container-platform/4.5/serverless/installing_serverless/installing-knative-eventing.html[Installing Knative Eventing] in the OpenShift documentation.
* You have created a BPMN model in your {PRODUCT} project with message start or end events that you want to integrate with Knative Eventing. For information about creating BPMN models, see xref:proc-bpmn-model-creating_kogito-developing-process-services[].

.Procedure
. Add the following dependencies to the `pom.xml` file of your {PRODUCT} project:
+
--
.Knative Eventing dependencies
[source,xml,subs="attributes+,+quotes"]
----
<dependencies>
    <!-- Enables Knative integration with Kogito -->
    <dependency>
      <groupId>org.kie</groupId>
      <artifactId>kie-addons-quarkus-knative-eventing</artifactId>
    </dependency>
    <!-- Enables Kubernetes and Knative resources generation for Kogito -->
    <dependency>
      <groupId>io.quarkus</groupId>
      <artifactId>quarkus-kubernetes</artifactId>
    </dependency>
</dependencies>
----

This dependency enable Knative Eventing add-on and messaging requirements. When a {PRODUCT} service has the Knative Eventing add-on enabled, {PRODUCT} generates code based on http://www.smallrye.io/smallrye-reactive-messaging/[Smallrye Reactive Messaging] to publish messages.

Optionally, you can add the https://quarkus.io/guides/deploying-to-kubernetes[Quarkus Kubernetes] dependency as exemplified. In this case, the add-on also generates Knative and Kubernetes resources to deploy the {PRODUCT} Service on any cluster. The exemplification assumes that you are using the `quarkus-kubernetes` extension.

--
. In your {PRODUCT} project, open the BPMN file that you want to use for consuming or producing messages in the Knative Eventing environment. BPMN files are typically in `src/main/resources`.
+
--
For example, the following `handle-travelers.bpmn2` process uses messaging start and end events to communicate with travelers:

.Example process with messaging start and end events
image::kogito/bpmn/bpmn-messaging-example.png[Image of BPMN process receiving and publishing messages]

The names of message start and end events serve as CloudEvents https://github.com/cloudevents/spec/blob/v1.0/spec.md#type[`type` attribute] definitions in Knative Eventing and must be unique.
--
. For each message event in the BPMN process model, select the node, click *Properties* in the upper-right corner of the modeler, and verify that the node name is clear and unique.
+
--
For example, consider adding the project or process name as a prefix to the message node name, such as `travelagency.travelers` in the following example:

.Set a unique message node name
image::kogito/bpmn/kogito-knative-set-node-name.png[Image of a message node property name]
--
. The Knative Eventing Add-on automatically configures your {PRODUCT} service by default with the following properties:
+
--
.Required application properties for publishing
[source,subs="attributes+,+quotes"]
----
mp.messaging.outgoing.kogito_outgoing_stream.connector=quarkus-http
mp.messaging.outgoing.kogito_outgoing_stream.url=${K_SINK}
----

NOTE: You can override these properties anytime by adding them to `src/main/resources/application.properties` file in your project.

The `quarkus-http` property defines the HTTP endpoint for the published messages. The `${K_SINK}` property is an environment variable injected by Knative Eventing when you deploy a {PRODUCT} service that references a Knative Eventing https://knative.dev/docs/eventing/samples/sinkbinding/[`SinkBinding`] or https://github.com/knative-sandbox/eventing-kogito#kogito-source[`KogitoSource`] object.

NOTE: If you run the environment variable `K_SINK` locally for test purposes, ensure that `K_SINK` is available in your environment. You can change the property to a constant value as follows:

[source,subs="attributes+,+quotes"]
----
mp.messaging.outgoing.kogito_outgoing_stream.url=${K_SINK:http://localhost:8080/}
----

--
. Build your {PRODUCT} project locally using your usual method, such as `mvn clean package`, and navigate to the `target/generated-sources/kogito` directory in your project and verify the following contents:
+
* Generated classes with the suffixes `MessageConsumer` and `MessageProducer`. These classes are generated based on the message start and end events in your BPMN model.
* Generated `app` folder containing a `CloudEventListenerResource.java` file. This file detects any CloudEvents messages produced by the Knative Eventing source that targets your {PRODUCT} service.

+
If any of these items are missing, ensure that you have configured all required dependencies, applications properties, and message event name. After all checks are complete, rebuild the project.
. After you configure and test your {PRODUCT} project locally, in your Kubernetes or OpenShift environment, add the following custom resources to deploy your {PRODUCT} project. These resources are generated automatically by the {PRODUCT} Knative Eventing add-on and can be found in `target/kubernetes/kogito.yml` and `target/kubernetes/kubernetes.yml` files. These resources are required for consuming or producing events in a Knative Eventing environment.
+
If you plan to run the application locally, please take a look at the example https://github.com/apache/incubator-kie-kogito-examples/tree/stable/process-knative-quickstart-quarkus["Process Knative Quickstart Quarkus"]. You will understand how to configure the enviroment in your local machine using https://knative.dev/docs/eventing/samples/container-source/#create-a-knative-service[Knative Event Display].
+
--
* `Broker`: When you deploy a {PRODUCT} service that uses the Knative Eventing add-on, you can also deploy a Knative Eventing https://knative.dev/docs/eventing/broker/[Broker] in the same namespace. The {PRODUCT} service uses this Broker to publish or listen to CloudEvents messages. You can use any Broker channel for the {PRODUCT} service, such as InMemoryChannel, KafkaChannel, or NatssChannel.
+
By default, the InMemoryChannel channel is used when no channel is specified, as shown in the following `Broker` custom resource example:
+
.Example `Broker` custom resource for Knative Eventing with default InMemoryChannel
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  name: default
----
+
NOTE: InMemoryChannel channels are for development use only. Do not use this channel in a production deployment.

+
For more information about available Broker channels and how to install them, see https://knative.dev/docs/eventing/channels/channels-crds/[Available Channels] in the Knative documentation.

* Knative `Trigger`: To make our service aware of the events of type `travellers` that are arriving in the `Broker`:
+
.Example Knative `Trigger` custom resource for a {PRODUCT} service with `Broker` binding
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: travellers-trigger-process-knative-quickstart-quarkus
spec:
  broker: default
  filter:
    attributes:
      type: travellers
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: process-knative-quickstart-quarkus
----
* Knative `SinkBinding`: The `SinkBinding` resource is used to sink the generated events of a {PRODUCT} service to the Knative Broker. Alternatively, you can set the property `org.kie.kogito.addons.knative.eventing.generate-kogito-source` as `true`. Using this approach, the add-on generates a Knative `KogitoSource` as shown in the following example:
+
.Example `KogitoSource` custom resource for a {PRODUCT} service with the default `Broker`
[source,yaml,subs="+quotes"]
----
apiVersion: kogito.knative.dev/v1alpha1
kind: KogitoSource
metadata:
  name: process-knative-quickstart-quarkus
spec:
  sink:
    ref:
      apiVersion: eventing.knative.dev/v1
      kind: Broker
      name: default
      namespace: ""
  subject:
    apiVersion: serving.knative.dev/v1
    kind: Service
    name: process-knative-quickstart-quarkus
----

After you apply the auto-generated resources to the Kubernetes or OpenShift namespace, the events in the BPMN or Serverless Workflow files (if any) are dispatched to the default Broker.

The Knative Eventing `Trigger` resource filters all messages that are delivered to the default Broker and sends the messages to the {PRODUCT} service.

This Knative Eventing `SinkBinding` resource injects the `${K_SINK}` environment variable to the `Deployment` or Knative `Service` resource created by the add-on. Each message that is generated by the {PRODUCT} service is redirected to the default Knative Broker.

NOTE: If you do not want to use the auto-generated resources, you must create `Trigger` and `SinkBinding` resources manually.

If any other components need to consume the messages produced by the {PRODUCT} service, you must create an additional Knative Eventing `Trigger` resource as shown in the following example:

.Knative Eventing resource for other consuming components
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: event-display-trigger
spec:
  # The default Broker is enabled in the namespace.
  broker: default
  filter:
    # Listens only to events of type `success` emitted by the CloudEvents-processing service.
    attributes:
      # The same type being generated by the custom service.
      type: /process/travelers/processedtravellers
      # The subscriber is the deployed displayer service. Any event that matches the filter in the Broker is sent here.
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: event-display
----

The `spec.filter.attributes.type` value defined in the `Trigger` resource is the same as the value generated by the {PRODUCT} service.
--

For an example {PRODUCT} service with Knative Eventing enabled, see the https://github.com/apache/incubator-kie-kogito-examples/tree/stable/process-knative-quickstart-quarkus[`process-knative-quickstart-quarkus`] example application.

[role="_additional-resources"]
.Additional resources
* {URL_CREATING_RUNNING}#ref-kogito-add-ons_kogito-creating-running[_{CREATING_RUNNING}_]

[id="con-task-lifecycle_{context}"]
== Task lifecycle in {PRODUCT} processes

[role="_abstract"]
In {PRODUCT} business processes, tasks are implemented as work items and their execution is defined by work item handlers. User tasks in particular are a core construct in {PRODUCT} processes. When a user task is reached in a process, the task progresses through phases of a defined lifecycle until it reaches an end state.

{PRODUCT} supports the following default phases in a work item (task) lifecycle:

* *Active*: Indicates initial state when the work item is activated
* *Abort*: Indicates abnormal completion of the work item
* *Complete*: Indicates normal completion of the work item
* *Claim*: Assigns the work item to a specific actor, restricting access to anyone else
* *Release*: Unassigns the work item from a specific actor, releasing it to any other potential user or group to work on it (by claiming or completing)
* *Skip*: Skips the work item

With {PRODUCT}, you can also add custom lifecycles and lifecycle phases to meet your business needs.

A lifecycle moves a work item across various phases that are not defined by the `WorkItem` interface and defines the behavior of a work item at runtime. You typically add a lifecycle on top of the `WorkItemHandler` interface so that the lifecycle is pluggable with more flexible runtime characteristics.

The `WorkItemHandler` interface provides the option to move between task phases, as shown in the following method example:

.WorkItemHandler support for moving between task phases
[source, java]
----
public void transitionToPhase(WorkItem workItem, WorkItemManager manager, Transition<?> transition)
----

NOTE: This method is a default method that does nothing when not implemented. This functionality maintains backward compatibility with existing work item handler implementations.

You typically implement the `transitionToPhase` method as shown in the following example:

.Example implementation of transitionToPhase method
[source, java]
----
@Override
public void transitionToPhase(WorkItem workItem, WorkItemManager manager, Transition<?> transition) {

    lifeCycle.transitionTo(workItem, manager, (Transition<Map<String, Object>>) transition);
}
----

The `lifeCycle` element is an implementation of `org.kie.{PRODUCT_INIT}.process.workitem.LifeCycle<T>` that defines the execution semantics.

=== User task lifecycles
{PRODUCT} provides two lifecycle implementations natively to choose from for user tasks which are `kogito` and `ws-human-task`. The default user task lifecycle `kogito` is a simplified lifecycle implementation compared to `ws-human-task` which is based on the Web Services - Human Task Specification 1.1 (see https://docs.oasis-open.org/bpel4people/ws-humantask-1.1-spec-cs-01.html[here]).

==== Kogito User Task Lifecycle
As mentioned earlier, this is the default lifecycle for {PRODUCT}.

.kogito user task lifecycle state diagram
image::kogito/bpmn/kogito-usertask-lifecycle.png[Image of kogito user task lifecycle]

With the Default life cycle, when a User Task is initiated in the User Task Subsystem it starts in a Created state. At that moment, it automatically passes through the Activate phase that will set the task in Ready state, making the task available to the users that are allowed to work with it.

The task will then remain in Ready state until a user claims it, which will make the task pass through the Claim phase making the move into a Reserved state and the user will become the owner of the task.

With the task Reserved, the owner will be able to complete the task (Complete phase) that will finally move the task to a Completed that will successfully finalize the task allowing the Process Instance to continue.

User Tasks in Ready or Reserved state, can also be reassigned (Reassign phase) that will unassign the task owner and will try to assign it to a different actor.

Also, Users Tasks in Ready or Reserved state, can be finalized with the Fail phase, which causes the task to terminate in a Error state indicating an abnormal completion or through Skip phase that will finalize the task in a Obsolete state indicating that the task was not executed.

Since this lifecycle is chosen as default, no extra configuration is required.

==== Web Services - Human Task Lifecycle
.WS-HumanTask lifecycle state diagram
image::kogito/bpmn/ws-humantask-lifecycle.png[Image of ws-humantask lifecycle]

Upon creation, a task goes into its initial state `Created`. Task creation succeeds irrespective of whether the people assignment returns a set of values or an empty set.

If potential owners were not assigned automatically during task creation then they must be assigned explicitly using nomination, which is performed by the tasks business administrator. The result of evaluating potential owners removes the excluded owners from results. The task remains in the state `Created` until it is activated and has potential owners.

When the task has a single potential owner, it transitions into the `Reserved` state, indicating that it is assigned to a single actual owner. Otherwise, (i.e., when it has multiple potential owners), it transitions into the `Ready` state, indicating that it can be claimed by one of its potential owners. Once a potential owner claims the task, it transitions into the `Reserved` state, making that potential owner the actual owner.

Once work is started on a task that is in state `Ready` or `Reserved`, it goes into the `InProgress` state, indicating that it is being worked on  if the transition is from Ready, the user starting the work becomes its actual owner.

On successful completion of the work, the task transitions into the `Completed` final state. On unsuccessful completion of the work, the task transitions into the `Failed` final state.

The current actual owner of a human task can release a task to again make it available for all potential owners. A task can be released from active states that have an actual owner (`Reserved`, `InProgress`), transitioning it into the `Ready` state. Business data associated with the task (intermediate result data, ad-hoc attachments and comments) is kept.

A task that is currently `InProgress` can be stopped by the actual owner, transitioning it into state `Reserved`. Business data associated with the task as well as its actual owner is kept.

Tasks potential owners, actual owner or business administrator can delegate a task to another user, making that user the actual owner of the task, and also adding them to the list of potential owners in case they are not, yet. A task can be delegated when it is in an active state (`Ready`, `Reserved`, `InProgress`), and transitions the task into the `Reserved` state. Business data associated with the task is kept.

Similarly, tasks potential owners, actual owner or business administrator can forward an active task to another person or a set of people, replacing himself by those people in the list of potential owners. Potential owners can only forward tasks that are in the `Ready` state. Forwarding is possible if the task has a set of individually assigned potential owners, not if its potential owners are assigned using one or many groups. If the task is in the `Reserved` or `InProgress` state then the task is implicitly released first, that is, the task is transitioned into the `Ready` state. Business data associated with the task is kept. The user performing the forward is removed from the set of potential owners of the task, and the forwardee is added to the set of potential owners.

A task can be temporarily suspended transitioning into a `Suspended` state where the task cannot be acted upon. The task can continue its lifecycle only when the task is resumed from Suspended state back to its previous state. Suspend and Resume transitions are allowed for tasks in states `Ready`, `Reserved` or `InProgress`.

A task can be skipped, if it is marked as skippable, and it moves to `Obsolete` final state. A task can also be moved to `Error` or `Exited` final states as required.

To select WS-HumanTask as the default lifecycle, we can use below property

```
kogito.usertasks.lifecycle=ws-human-task
```

Accepted values for this property are: `kogito`, `ws-human-task`.

==== Custom user defined lifecycles
Along with `kogito` and `ws-human-task` which are provided natively by {PRODUCT}, users have the flexibility to provide their own custom user task lifecycle implementation. To do that users needs to implement `org.kie.kogito.usertask.lifecycle.UserTaskLifeCycle` interface. https://github.com/apache/incubator-kie-kogito-examples/tree/main/kogito-quarkus-examples/process-usertasks-custom-lifecycle-quarkus[This] example depicts the usage of a custom user defined user task lifecycle implementation.

A custom user defined implementation takes precedence over the property `kogito.usertasks.lifecycle`.

=== User task authorization

The `org.jbpm.process.instance.impl.humantask.BaseHumanTaskLifeCycle` implementation in {PRODUCT} ensures that a user task is worked on by authorized users, based on the user or group assignments that you provide.

You can use the following parameters to provide assignments for authorized users or groups in the relevant BPMN process model. All of the listed parameters support expressions.

.Parameters for authorized users or groups
[cols="35%,35%,30%"]
|===
|Parameter name |Description |Example value

|`ActorId`
|Comma-separated list of authorized users
|`John,Mary,#{actor}`

|`GroupId`
|Comma-separated list of authorized groups of users
|`mangers,#{mygroup}`

|`BusinessAdministratorId`
|Comma-separated list of authorized administrators
|`administrator,#{adminuser}`

|`BusinessAdministratorGroupId`
|Comma-separated list of groups of administrators
|`admins,#{admingroup}`

|`ExcludedOwnerId`
|Comma-separated list of unauthorized users who cannot work on this task
|`paul,#{lastactor}`
|===

NOTE: Authorization is only enforced when the method that calls the work item lifecycle methods uses a security context. This security behavior is dependent on the API that you use.

=== REST endpoints for tasks in {PRODUCT}

When a process execution reaches the associated user task node, the user task enters the `Active` phase and the execution is paused. In the user task active phase, related input properties are passed to the task. After the user task is completed, the generated results are mapped with the process properties and then the process execution resumes.

When a user task is in the `Active` phase, you can change the task phase, update task results, and manage comments and attachments of a task using the following REST endpoints.

For each endpoint, use a REST client, curl utility, or Swagger UI (if configured for the application) to send requests with the following components:

* *Base URL*: `http://__HOST__:__PORT__/{processId}/{processInstanceId}/{taskName}/{taskInstanceId}`
* *Path parameters*:
** `{processId}`: The string identifier of the process definition, such as `approval`
** `{processInstanceId}`: The integer identifier of the process instance, such as `ec44f890-d21d-444f-a4ec-cb88589bd79`
** `{taskName}`: The string identifier of the task definition, such as `firstLineApproval`
** `{taskInstanceId}`: The integer identifier of the node instance, such as `7a520588-d5ab-464a-8378-d34fda3ff7e9`
* *HTTP headers*: For `POST` requests only:
** `accept`: `application/json`
** `content-type`: `application/json`
* *HTTP methods*: `GET`, `POST`, `PUT`, or `DELETE`

==== Task phases

Use the following REST endpoints to change phases for a task:

Change the current phase for a task::
+
--
`[POST] /phase/{phaseName}`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/phase/complete`

.Example curl request
[source]
----
curl -X POST http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/phase/complete -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Comments

Use the following endpoints to manage comments for a user task:

Retrieve list of comments related to a task::
+
--
`[GET] /comments`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments`

.Example curl request
[source]
----
curl -X GET http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments -H 'content-type: application/json' -H 'accept: application/json'
----
--

Create a comment with the text passed in the request body::
+
--
`[POST] /comments`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments`

.Example curl request
[source]
----
curl -X POST http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments -H 'content-type: application/json' -H 'accept: application/json'
----
--

Update a comment with the text passed in the request body::
+
--
`[PUT] /comments/{commentId}`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments/firstComment`

.Example curl request
[source]
----
curl -X PUT http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments/firstComment -H 'content-type: application/json' -H 'accept: application/json'
----
--

Delete a comment::
+
--
`[DELETE] /comments/{commentId}`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments/firstComment`

.Example curl request
[source]
----
curl -X DELETE http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/comments/firstComment -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Attachments

Use the following REST endpoints to manage attachments for a user task:

Retrieve list of attachments related to a task::
+
--
`[GET] /attachments`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments`

.Example curl request
[source]
----
curl -X GET http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments -H 'content-type: application/json' -H 'accept: application/json'
----
--

Create an attachment with the URL passed in the request body::
+
--
`[POST] /attachments`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments`

.Example curl request
[source]
----
curl -X POST http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments -H 'content-type: application/json' -H 'accept: application/json'
----
--

Update an attachment with the URL passed in the request body::
+
--
`[PUT] /attachments/{attachmentId}`

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments/firstAttachment`

.Example curl request
[source]
----
curl -X PUT http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments/firstAttachment -H 'content-type: application/json' -H 'accept: application/json'
----
--

Delete an attachment::
+
--
`[DELETE] /attachments/{attachmentId}``

.Example REST endpoint
`\http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments/firstAttachment`

.Example curl request
[source]
----
curl -X DELETE http://localhost:8080/approval/ec44f890-d21d-444f-a4ec-cb88589bd79/firstLineApproval/7a520588-d5ab-464a-8378-d34fda3ff7e9/attachments/firstAttachment -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Task management

The REST endpoints for task management in Kogito enable you to manage the predefined information of a task, which cannot be modified using the tasks API endpoints. The predefined information of a task includes Description, Priority, Potential Owners, Administrators, and Input Parameters.

NOTE: The REST API endpoints for task management are accessible to system administrators and users with enough privileges.

The task management REST endpoints support the following HTTP methods:

* `GET` method is used to retrieve information about a task.
* `PUT` method is used to replace the entire task information, indicating that you need to pass the entire task information. Therefore, if you do not include a field in the request, then that field is set as null.
* `PATCH` method is used to replace certain task information, indicating that you need to pass only those fields that you want to modify.

The task management REST API base URL is `http://__HOST__:__PORT__/management/processes/approvals`. Use the following REST endpoints to manage a task:

Retrieve a task information::
+
--
`[GET] /instances/{processInstanceId}/tasks/{taskId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/approvals/instances/ec44f890-d21d-444f-a4ec-cb88589bd79/tasks/8B62D3CA-5D03-4B2B-832B-126469288BB4`

.Example curl request
[source]
----
curl -X GET http://localhost:8080/management/processes/approvals/instances/ec44f890-d21d-444f-a4ec-cb88589bd79/tasks/8B62D3CA-5D03-4B2B-832B-126469288BB4 -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
{
  "description": null,
  "priority": null,
  "potentialUsers": [
    "manager"
  ],
  "potentialGroups": [
    "managers"
  ],
  "excludedUsers": [],
  "adminUsers": [],
  "adminGroups": [],
  "inputParams": {
    "TaskName": "firstLineApproval",
    "NodeName": "First Line Approval",
    "Skippable": "true",
    "ActorId": "manager",
    "traveller": {
      "firstName": "John",
      "lastName": "Doe",
      "email": "jon.doe@example.com",
      "nationality": "American",
      "address": {
        "street": "main street",
        "city": "Boston",
        "zipCode": "10005",
        "country": "US"
      }
    },
    "GroupId": "managers"
  }
}
----
--

Modify specific fields of a task::
+
--
`[PATCH] /instances/{processInstanceId}/tasks/{taskId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/approvals/instances/ec44f890-d21d-444f-a4ec-cb88589bd79/tasks/8B62D3CA-5D03-4B2B-832B-126469288BB4`

.Example request body (JSON)
[source,json]
----
{
	"inputParams": {
		"Skippable": false
	},
	"description": " Real Betis Balompie is the best soccer team in the world",
	"potentialUsers": ["manager", "meganito"]
}
----

.Example response (JSON)
[source,json]
----
{
	"description": " Real Betis Balompie is the best soccer team in the world",
	"priority": null,
	"potentialUsers": [
		"manager", "menganito"
	],
	"potentialGroups": [
		"managers"
	],
	"excludedUsers": [],
	"adminUsers": [],
	"adminGroups": [],
	"inputParams": {
		"TaskName": "firstLineApproval",
		"NodeName": "First Line Approval",
		"Skippable": false,
		"ActorId": "manager",
		"traveller": {
			"firstName": "John",
			"lastName": "Doe",
			"email": "jon.doe@example.com",
			"nationality": "American",
			"address": {
				"street": "main street",
				"city": "Boston",
				"zipCode": "10005",
				"country": "US"
			}
		},
		"GroupId": "managers",

	}
}
----
--

=== API interaction with task lifecycle phases

The following example API interacts with user tasks (work items) using lifecycle phases:

.Example API to interact with task lifecycle phases
[source, java]
----
// Start process instance
ProcessInstance<?> processInstance = approvalsProcess.createInstance(m);
processInstance.start();

// Set up security policy with identity information
StaticIdentityProvider identity = new StaticIdentityProvider("admin", Collections.singletonList("managers"));
SecurityPolicy policy = SecurityPolicy.of(identity);

// Get list of work items, taking security restrictions into account
List<WorkItem> workItems = processInstance.workItems(policy);

// Work on a task
final String wiId = workItems.get(0).getId();
processInstance.transitionWorkItem(wiId,
                                   new HumanTaskTransition(Claim.ID, null, policy));

processInstance.transitionWorkItem(wiId,
                                   new HumanTaskTransition(Complete.ID, Collections.singletonMap("approved", false), policy));
----

When you interact with user tasks through a REST API, you can also provide the following query parameters for user and group information:

.Query parameters for user or group information in REST APIs
[cols="20%,60%,20%"]
|===
|Parameter name |Description |Multi-value support

|`user`
|User name to be used for the user task authorization check
|No

|`group`
|Zero or more group names to be used for the user task authorization check
|Yes
|===

For example, the following REST endpoints interact with user tasks in an `orderItems.bpmn2` process for verifying customer orders:

.Example GET request to retrieve open tasks using the process UUID
[source]
----
curl -X GET http://localhost:8080/orderItems/66c11e3e-c211-4cee-9a07-848b5e861bc5/tasks
----

.Example response
[source]
----
{"62f1c985-d31c-4ead-9906-2fe8d05937f0":"Verify order"}
----

.Example GET request to retrieve task details by process and task UUID
[source,subs="+quotes"]
----
curl -X GET http://localhost:8080/orderItems/66c11e3e-c211-4cee-9a07-848b5e861bc5/Verify_order/62f1c985-d31c-4ead-9906-2fe8d05937f0
----

.Example response
[source]
----
{"id":"62f1c985-d31c-4ead-9906-2fe8d05937f0","input1":{"orderNumber":"12345","shipped":false,"total":0.537941914075738},"name":"Verify order"}
----

.Example POST request to complete the task and define the authorized group and user
[source]
----
curl -X POST http://localhost:8080/orderItems/66c11e3e-c211-4cee-9a07-848b5e861bc5/Verify_order/62f1c985-d31c-4ead-9906-2fe8d05937f0?group=managers&user=john -H "accept: application/json" -H "content-type: application/json"
----

.Example response
[source]
----
{"id":"66c11e3e-c211-4cee-9a07-848b5e861bc5","order":{"orderNumber":"12345","shipped":false,"total":0.537941914075738}}
----

[id="proc-task-lifecycle-custom_{context}"]
=== Creating a custom task lifecycle and phase

[role="_abstract"]
You can extend the user task lifecycle and lifecycle phases in {PRODUCT} to implement a custom lifecycle and phases as needed.

.Procedure
. To add custom lifecycle phases, implement the `org.kie.kogito.process.workitem.LifeCyclePhase` resource in the Java class for your custom lifecycle phases.
+
--
This resource implements the following key methods:

* `id`: Assigns a unique ID that is used when transitioning through phases
* `canTransition`: Provides a checkpoint between phases, if this phase can be transitioned from a specified phase
* `status`: Defines a human-readable status for this phase
* `isTerminating`: Determines if this phase is a completion stage, and if so, completes the work item and moves on to the next activity in the process
* `apply`: Enables additional updates to the work item when transitioning through phases

You can implement as many phases as needed or extend existing phases.
--
. To add a custom lifecycle, implement the `org.kie.kogito.process.workitem.LifeCycle<Map<String, Object>>` resource in the Java class for your custom lifecycle.
+
--
NOTE: To support user tasks, the parameterized type `LifeCycle` must be `Map<String, Object>`.

This resource implements the following key methods:

* `phaseById`: Retrieves the lifecycle phase by ID to verify if the phase is supported by the lifecycle implementation
* `phases`: Returns all supported phases by a specified lifecycle implementation
* `transitionTo`: Provides the main logic to handle phase transition
* `data`: Returns the current state of data for the work item

The following is an example Java class that extends the `Complete` lifecycle phase from a custom lifecycle implementation:

.Example Java class to extend the `Complete` lifecycle phase
[source,java]
----
package org.acme.travels.usertasks;

import java.util.Arrays;
import java.util.List;

import org.jbpm.process.instance.impl.workitem.Complete;
import org.kie.kogito.process.workitem.LifeCyclePhase;

public class CompleteStartedOnly extends Complete {

    private List<String> allowedTransitions = Arrays.asList(Start.ID);

    @Override
    public boolean canTransition(LifeCyclePhase phase) {
        return allowedTransitions.contains(phase.id());
    }

}
----
--

. After you implement your custom lifecycle or lifecycle phases, create a Java configuration class to enable the {PROCESS_ENGINE} to use the new lifecycle or phase instead of the default lifecycle.
+
--
In this configuration, you use the `WorkItemHandlerConfig` class as you do for any other work item handler, as shown in the following example:

.Example configuration class for a custom lifecycle phase
[source,java]
----
@ApplicationScoped
public class CustomWorkItemHandlerConfig extends DefaultWorkItemHandlerConfig {
 {
  register("Human Task", new HumanTaskWorkItemHandler(new CustomHumanTaskLifeCycle()));
 }
}
----

The work item handler is the same as the default, but instead of the default lifecycle, you pass as a constructor argument the custom implementation of the `LifeCycle` interface.
--

For example {PRODUCT} services with custom task lifecycle configurations, see the following example applications in GitHub:

* https://github.com/apache/incubator-kie-kogito-examples/tree/stable/process-usertasks-custom-lifecycle-quarkus[`process-usertasks-custom-lifecycle-quarkus`]: Example on Quarkus
* https://github.com/apache/incubator-kie-kogito-examples/tree/stable/process-usertasks-custom-lifecycle-springboot[`process-usertasks-custom-lifecycle-springboot`]: Example on Spring Boot

[id="con-task-notification-addon_{context}"]
=== {PRODUCT} task notification add-on

[role="_abstract"]
{PRODUCT} provides different task notification add-ons for Quarkus and Spring Boot, enabling you to manage the notifications related to a task when the task is not started or not completed. The task notification add-ons include `jbpm-addons-quarkus-task-notification`, `task-notification-springboot-addon`, `jbpm-addons-quarkus-mail`, and `mail-springboot-addon`.

When a user task deadline is reached and the *Task state type* is still *Not started* or *Not completed*, then a notification is triggered using the configured add-ons. To publish an event on Apache Kafka, {PRODUCT} provides `jbpm-addons-quarkus-task-notification` and `task-notification-springboot-addon` addons, and to send an email notification, {PRODUCT} provides `jbpm-addons-quarkus-mail` and `mail-springboot-addon`. The `jbpm-addons-quarkus-mail` and `mail-springboot-addon` add-ons send the email notification using the information added on the *Notification* page.

image::kogito/bpmn/task-notification-page.png[Notification setting in Kogito]

In the previous example, a notification is set to be triggered every minute till the task is completed. When the defined *Task expiration definition* expires, an email notification is sent to the added user.

To configure the add-ons for your {PRODUCT} services, you can add the task notification add-on as a dependency in the `pom.xml` file of your {PRODUCT} project:

.Project dependency to enable task notifications in Quarkus projects
[source]
----
<profile>
	<id>notification</id>
	<dependencies>
    	 <dependency>
        	 <groupId>org.jbpm</groupId>
        	 <artifactId>jbpm-addons-quarkus-mail</artifactId>
    	 </dependency>
    	 <dependency>
        	 <groupId>org.jbpm</groupId>
        	 <artifactId>jbpm-addons-quarkus-task-notification</artifactId>
    	</dependency>
    	<dependency>
        	 <groupId>io.quarkus</groupId>
        	 <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>
    	</dependency>
  	</dependencies>
</profile>
----

In the previous configuration, `jbpm-addons-quarkus-task-notification` is added as a dependency that uses the https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/2/connectors/connectors.html[Smallrye library] to define a channel named `kogito-deadline-events`. In the `kogito-deadline-events` channel, as `quarkus-smallrye-reactive-messaging-kafka` dependency is added, an event that contains the notification data is published into the configured Apache Kafka topic.

Once the event is published into the configured Apache Kafka topic, you can configure a listener that publishes the email on event reception. To configure an event listener, add the `jbpm-addons-quarkus-mail` in the `pom.xml` file of your {PRODUCT} project. The `jbpm-addons-quarkus-mail` accesses the Apache Kafka records that are published on `kogito-deadline-events` and sends an email using the information in the Apache Kafka record.

To send an email notification, you need to add the following properties to the `application.properties` file. For more information about email configuration, see https://quarkus.io/guides/mailer-reference#configuration-reference[Quarkus mailer configuration].

.Example properties to enable mail notification in `application.properties` file
[source]
----
quarkus.mailer.host=localhost
quarkus.mailer.port=25
quarkus.mailer.mock=false
quarkus.mailer.ssl=false
quarkus.mailer.start-tls=disabled
----

[id="con-process-decisions-integration_{context}"]
== Processes and decisions integration in {PRODUCT}

[role="_abstract"]
When you design a business process in {PRODUCT}, you can define decisions as distinct services using DMN and DRL. For more information about defining decision services, see {URL_DECISION_SERVICES}#chap-kogito-using-dmn-models[_{DECISION_SERVICES}_] and {URL_DECISION_SERVICES}#chap-kogito-using-drl-rules[_{DECISION_SERVICES}_].

{PRODUCT} enables the integration of processes and decisions using different ways, including:

* Embedded method
* Remote method

Based on the use cases, you can either use the embedded or remote method, or you can combine both methods in the same process.

[id="con-process-decisions-integration-embedded_{context}"]
=== Embedded method to integrate processes and decisions

The embedded method to integrate the processes and decisions uses business rule tasks that use the communication between a local process and decision engine that is running in the same application. The embedded method does not require any remote call but requires the decision services to be deployed in the same application as the process running.

For more information about business rule tasks, see xref:ref-bpmn-tasks_kogito-developing-process-services[].

.Embedded method to integrate a process with decisions
image::kogito/bpmn/decisions/process-decisions-embedded-integration.png[Image of Embedded process integration with decisions]

For more information, you can see xref:con-process-decisions-integration-traffic-violation-process-embedded_kogito-developing-process-services[].

You can also use the example applications for Quarkus and Spring Boot, such as https://github.com/apache/incubator-kie-kogito-examples/tree/main/kogito-quarkus-examples/process-decisions-quarkus[`process-decisions-quarkus`] and https://github.com/apache/incubator-kie-kogito-examples/tree/main/kogito-springboot-examples/process-decisions-springboot[`process-decisions-springboot`].

The example of a traffic violations project describes how to use decisions within the processes and how to integrate decisions in an embedded way using the business rule tasks, which must be deployed with a process in the same application.

In {PRODUCT}, the decisions can be expressed in different domains or assets, such as DMN and DRL. All the assets including BPMN, DMN, and DRL must be placed in the `resources` folder.

When the example application is running, there also must be different running processes, such as a process using a business rule task, containing the URL as `http://localhost:8080/traffic`.

[id="con-process-decisions-integration-traffic-violation-process-embedded_{context}"]
==== Traffic violations example for embedded method

The traffic violations project is based on the evaluation process of the traffic violations. In the traffic violations example, first, the information of the driver is fetched, and based on the fetched information, it is determined whether the driver has a valid driving license using a RuleUnit in a DRL. After the validation of the driving license, the violation evaluation is executed, which is defined as a DMN decision, and the output provides the information of whether the driver is suspended or not.

.Traffic violations example
image::kogito/bpmn/decisions/traffic-rules-dmn.png[Image of Traffic Process in process designer]

Processes in traffic violation example::

In the traffic violations project, the interactions with the defined decisions are executed using the decision engine. Also, the information that is required to execute the decision evaluation must be defined in the *Data Assignments* property of the business rule task.

IMPORTANT: The ID property of a process is used in the REST endpoint generation, which refers to the path that is used to interact with the process.

Also, the classes in the process are used to define the Plain Old Java Objects (POJOs) that enable the interaction between the process and decisions. The process classes include `Violation`, `Driver`, `Fine`.

Decisions in traffic violation example::

The traffic violations process contains license validation as a decision that is created using DRL. The license validation consists of rules that are evaluated to verify that the license is expired or not. The result of the license validation is added for the `driver` variable.
The rule units are declared in the `LicenseValidationService.drl` file and the rule unit data is added to the `LicenseValidationService` class.

.Example `LicenseValidationService.drl` file
[source]
----
unit LicenseValidationService

rule "Is driver license valid"
when
    $driver: /driver[licenseExpiration.after(currentTime)]
then
    $driver.setValidLicense(true);
end

rule "Is driver license expired"
when
    $driver: /driver[licenseExpiration.before(currentTime)]
then
    $driver.setValidLicense(false);
end

query "validation"
  $driver : /driver
end
----

.Example `LicenseValidationService` class
[source,java]
----
public class LicenseValidationService implements RuleUnitData {
    private SingletonStore<Driver> driver;

    public LicenseValidationService() {
        this(DataSource.createSingleton());
    }

    public LicenseValidationService(SingletonStore<Driver> driver) {
        this.driver = driver;
    }

    public void setDriver(SingletonStore<Driver> driver) {
        this.driver = driver;
    }

    public SingletonStore<Driver> getDriver() {
        return driver;
    }

    public Date getCurrentTime() {
        return new Date();
    }
}
----

After the license validation task, the traffic violations process contains traffic violation as a decision that is created using DMN. The traffic violation decision verifies whether the driver is suspended or not based on the points in the drivers license.

The traffic violation decision is declared in the `TrafficViolation.dmn` file.

.Example `TrafficViolation.dmn` file
image::kogito/bpmn/decisions/traffic-violation-dmn.png[Image of Traffic Violation - DMN in DMN designer]

[id="con-process-decisions-integration-traffic-violation-data-mapping-embedded_{context}"]
===== Data mapping between a process and decisions

To map the data between a process and decisions, you can align all the attributes names in a Java class, which is used as process variables. If the names of the attributes contain spaces or the names of the attributes are not following Java conventions, then you can use https://github.com/FasterXML/jackson[Jackson] annotations. The Jackson annotations align the process variables with the data types of the DMN model. For example, in the traffic violations project, the `Violation` class is mapped with the `speedLimit` attribute using the `@JsonProperty` annotation. Therefore, the `speedLimit` attribute can be integrated with the `Violation` data type defined in the DMN model.

.Violation class defined in the Traffic Violations example
[source,java]
----
public class Violation {

    @JsonProperty("Code")
    private String code;

    @JsonProperty("Date")
    private Date date;

    @JsonProperty("Type")
    private String type;

    @JsonProperty("Speed Limit")
    private BigDecimal speedLimit;

    @JsonProperty("Actual Speed")
    private BigDecimal actualSpeed;

    //Getters / Setters
}
----

.Violation data type in DMN
image::kogito/bpmn/decisions/violation-dmn-data-types.png[Image of Violation Data Type in DMN in DMN designer]

When the driver information is fetched, an external call to a service task is performed to retrieve the driver information from the database. In this case, the service task implementation is performed using the `DriverService` class. In the Data Assignments, `driverId` is defined as an input variable and `driver` is defined as an output variable, consisting of the driver information.

Fetching the driver information leads to the license validation task, which represents the task of calling a DRL service.

.License validation task (DRL)
image::kogito/bpmn/decisions/license-validation-drl-businessrule.png[Image of License Validation Task in process designer]
The properties that are required to set for the DRL service task include `Rule Language`, which must be set as `DRL` and the `Rule Flow Group`. You can set the value of `Rule Flow Group` using the following format:

`unit:` + `[the FQCN of the Rule Unit Data class]`
For example: `unit:org.kie.kogito.traffic.LicenseValidationService`

In this case, the `driver` variable contains the license validation information.

.License validation task data assignments
image::kogito/bpmn/decisions/license-validation-dmn-businessrule-data.png[Image of License Validation Task data assignment in process designer]

Similar to the license validation task, the traffic violation task represents the task of calling a DMN service.

.Traffic violation task (DMN)
image::kogito/bpmn/decisions/traffic-violation-dmn-businessrule.png[raffic Violation Task data in process designer]

The properties that are required to set for the DMN service task include `Rule Language`, which must be set as `DMN`. Also, you must set the values for `Namespace`, `Decision Name` and `DMN Model Name` properties as defined in the DMN model, such as `TrafficViolation.dmn`. For example, you can set the following values:

* Rule Language: `DMN`
* Namespace: `https://github.com/apache/incubator-kie-drools/kie-dmn/_A4BCA8B8-CF08-433F-93B2-A2598F19ECFF`
* Decision Name: `Traffic Violation`
* DMN Model Name: `Traffic Violation`

The input for the traffic violation task includes `Driver` and `Violation` variables, and the output includes `Suspended` and `Fine` in the Data Assignment property.

.Traffic Violation Task data assignment
image::kogito/bpmn/decisions/traffic-violation-dmn-businessrule-data.png[Traffic Violation Task data assignment in process designer]

In both cases, whether the driver is suspended or not, the related information is logged in the console.

[id="con-process-decisions-integration-remote_{context}"]
=== Remote method to integrate processes and decisions

The remote method to integrate the processes and decisions uses REST endpoints from the decision services. In the REST endpoints, the process can use the BPMN to send HTTP requests, such as a service task or a REST work item.

In the remote method, it is not required for the process and decision services to run in the same application, as the communication between the process and decision services is performed using the network.

.Process integration with decisions through REST
image::kogito/bpmn/decisions/process-decisions-rest-integration.png[Image of Process integration with decisions through REST]

You can also use the example applications for Quarkus and Spring Boot, such as https://github.com/apache/incubator-kie-kogito-examples/tree/main/kogito-quarkus-examples/process-decisions-rest-quarkus[`process-decisions-rest-quarkus`] and https://github.com/apache/incubator-kie-kogito-examples/tree/main/kogito-springboot-examples/process-decisions-rest-springboot[`process-decisions-rest-springboot`].

You can define the decisions in different domains or assets, such as DMN and DRL. Here, we can consider the example of traffic violations, which describes how to integrate decisions in a remote environment using REST endpoints. In the REST endpoints, the decisions are deployed from the process service.

For convenience, the decision assets in the traffic violations example are under the same project as the process. The endpoints are generated differently for the process and decisions but under the same application. However, the endpoints can be placed in different applications.

The traffic violations example of the remote method covers the following processes:

* DMN to define a decision service
* DRL to define rules decision service
* To integrate the process with decisions using REST endpoints
* Service task to call an external decision service
* REST work item to call an external decision service

When the example application is running, there also must be different running processes, such as:

* A process using a service task, containing the URL as `http://HOST:PORT/{serviceTask}`. For example, `http://localhost:8080/traffic_service`.
* A process using a REST work item, containing the URL as `http://HOST:PORT/{workItem}`. For example, `http://localhost:8080/traffic_wih`.

To use the application, you can send requests to the URL. For example:

.Example JSON request
[source,json]
----
{
  "driverId": "12345",
  "violation": {
    "Type": "speed",
    "Speed Limit": 100,
    "Actual Speed": 140
  }
}
----

.Example CURL request
[source]
----
curl -X POST -H 'Content-Type:application/json' -H 'Accept:application/json' -d '{"driverId": "12345","violation":{"Type":"speed","Speed Limit": 100,"Actual Speed":140}}' http://localhost:8080/traffic_service
----

.Example response
[source,json]
----
{
  "id": "e499326d-3bd2-4ddb-93b7-0f68f74a9673",
  "driverId": "12345",
  "driver": {
    "licenseExpiration": "2021-08-12T19:35:48.971+00:00",
    "validLicense": true,
    "Name": "Arthur",
    "State": "SP",
    "City": "Campinas",
    "Points": 13,
    "Age": 30
  },
  "trafficViolationResponse": {
    "Fine": {
      "Amount": 1000,
      "Points": 7
    },
    "Suspended": "Yes"
  },
  "violation": {
    "Code": null,
    "Date": null,
    "Type": "speed",
    "Speed Limit": 100,
    "Actual Speed": 140
  }
}
----

[id="con-process-decisions-integration-traffic-violation-process-remote_{context}"]
==== Traffic violations example for remote method

The traffic violations example for remote method is similar to the xref:con-process-decisions-integration-traffic-violation-process-embedded_kogito-developing-process-services[]. However, in the remote method, you need to use different tasks to perform the calls to the decision services.

The traffic violations example is based on the evaluation process of the traffic violations. In the traffic violations example, first, the information of the driver is fetched, and based on the fetched information, it is determined whether the driver has a valid driving license using a RuleUnit in a DRL. After the validation of the driving license, the violation evaluation is executed, which is defined as a DMN decision, and the output provides the information of whether the driver is suspended or not.

IMPORTANT: The ID property of a process is used in the REST endpoint generation, which refers to the path that is used to interact with the process.

.Traffic process variables
image::kogito/bpmn/decisions/process-variables.png[Image of Traffic Process with service tasks for REST in process designer]

Also, the classes in the process are used to define the Plain Old Java Objects (POJOs) that enable the interaction between the process and decisions. The process classes include  `Violation`, `Driver`, `Fine` and `TrafficViolationResponse`.

Traffic process using service tasks::

When using service tasks for defining a process, it requires coding to provide an implementation in the application that is responsible to execute the task, and in this case a REST or HTTP call.

.Traffic Process with service tasks for REST
image::kogito/bpmn/decisions/traffic-rules-dmn-service-task.png[Image of Traffic Process with service tasks for REST in process designer]

For more information about implementation, see https://quarkus.io/guides/rest-client[Quarkus REST Client], and for implementation details, see the following `LicenseValidationRestClient` and `TrafficViolationRestClient` classes.

.LicenseValidationRestClient class in traffic violation example
[source,java]
----
@Path("/validation/first")
@RegisterRestClient
public interface LicenseValidationRestClient {

    @POST
    @Produces(MediaType.APPLICATION_JSON)
    @Consumes(MediaType.APPLICATION_JSON)
    Driver post(Map<String, Object> parameters);

}
----

.TrafficViolationRestClient class in traffic violation example
[source,java]
----
@Path("/Traffic%20Violation")
@RegisterRestClient
public interface TrafficViolationRestClient {

    @POST
    @Produces(MediaType.APPLICATION_JSON)
    @Consumes(MediaType.APPLICATION_JSON)
    TrafficViolationResponse post(Map<String, Object> parameters);

}
----

The process is declared in the `traffic-rules-dmn-service-task.bpmn` file.

Traffic process using REST work item::

Using the REST work item is a declarative way, which does not require additional implementation. The REST or HTTP call is executed by the decision engine.

.Process using REST work item
image::kogito/bpmn/decisions/traffic-rules-dmn-wih.png[Image of Traffic Process with service tasks for REST in process designer]

The information that is required to execute the REST call, such as URL and HTTP method must be set in the *Data Assignments* for the REST work item. The process is declared in the `traffic-rules-dmn-wih.bpmn` file.

[id="con-process-decisions-integration-traffic-violation-data-mapping-remote_{context}"]
===== Data mapping between a process and decisions

Data mapping from a process to decisions in the remote method is similar to the embedded method. For more information, see xref:con-process-decisions-integration-traffic-violation-data-mapping-embedded_kogito-developing-process-services[].

To map the data between a process and decisions, you can align all the attributes names in a Java class, which is used as process variables. If the names of the attributes contain spaces or the names of the attributes are not following Java conventions, then you can use https://github.com/FasterXML/jackson[Jackson] annotations. The Jackson annotations align the process variables with the data types of the DMN model. For example, in the traffic violations project, the `Violation` class is mapped with the `speedLimit` attribute using the `@JsonProperty` annotation. Therefore, the `speedLimit` attribute can be integrated with the `Violation` data type defined in the DMN model.

.Violation class defined in the traffic process
[source,java]
----
public class Violation {

    @JsonProperty("Code")
    private String code;

    @JsonProperty("Date")
    private Date date;

    @JsonProperty("Type")
    private String type;

    @JsonProperty("Speed Limit")
    private BigDecimal speedLimit;

    @JsonProperty("Actual Speed")
    private BigDecimal actualSpeed;

    //Getters / Setters
}
----

In the traffic violation project, when fetching driver information, an external call to a service task is performed to retrieve the driver information from the database. In this case, the service task implementation is performed using the `DriverService` class. In the Data Assignments, `driverId` is defined as an input variable and `driver` is defined as an output variable, consisting of the driver information.

Fetching the driver information leads to the license validation task, which represents the task of calling a DRL service. The license validation task can be performed using a service task or REST work item:

* When using a service task for the license validation task, the implementation properties must be along with the method. In the implementation properties, it is must to set the Java class to implement the service task that executes the REST call.
+
.License validation service task
image::kogito/bpmn/decisions/license-validation-drl-service-task.png[Image of License Validation Service Task in process designer]
+
The input and output mapping for the license validation service task is the `driver` variable, which contains the validated license information.
+
.License validation service task data assignment
image::kogito/bpmn/decisions/license-drl-service-task-data-mapping.png[Image of License Validation Service Task data assignment in process designer]

* When using a REST work item, the input and output mapping for the license validation task includes the `driver` variable that contains the validated license information. Also, the URL and HTTP method is set as input parameters for the process.
+
.License validation REST work item
image::kogito/bpmn/decisions/license-validation-drl-wih.png[Image of License Validation Service Task in process designer]
+
.License validation REST work item data assignment
image::kogito/bpmn/decisions/license-validation-drl-wih-data-mapping.png[Image of License Validation Service Task data assignment in process designer]

Similar to the license validation task, the traffic violation task represents the task of calling a DMN service using a service task or REST work item:

* When using a service task, the implementation properties must be set along with the method. The implementation properties consist of the Java class that implements the service task.
+
.Traffic violation service task
image::kogito/bpmn/decisions/traffic-violation-drl-service-task.png[Image of License Validation Service Task in process designer]
+
.Traffic violation service task properties
image::kogito/bpmn/decisions/traffic-violation-drl-service-task-properties.png[Image of Traffic Violation Service Task properties in process designer]
+
The input for the traffic violation task includes `Driver` and `Violation` variables, and the output includes `Suspended` and `Fine`, which is part of `TrafficViolationResponse`.
+
.Traffic violation service task data assignment
image::kogito/bpmn/decisions/traffic-violation-drl-service-task-data.png[Image of Traffic Violation Service Task data assignment in process designer]

* When using a REST work item, the input for the task violation task includes `Driver` and `Violation` variables, and the output includes `Suspended` and `Fine, which is part of `TrafficViolationResponse`. Also, the URL and HTTP method is set as input parameters for the process.
+
.Traffic violation REST work item
image::kogito/bpmn/decisions/traffic-violation-drl-wih.png[Image of Traffic Violation REST Work Item in process designer]
+
.Traffic violation REST work item data assignment
image::kogito/bpmn/decisions/traffic-violation-drl-wih-data.png[Image of Traffic Violation REST Work Item data assignmentg in process designer]

In both cases, whether the driver is suspended or not, the related information is logged in the console.

[id="con-flex-processes_{context}"]
== Flexible processes for case management in {PRODUCT}

[role="_abstract"]
{PRODUCT} does not support the https://www.omg.org/cmmn/[Case Management Model and Notation (CMMN) specification] for case management in process services. Instead, {PRODUCT} uses Business Process Model and Notation (BPMN) extensions to provide similar case-management functionality through _flexible processes_.

A flexible process in {PRODUCT} is any process definition that uses ad hoc components or other features that enable the process to be executed more flexibly than traditional processes. For example, a flexible process does not require a standard start event and does not require all nodes to be connected. Some of the typical components in flexible processes include the `Ad-Hoc` process property that enables the process to use ad hoc auto-start fragments and to not require strict start and end events, ad hoc subprocesses that contain embedded inner activities within another process, and milestones that flag or trigger tasks and events.

Similar to case files in CMMN, flexible processes enable you to define traditional processes with more flexibility when the execution path is not rigid. This flexibility is helpful when the process cannot be fully automated or when the scope of the process is difficult to measure. A typical example of a case or flexible process is related to healthcare. A patient has a file that is accessible to the doctor and to any health professionals (or _knowledge workers_) who are assigned to the patient. These assigned workers take action and make different decisions and assessments until the patient is diagnosed and treated, completing the case or flexible process.

{PRODUCT} currently supports the following key case-related features in flexible processes:

* *Ad hoc processes*: An ad hoc process is any process definition that has the `Ad-Hoc` property enabled in the process diagram *Properties* panel. This property enables the process to use ad hoc auto-start fragments, such as ad hoc subprocesses and ad hoc tasks, and to not require strict start and end events. An ad hoc process is similar to a Case in CMMN.
+
.Ad hoc process property
image::kogito/bpmn/bpmn-ad-hoc-process.png[Image of Ad-Hoc process property]
* *Ad hoc subprocesses*: An ad hoc subprocess contains embedded inner activities within another process and is a standard BPMN component that is supported in {PRODUCT}. An ad hoc subprocess is similar to a Stage in CMMN.
+
.Ad hoc subprocess node
image::kogito/bpmn/bpmn-adhoc-subprocess.png[Image of ad hoc subprocess node in process designer]
* *Ad hoc auto-start fragments*: An ad hoc auto-start fragment is any ad hoc process, ad hoc subprocess, or ad hoc task with the `AdHoc Autostart` property enabled. This property enables the fragment to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.
+
.Ad hoc auto-start property
image::kogito/bpmn/bpmn-adhoc-subprocess-autostart.png[Image of ad hoc subprocess node in process designer]
* *Milestones*: A milestone is a standard CMMN component that is incorporated in {PRODUCT} as a BPMN custom task. A milestone represents a single point of achievement within a process instance. You can use milestones to flag certain events to trigger other tasks or track the progress of the process.
+
.Milestone node
image::kogito/bpmn/bpmn-milestone.png[Image of Mileston node in process designer]
* *REST API requests as signals*: A REST API request can serve as a signal event to trigger milestones or to create and start ad hoc fragments such as ad hoc processes, ad hoc subprocesses, or tasks. For non-flexible processes, an empty `POST` request for a process triggers the start node, whereas in a flexible process, the request creates the process instance. Similarly for ad hoc tasks, an empty `POST` request instantiates the task node. All ad hoc auto-start fragments with the `AdHoc Autostart` property enabled are started automatically when the process is created.
+
.Example curl request to add comments to a ticket
[source]
----
curl -D -X POST -H 'Content-Type:application/json' -H 'Accept:application/json' http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment
----
+
.Example response (JSON)
[source,json]
----
HTTP/1.1 201 Created
Content-Length: 305
Location: http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment/f3b36cf9-3953-43ae-afe6-2a48fea8a79a
Content-Type: application/json

{
  "id":"b3c75b24-2691-4a76-902c-c9bc29ea076c",
  "supportCase":{
    "product": {
      "name":"Kogito",
      "family":"Middleware"
    },
    "description":"Kogito is not working for some reason.",
    "engineer":"kelly",
    "customer":"Paco the customer",
    "state":"WAITING_FOR_OWNER",
    "comments":null,
    "questionnaire":null
  },
  "supportGroup":"Kogito"
}
----

[id="ref-flex-process-example_{context}"]
=== Flexible process example

[role="_abstract"]
A typical flexible process consists of one or more of the following basic components:

* Optional start event (might or might not be explicit)
* Optional node connections (might or might not connect all nodes)
* Enabled `Ad-Hoc` process property
* One or more subprocesses, typically ad hoc subprocesses
* Ad hoc auto-start fragments, such as ad hoc subprocesses or ad hoc tasks
* Milestones that flag or trigger events
* End event to terminate the process

The following example is a real-world BPMN model scenario that demonstrates how you can use flexible processes for case management. In this scenario, a service desk uses a flexible process for handling customer tickets related to problems or questions about a specific product.

NOTE: This example is based on the `flexible-process-quarkus` application in the https://github.com/apache/incubator-kie-kogito-examples[`kogito-examples`] repository in GitHub. However, this example may differ from the exact example source code as {PRODUCT} continues to be developed. Be sure to explore this and other {PRODUCT} examples in GitHub to help you develop your own applications.

.Example `service-desk.bpmn2` flexible process
image::kogito/bpmn/bpmn-flex-process-example.png[Image of `service-desk.bpmn2` example process]

To start the process and generate a ticket, a user provides an initial `supportCase` object in a REST request that contains information about the product, the customer, and the related issue:

.Example REST request to start the process and generate a ticket
[source,json]
----
{
  "supportCase": {
    "customer": "Paco the customer",
    "description": "Kogito is not working for some reason.",
    "product": {
      "family": "Middleware",
      "name": "Kogito"
    }
  }
}
----

After the ticket is generated, the `Triage` ad hoc subprocess is automatically started and the ticket is assigned to a support team and then to a support engineer. If the system cannot determine which team to assign the ticket to, a user assigns the ticket manually to a support engineer.

The decision logic for the `Triage` subprocess is defined in the following `SupportGroup` decision table in the `triage.dmn` Decision Model and Notation (DMN) model:

.Example `SupportGroup` DMN decision table
image::kogito/bpmn/bpmn-flex-process-example-decision-table.png[Image of `SupportGroup` example DMN decision table]

The `Work case` ad hoc subprocess is also automatically started when the process is created. Anyone from the `customer` and `support` groups can add comments. To create a task that can be used to add a comment, a user can send an empty `POST` request as shown in the following example:

.Example curl request
[source]
----
curl -D -X POST -H 'Content-Type:application/json' -H 'Accept:application/json' http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment
----

.Example response (JSON)
[source,json]
----
HTTP/1.1 201 Created
Content-Length: 305
Location: http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment/f3b36cf9-3953-43ae-afe6-2a48fea8a79a
Content-Type: application/json

{
  "id":"b3c75b24-2691-4a76-902c-c9bc29ea076c",
  "supportCase":{
    "product": {
      "name":"Kogito",
      "family":"Middleware"
    },
    "description":"Kogito is not working for some reason.",
    "engineer":"kelly",
    "customer":"Paco the customer",
    "state":"WAITING_FOR_OWNER",
    "comments":null,
    "questionnaire":null
  },
  "supportGroup":"Kogito"
}
----

A user can then use the URL in the `Location` HTTP header when rendering the `form action`, as shown in the following example:

.Example form action for a user comment
[source]
----
<form action="http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment/f3b36cf9-3953-43ae-afe6-2a48fea8a79a" method="post">
  <label for="comment">Comment:</label>
  <input type="text" id="comment" name="comment">
</form>
----

After the customer is satisfied with the ticket response and actions, a user clicks a *Resolve Case* button, which sends an empty `POST` request to the service task to set the case to `Resolved` and the process emits a `CaseResolved` event. This event signals the `CaseResolved` milestone, which starts the `Close` ad hoc subprocess that sends, receives, and saves the customer questionnaire and closes the case.

// tag::con-bpmn-process-management-addon[]
[id="con-bpmn-process-management-addon_{context}"]
== {PRODUCT} process management add-on

[role="_abstract"]
{PRODUCT} provides a `kie-addons-quarkus-process-management` add-on that enables basic REST operations that you can use to manage process instances. These REST operations are supplemental to any other specific REST operations that you have configured in your application.

To configure process management REST capabilities for your {PRODUCT} services, you can add the process management add-on as a dependency in the `pom.xml` file of your {PRODUCT} project:

.Project dependency to enable process management REST operations
[source,xml]
----
<dependency>
  <groupId>org.kie.kie</groupId>
  <artifactId>kie-addons-quarkus-process-management</artifactId>
</dependency>
----

The {PRODUCT} process management add-on provides REST support for the following basic operations:

* *Process instances*: Abort an active process instance
* *Node instances*:  Cancel or re-trigger a node instance, or trigger a new node instance
* *Error handling*: Retrieve error details for a process instance, or skip or re-trigger a failed node instance

In addition to exposed REST operations, the process management add-on also provides the following REST exception mappers to generate more meaningful error messages for typical exception types:

* `ProcessInstanceNotFound`
* `NodeInstanceNotFound`
* `NodeNotFound`
* `ProcessInstanceExecutionError`
* `NotAuthorized`
* `InvalidTransition` (for work items)
* `InvalidLifeCyclePhase` (for work items)

These exception mappers produce a valid HTTP error code with JSON payload with the context that caused the exception.

For example, the following is a `ProcessInstanceNotFoundException` error generated at runtime:

.Example error with JSON payload at runtime
[source,json]
----
HTTP code : 404

{
  "processInstanceId" : "c6862071-0f2e-4f21-9bc8-586245a76c3aa",
  "message" : "Process instance with id c6862071-0f2e-4f21-9bc8-586245a76c3aa not found"
}
----
// end::con-bpmn-process-management-addon[]

=== REST endpoints for the process management add-on

After you add the `kie-addons-quarkus-process-management` dependency to your {PRODUCT} project and run your {PRODUCT} services, you can use the following REST endpoints to manage your process and node instances. These REST operations are supplemental to any other specific REST operations that you have configured in your application.

For each endpoint, use a REST client, curl utility, or Swagger UI (if configured for the application) to send requests with the following components:

* *Base URL*: `http://__HOST__:__PORT__/management/processes/{processId}/instances/{processInstanceId}`
* *Path parameters*:
** `{processId}`: The string identifier of the process definition, such as `orders`
** `{processInstanceId}`: The integer identifier of the process instance, such as `ec44f890-d21d-444f-a4ec-cb88589bd79`
** `{nodeId}`: The string identifier of the node, such as `verifyOrders`
** `{nodeInstanceId}`: The integer identifier of the node instance, such as `6e46bec2-0273-46f6-ad7d-2ff156e55a6c`
* *HTTP headers*: For `POST` requests only:
** `accept`: `application/json`
** `content-type`: `application/json`
* *HTTP methods*: `GET`, `POST`, or `DELETE`

==== Process instances

Use the following REST endpoints from the process management add-on to interact with process instances:

Return active node instances for a process instance::
+
--
`[GET] /management/processes/{processId}/instances/{processInstanceId}/nodeInstances`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances`

.Example curl request
[source]
----
curl -X GET localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
{
  "id": "ec44f890-d21d-444f-a4ec-cb88589bd79a",
  "name": "Verify order",
  "nodeInstanceId": "6e46bec2-0273-46f6-ad7d-2ff156e55a6c",
  "parameters": {
    "Locale": "en-UK",
    "TaskName": "Verify order",
    "NodeName": "Verify order",
    "Priority": "1",
    "input1": {
      "orderNumber": "12345",
      "shipped": false,
      "total": 0.8233575052440095
    },
    "Skippable": "true",
    "ActorId": "john"
  },
  "phase": "active",
  "phaseStatus": "Ready",
  "results": {},
  "state": 0
}
----
--

Abort a process instance::
+
--
`[DELETE] /management/processes/{processId}/instances/{processInstanceId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a`

.Example curl request
[source]
----
curl -X DELETE localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Nodes

Use the following REST endpoint from the process management add-on to interact with process nodes:

Return nodes from a process::
+
--
`[GET] /management/processes/{processId}/nodes`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/nodes`

.Example curl request
[source]
----
curl -X GET localhost:8080/management/processes/orders/nodes -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
[
  {
    "name": "End",
    "id": 1,
    "type": "EndNode",
    "uniqueId": "1"
  },
  {
    "name": "End",
    "id": 2,
    "type": "EndNode",
    "uniqueId": "2"
  },
  {
    "name": "Hello2",
    "id": 3,
    "type": "HumanTaskNode",
    "uniqueId": "3"
  },
  {
    "name": "Split",
    "id": 4,
    "type": "Split",
    "uniqueId": "4"
  },
  {
    "name": "End",
    "id": 5,
    "type": "EndNode",
    "uniqueId": "5"
  },
  {
    "name": "End",
    "id": 6,
    "type": "EndNode",
    "uniqueId": "6"
  },
  {
    "name": "Hello1",
    "id": 7,
    "type": "HumanTaskNode",
    "uniqueId": "7"
  },
  {
    "name": "Start",
    "id": 8,
    "type": "StartNode",
    "uniqueId": "8"
  },
  {
    "name": "BoundaryEvent",
    "id": 9,
    "type": "BoundaryEventNode",
    "uniqueId": "9"
  },
  {
    "name": "BoundaryEvent",
    "id": 10,
    "type": "BoundaryEventNode",
    "uniqueId": "10"
  }
]
----
--

==== Node instances

Use the following REST endpoints from the process management add-on to interact with node instances:

Cancel a node instance within a process instance::
+
--
`[DELETE] /management/processes/{processId}/instances/{processInstanceId}/nodeInstances/{nodeInstanceId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c`

.Example curl request
[source]
----
curl -X DELETE localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c -H 'content-type: application/json' -H 'accept: application/json'
----
--

Re-trigger a node instance within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/nodeInstances/{nodeInstanceId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c -H 'content-type: application/json' -H 'accept: application/json'
----
--

Trigger a new instance of a node within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/nodes/{nodeId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodes/verifyOrder`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodes/verifyOrder -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Error handling

Use the following REST endpoints from the process management add-on to troubleshoot errors with process and node instances:

NOTE: These endpoints function only when a process instance is in an `ERROR` state.

Return error details for a process instance::
+
--
`[GET] /management/processes/{processId}/instances/{processInstanceId}/error`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/error`

.Example curl request
[source]
----
curl -X GET localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/error -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
{
  "processInstanceId" : "ec44f890-d21d-444f-a4ec-cb88589bd79a",
  "message" : "Process instance with id c6862071-0f2e-4f21-9bc8-586245a76c3aa contains no input assignment"
}
----
--

Re-trigger any failed nodes within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/retrigger`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/retrigger`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/retrigger -H 'content-type: application/json' -H 'accept: application/json'
----
--

Skip any failed nodes within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/skip`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/skip`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/skip -H 'content-type: application/json' -H 'accept: application/json'
----
--

// tag::con-bpmn-process-svg-addon[]
[id="con-bpmn-process-svg-addon_{context}"]
== {PRODUCT} process SVG add-on

[role="_abstract"]
{PRODUCT} provides an add-on named `process-svg-addon`, enabling the basic REST operations that you can use to visualize the process diagram and execution path of the related process instances. The REST operations are supplemental to any other specific REST operation that is configured in your application.

The add-on requires the access of process SVG files. The process SVG files can be placed in a file system, which is accessible to the service or available in `META-INF/processSVG/` folder in the class path. For example, when the SVG files are generated, rename the files to `{processId}.svg`. The `{processId}.svg` file is used by the add-on and placed in a file system folder (accessible by the service) or in `META-INF/processSVG` folder in the class path. The configuration property `kogito.svg.folder.path` of the add-on points to the file system folder, otherwise the files are searched in the class path.

The VSCode extension enables you to export the process to SVG format:

.Export process diagram at VSCode
image::kogito/bpmn/kogito-svg-addon-manually-export.png[Manually export to SVG at VSCode]

[NOTE]
====
When you export a process to SVG format, the generated SVG is named to {processFileName}-svg.svg.
====

The process code generation searches this export and, if this file exists, copies and renames it to `META-INF/processSVG/{processId}.svg allowing the process SVG addon to consume it directly.

To configure process SVG REST capabilities for your {PRODUCT} services, you can add the process SVG add-on as a dependency in the `pom.xml` file of your {PRODUCT} project:

.Project dependency to enable process SVG REST operations in Quarkus projects
[source,xml]
----
<dependency>
  <groupId>org.kie</groupId>
  <artifactId>kie-addons-quarkus-process-svg</artifactId>
</dependency>
----

.Project dependency to enable process SVG REST operations in Spring Boot projects
[source,xml]
----
<dependency>
  <groupId>org.kie</groupId>
  <artifactId>kie-addons-springboot-process-svg</artifactId>
</dependency>
----

The process SVG add-on provides the following set of configuration properties:

.Process SVG add-on configuration properties in {PRODUCT}
[cols="30%,70%"]
|===
|Property
|Description

|`kogito.svg.folder.path`
|Determines the folder in which the add-on searches the initial process diagrams. If this property is not enabled, then the add-on searches `META-INF/processSVG/` folder in the class path.

Default value: `empty`

Example: `kogito.svg.folder.path=/home/user/diagrams`

a|`kogito.svg.color.completed`
|Changes the color to fill the completed nodes when showing the execution path.

Default value: `#C0C0C0`

Example: `kogito.svg.color.completed=#C2C0C1`

a|`kogito.svg.color.completed.border`
|Changes the color of the border of the completed node when showing the execution path.

Default value: `#030303`

Example: `kogito.svg.color.completed.border=#C2C0C1`

a|`kogito.svg.color.active.border`
|Changes the color of the border of the active node when showing the execution path.

Default value: `#FF0000`

Example: `kogito.svg.color.active.border=#C2C0C1`

|===

The {PRODUCT} process SVG add-on provides REST support for the following basic operations:

* *Process Diagram*: Return the process SVG diagram
* *Process instance diagram*: Return the process SVG diagram displaying the executed path of a specific process instance
// end::con-bpmn-process-svg-addon[]

=== REST endpoints for the process SVG add-on

After you add the `kie-addons-quarkus-process-svg` or `kie-addons-springboot-process-svg` dependency to your {PRODUCT} project, add the recommended configuration properties, and run your {PRODUCT} services. You can use the following REST endpoints to receive the process related SVGs. The REST operations are supplemental to any other specific REST operations that are configured in your application.

NOTE: These REST operations are supplemental to any other specific REST operations that you have configured in your application.

For each endpoint, use a REST client, curl utility, or Swagger UI (if configured for the application) to send requests with the following components:

* *Base URL*: `http://__HOST__:__PORT__/svg/processes/{processId}`
* *Path parameters*:
** `{processId}`: The string identifier of the process definition, such as `travels`
* *HTTP methods*: `GET`

==== Process diagram
Use the following REST endpoint from the process SVG add-on to interact with the process diagram:

Return the SVG that shows the process diagram::
+
--
`[GET] /svg/processes/{processId}`

.Example REST endpoint
`\http://localhost:8380/svg/processes/travels`

.Example curl request
[source]
----
curl -X GET http://localhost:8380/svg/processes/travels -H 'content-type: application/json' -H 'accept: image/svg+xml'
----
--

==== Process instance diagram
Use the following endpoint from the process SVG add-on to interact with the process instance diagram:

Return the process SVG diagram and highlight the executed path::
+
--
`[GET] /svg/processes/{processId}/instances/{processInstanceId}`

.Example REST endpoint
`\http://localhost:8380/svg/processes/travels/instances/2d115b55-ff30-42f0-ab21-e0651abb4d04`

.Example curl request
[source]
----
curl -X GET http://localhost:8380/svg/processes/travels/instances/2d115b55-ff30-42f0-ab21-e0651abb4d04 -H 'content-type: application/json' -H 'accept: image/svg+xml'
----
--

This REST endpoint can be used in environments that hold enabled security at the connected Data Index Service. The SVG add-on generates a query on Data Index Service to retrieve the executed nodes and if the Data Index Service contains enabled security, then it needs to pass a valid bearer token to complete the query.

If the SVG add-on detects a known security context enabled, then it retrieves the bearer token, otherwise the add-on reuses the token that is passed directly in the Authorization header.

NOTE: Currently, the process SVG add-on retrieves the token for systems that contain OpenID Connect using Keycloak.

// tag::con-bpmn-process-event-addon[]
[id="con-bpmn-process-event-addon_{context}"]
== {PRODUCT} process event add-on

{PRODUCT} provides a process event add-on, which you can use to send processes, tasks, and variable events to an external event listener. In this case, the processes, tasks, and variable events are generated as a result of the execution of an operation, which modifies a process state; such events are known as runtime events.

In {PRODUCT}, every modifying operation is executed within an abstraction called a unit of work. Examples of such operations include creating a process instance, transitioning a task, and modifying a variable. A runtime event is published when a unit of work is completed.

You can use the {PRODUCT} process event add-on to build a historical representation of all process instance executions. Also, you can use this add-on with process REST API to build a custom graphical user interface to handle the user tasks.

By default, the event format follows https://cloudevents.io/[CloudEvent] specification. The CloudEvent specification allows sending information using the data field, which contains a JSON of one of the following types:

* https://github.com/apache/incubator-kie-kogito-runtimes/blob/main/api/kogito-services/src/main/java/org/kie/kogito/services/event/impl/ProcessInstanceEventBody.java[ProcessInstanceEvent]: This event is published when a process instance is created, modified, or completed.
* https://github.com/apache/incubator-kie-kogito-runtimes/blob/main/api/kogito-services/src/main/java/org/kie/kogito/services/event/impl/UserTaskInstanceEventBody.java[UserTaskInstanceEvent]: This event is published when a change occurs on a user task.
* https://github.com/apache/incubator-kie-kogito-runtimes/blob/main/api/kogito-services/src/main/java/org/kie/kogito/services/event/impl/VariableInstanceEventBody.java[VariableInstanceEvent]: This event is published when a variable is created, modified, or removed.

To configure process event capabilities for your {PRODUCT} services, you can add the process event add-on as a dependency in the `pom.xml` file of your {PRODUCT} project:

.Project dependency to enable process event operations in Quarkus projects
[source,xml,subs="attributes+"]
----
<dependency>
  <groupId>org.kie</groupId>
  <artifactId>kie-addons-quarkus-events-process</artifactId>
</dependency>
----

.Project dependency to enable process event operations in Spring Boot projects
[source,xml,subs="attributes+"]
----
<dependency>
  	<groupId>org.kie</groupId>
  	<artifactId>kie-addons-springboot-events-process-kafka</artifactId>
</dependency>
----

NOTE: The {PRODUCT} process event add-on for Spring Boot is specific to Kafka. Therefore, you do not need to add additional dependencies to your `pom.xml` file to use an event broker.

For Quarkus, the {PRODUCT} process event add-on implementation is based on https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/2/connectors/connectors.html[Smallrye Messaging] library, which provides a set of connectors for event brokers, such as JMS, AMQP, and Kafka. Therefore, the {PRODUCT} process event add-on is not specifically combined with any event broker in Quarkus, but requires additional configuration to use a suitable Smallrye connector.

For example, to use Kafka as an event broker in Quarkus, you can add the following dependency in the `pom.xml` file of your {PRODUCT} project:

.Project dependency to enable Kafka event broker in Quarkus
[source,xml,subs="attributes+"]
----
 <dependency>
  	<groupId>io.quarkus</groupId>
  	<artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>
</dependency>
----

Smallrye defines an abstraction named channel to enable multi-broker support. For every channel that you define in your {PRODUCT} application, you can specify the connector to use for that channel using the following form:

`mp.messaging.[incoming|outgoing].<channel name>.connector = <connector name>`

Optionally, for Kafka connector, you can define the Kafka topic to be used for that channel using the following form:

`mp.messaging.[incoming|outgoing].<channel name>.topic = <topic name>`

You can also set up a channel property using the following form:

`mp.messaging.[incoming|outgoing].<channel name>.<property name>= <property value>`

IMPORTANT: If the defined property is not found, then the topic name is considered to be the same as Kafka name.

The {PRODUCT} process event add-on defines a channel for each event type, such as `kogito-processinstances-events`, `kogito-usertaskinstances-events`, and `kogito-variables-events`. Therefore, when the process event add-on is enabled, you must add the event types to your `application.properties` file using the following properties:

.Properties to define event types in `application.properties` file
[source]
----
mp.messaging.outgoing.kogito-processinstances-events.connector=smallrye-kafka
mp.messaging.outgoing.kogito-processinstances-events.topic=kogito-processinstances-events
mp.messaging.outgoing.kogito-processinstances-events.value.serializer=org.apache.kafka.common.serialization.StringSerializer

mp.messaging.outgoing.kogito-usertaskinstances-events.connector=smallrye-kafka
mp.messaging.outgoing.kogito-usertaskinstances-events.topic=kogito-usertaskinstances-events
mp.messaging.outgoing.kogito-usertaskinstances-events.value.serializer=org.apache.kafka.common.serialization.StringSerializer

mp.messaging.outgoing.kogito-variables-events.connector=smallrye-kafka
mp.messaging.outgoing.kogito-variables-events.topic=kogito-variables-events
mp.messaging.outgoing.kogito-variables-events.value.serializer=org.apache.kafka.common.serialization.StringSerializer
----

Additionally, you can disable the publishing on any channel by setting the related property to false as shown in the following example:

.Example properties to disable publishing
[source]
----
kogito.events.usertasks.enabled=false
kogito.events.variables.enabled=false
----
// end::con-bpmn-process-event-addon[]

[id="con-management-console_{context}"]
== {PRODUCT} Management Console

[role="_abstract"]
The {PRODUCT} Management Console is a user interface for viewing the state of all available {PRODUCT} services and managing process instances:

.{PRODUCT} Management Console
image::kogito/bpmn/kogito-management-console.png[Image of Kogito Management Console]

You can use the Management Console to view process, subprocess, and node instance details, abort process instances, and view domain-specific process data.

The Management Console requires your {PRODUCT} services to use the following {PRODUCT} components:

* *{PRODUCT} Data Index Service*: Enables the Management Console to access stored events related to processes and domain data from your {PRODUCT} services. The {PRODUCT} Data Index Service requires Infinispan or MongoDB persistence and Apache Kafka messaging for your {PRODUCT} service. For more information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].
* *{PRODUCT} process management add-on*: Enables the Management Console to interact with the process data from your {PRODUCT} services through the add-on REST endpoint `/management/processes`. If you do not enable this add-on for your {PRODUCT} service, the Management Console provides read-only access to your service data without the ability to modify instances, such as aborting process instances. For more information about the process management add-on, see xref:con-bpmn-process-management-addon_kogito-developing-process-services[].

To visualize the process instance execution path at the management console, add the following add-on:

* *{PRODUCT} process SVG add-on*: Enables the process SVG diagram to visualize the process instance execution path. If this add-on is not enabled for your {PRODUCT} service, the management console does not display the diagram panel. For more information about the process SVG add-on, see xref:con-bpmn-process-svg-addon_kogito-developing-process-services[].

[id="proc-management-console-using_{context}"]
=== Using the {PRODUCT} Management Console to manage process instances

[role="_abstract"]
You can use the {PRODUCT} Management Console to view and manage process instance details from your {PRODUCT} services. You can run the Management Console for local {PRODUCT} services or add it to your {PRODUCT} infrastructure on {OPENSHIFT}.

.Prerequisites
* A {PRODUCT} Data Index Service instance is configured and running for your {PRODUCT} service. The Data Index Service enables the Management Console to access stored process data. The Data Index Service requires Infinispan or MongoDB persistence and Apache Kafka messaging for your {PRODUCT} service. For information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].
* The `pom.xml` file of your {PRODUCT} project contains the following dependency for the process management add-on. This add-on enables the Management Console to interact with the process data through the add-on REST endpoint `/management/processes`. For more information about the process management add-on, see xref:con-bpmn-process-management-addon_kogito-developing-process-services[].
+
.Project dependency to enable process management REST operations
[source,xml]
----
<dependency>
  <groupId>org.kie</groupId>
  <artifactId>kie-addons-quarkus-process-management</artifactId>
</dependency>
----
* The `application.properties` file of your {PRODUCT} project contains the following system properties for the location where the {PRODUCT} service is deployed, such as `\http://localhost:8080`, and for Quarkus Cross-Origin Resource Sharing (CORS) support. These properties enable the Management Console to generate the URLs to execute the REST operations from the process management add-on.
+
.Application properties for REST URLs
[source,subs="+quotes"]
----
kogito.service.url=http://__HOST__:__PORT__
quarkus.http.cors=true
----

.Procedure
. Go to the https://repository.jboss.org/org/kie/kogito/management-console/[`management-console`] artifacts page, select the latest release of the {PRODUCT} Management Console, and download the `management-console-__VERSION__-runner.jar` file to a local directory.
. In a command terminal, navigate to the directory location of the downloaded `management-console-__VERSION__-runner.jar` file and enter the following command to run the Management Console:
+
--
.Running the Management Console
[source,subs="+quotes"]
----
$ java -Dquarkus.http.port=8280 -jar management-console-__VERSION__-runner.jar
----

[NOTE]
====
The default port for the Management Console is 8080, but this example specifies port 8280 to avoid conflicts with the example {PRODUCT} service running at port 8080.

Also, the Management Console uses the default Data Index Service port 8180. If you modified this port in your Data Index Service instance, you must also modify the port in the Management Console properties by using the start-up property `-Dkogito.dataindex.http.url=http://__HOST__:__PORT__/graphql` when you run the Management Console.
====

To change the logging level of the Management Console, such as for debugging, you can specify the following start-up properties:

.Modifying Management Console logging level for debugging
[source,subs="+quotes"]
----
$ java  \
  -Dquarkus.log.console.level=DEBUG -Dquarkus.log.category.\"org.kie.kogito\".min-level=DEBUG  \
  -Dquarkus.log.category.\"org.kie.kogito\".level=DEBUG  \
  -Dquarkus.http.port=8280  \
  -jar management-console-__VERSION__-runner.jar
----
--

[id="proc-management-console-structure_{context}"]
=== {PRODUCT} Management Console application

{PRODUCT} Management Console consists of the following tabs that allow you to interact with your process instances and data:

* *Process Instances*: Use this tab to find process and subprocess instances by status or business key
* *Jobs*: Use this tab to view a list of available jobs to filter jobs by status and perform actions for individual jobs, such as view details, reschedule, or cancel.

.{PRODUCT} Management Console
image::kogito/bpmn/kogito-management-console.png[Image of Kogito Management Console]

In this example, the Management Console displays data for the `kogito-travel-agency` extended example application in the https://github.com/apache/incubator-kie-kogito-examples[`kogito-examples`] repository in GitHub.

[id="con-process-instances"]
==== Process instances

The *Process Instances* tab displays the list of process instances and enables you to add filters to the list.

.Process Instances tab
image::kogito/bpmn/kogito-management-console-process-instance-section.png[Image of process instance list section]

When you select a process instance on the *Process Instances* page, it redirects you to the *Process Details* page, providing the process instance details including interactions with the process instance. You can access the *Process Details* page from a different {PRODUCT} Management Console tab, displaying the instance related data and enables you to perform the available actions. You can also sort the results based on the column headers.

.Process Details page
image::kogito/bpmn/kogito-management-console-process-diagram.png[Image of Process Instance details in Management Console]

The *Process Details* page consists of the following panels:

* Process Diagram panel
* Details panel
* Process Variables panel
* Timeline panel
* Node Trigger panel
* Milestones panel
* Jobs panel


Process Diagram panel::
+
--
This panel enables you to explore the process diagram and execution path of the related process instance. The execution path is displayed when the Management Console finds the `.svg` resources using the {PRODUCT} process SVG add-on configuration included in the {PRODUCT} Management Console.

.Process Diagram panel
image::kogito/bpmn/kogito-management-console-process-diagram-panel.png[Image of process instance diagram panel]

This panel includes different controls to view the process diagram, such as *Selection*, *Pan*, *Zoom in*, *Zoom out*, and *Fit to viewer*.
--

Details panel::
+
--
This panel displays the basic process instance information and provides links to the related process runtime UI. If the process instance is related to other process instances, then links to the parent and subprocess instances are also available in the *Details* panel.

.Details panel
image::kogito/bpmn/kogito-management-console-details-panel.png[Image of process instance details panel]

The Details panel consists of the following fields:

* *Name*: The process definition ID related to the process instance.
* *Business key*: Optional business key of the process instance.
* *State*: The state of the process instance. The state of a process instance can be pending, active, completed, aborted, suspended, or error.
* *Id*: The unique identifier of the process instance.
* *Endpoint*: The endpoint of the process instance. You can click the displayed endpoint to view the process or application UI that triggered the process instance.
+
.Process instance details endpoint
image::kogito/bpmn/kogito-management-console-process-details-endpoint.png[Image of process instance details endpoint in Management Console]

* *Start*: Time reference indicating when the process instance is started.
* *Last Updated*: Time reference indicating when the process instance is updated.
* *End*: Time reference indicating when the process instance is completed.
* *Parent Process*: Parent process instance of the instance (if linked). You can click and navigate to the parent process instance.
* *Sub Processes*: Subprocess of the instance (if linked). You can click and navigate to the subprocess instances.
--

Process Variables panel::
+
--
The *Process Variables* panel displays the process instance domain data in a tree structure. When you hover the mouse on different elements, the available actions are displayed.

.Process Variables panel
image::kogito/bpmn/kogito-management-console-process-variable-panel.png[Image of process variables panel  in Management Console]

.Actions in Process Variables panel
image::kogito/bpmn/kogito-management-console-process-variable-actions.png[Image of process variables panel available actions in Management Console]

The process variables in the *Process Variables* panel consists of the following actions:

* Expand or collapse: Enables you to expand or collapse an element.
* Add item: Enables you to add a new key. When you add a new key, it contains null values, which you can edit if required.
+
.Add new key
image::kogito/bpmn/kogito-management-console-process-variable-add.png[Steps to add a new variable to a process instance in Management Console]

* Copy: Enables you to copy the selected value in clipboard.
* Edit: Enables you to edit the selected element value.
* Remove: Enables you to remove the selected element.

If there are pending changes to be saved, the panel displays *Changes are not saved yet* message. To save the changes that you made to the process variable, click *Save*, or click *Abort* to abort the changes. If you want to revert the changes, click the refresh icon.
--

Timeline panel::
+
--
The *Timeline* panel displays the list of node instances related to the process instance sorted by the start time. Each node consists of an icon, indicating the state of the node, such as active, completed, or error.

.Timeline panel
image::kogito/bpmn/kogito-management-console-process-timeline-panel.png[Image of Timeline panel showing the related node instances]

The actions that are available for an active node include retriggering and canceling a node. Whereas the actions for an error node include retrying and skipping the node. The node actions in the *Timeline* panel are connected with the {PRODUCT} runtime service to perform the requested action.

If a node in the *Timeline* panel is associated with a job, then select the clock icon to view the job details or click the menu for additional job operations, such as *Job Reschedule* or *Job Cancel*.
--

Node Trigger panel::
+
--
The *Node Trigger* panel displays the list of all process definition nodes in a drop-down. When you select a node, the related information is displayed, such as *Node name*, *Node type*, and *Node id*. Click the *Trigger* button, to trigger the selected node.

.Node Trigger panel
image::kogito/bpmn/kogito-management-console-node-trigger-panel.png[Image of node trigger panel in Management Console]
--

Milestones panel::
+
--
The *Milestones* panel displays a list of the milestones for the process instance, if applicable.

.Milestones panel
image::kogito/bpmn/kogito-management-console-milestones-panel.png[Image of milestones panel in Management Console]
--

Jobs panel::
+
--
The *Jobs* panel displays the list of available jobs that are related to the process instance.

.Jobs panel
image::kogito/bpmn/kogito-management-console-jobs-panel.png[Image of jobs panel in Management Console]

.Job details
image::kogito/bpmn/kogito-management-console-jobs-panel-details.png[Image of jobs panel details in Management Console]

You can reschedule or cancel a job that is in scheduled or error state. You can also modify the expiration time for one-time jobs and repeat interval, repeat time, and expiration time for the periodic jobs.
--

[id="con-jobs-management"]
==== Jobs management

The *Jobs Management* tab displays the list of existing jobs, which you can filter and perform related management actions such as viewing job details, rescheduling a job, or canceling a job.

.Jobs Management page
image::kogito/bpmn/kogito-management-console-jobs-management.png[Image of Jobs Management page in Management Console]

You can also cancel the multiple jobs at the same time. To cancel multiple jobs, select the jobs to be canceled and click the *Cancel Selected* button.

[id="proc-management-console-security_{context}"]
=== Configuring {PRODUCT} Management Console security

[role="_abstract"]
For security, the {PRODUCT} Management Console accesses Keycloak as an authentication service. Once a user is authenticated, Management Console uses bearer tokens to communicate with other {PRODUCT} services.The bearer tokens are issued using OpenID Connect and OAuth 2.0 compliant authorization servers such as https://www.keycloak.org/about.html[Keycloak].

IMPORTANT: This procedure applies only when you are using a locally cloned copy of the https://github.com/apache/incubator-kie-kogito-apps/tree/master/management-console[{PRODUCT} Management Console] repository in GitHub.

.Prerequisites
* You have cloned the https://github.com/apache/incubator-kie-kogito-apps/tree/master/management-console[{PRODUCT} Management Console] repository from GitHub.
* An instance of Keycloak server is running.

IMPORTANT: Ensure that you log in to the administration console of the Keycloak, navigate to the respective client configuration, and add correct URLs of different applications. For easier configuration, you can add `*`  in the *Web Origins*, however, it can cause security issues. You can also add the origin URLs as a parameter to the *Web Origins*, which can prevent the issues related to `Access-Control-Allow-Origin`.

image::kogito/bpmn/kogito-consoles-keycloak-config.png[Image of client config in keycloak server]

.Procedure
. In a command terminal, navigate to the local clone of the {PRODUCT} Management Console repository and enter the following command to run the application with security enabled:
+
--
.Run the Management Console with security enabled
[source]
----
mvn clean compile quarkus:dev
----

IMPORTANT: Ensure that the service is not started at the same port as the security server. You can change the port by adding `-Dquarkus.http.port=__PORT_NUMBER__` to the start-up properties.

--
. Navigate to the `src/main/resources/application.properties` file of the Management Console project and add the following properties:
+
--
.Required security properties in `applications.properties` file
[source]
----
# OpenID Connect configurations
kogito.consoles.keycloak.config.realm=kogito
kogito.consoles.keycloak.config.url=http://localhost:8280/auth/
kogito.consoles.keycloak.config.client-id=kogito-console-quarkus
kogito.consoles.keycloak.config.health-check-url=http://localhost:8280/auth/realms/kogito/.well-known/openid-configuration
kogito.consoles.keycloak.config.disable-health-check=false
kogito.consoles.keycloak.config.update-token-validity=30
----

--
. Replace any property definitions with those of your specific environment, especially the following properties:
+
* `kogito.consoles.keycloak.config.url`: The base URL of the Keycloak server, such as `https://localhost:8280/auth`. All other Keycloak server pages and service URLs are derived from the base URL.
* `kogito.consoles.keycloak.config.client-id`: The client ID of the application. Each application contains a client ID that is used to identify the application.
* `kogito.consoles.keycloak.config.realm`: The realm, containing all the security configurations.
* `kogito.consoles.keycloak.config.health-check-url`: The health check URL that is used to check if the Keycloak server started properly.
* `kogito.consoles.keycloak.config.disable-health-check`: The property to disable the health check. By default, the health check is enabled.
* `kogito.consoles.keycloak.config.update-token-validity`: The property indicates the minimum validity (in seconds) of the token. If the token expires within the specified time, the token is refreshed.

. In the same `application.properties` file, also configure the resources to be exposed and the required permissions for accessing the resources.
+

. Stop and restart the {PRODUCT} Management Console to ensure that the security changes are applied.

[role="_additional-resources"]
.Additional resources
* https://www.keycloak.org/documentation[Setting up and configuring keycloak server]
* https://www.keycloak.org/docs/latest/securing_apps/#_javascript_adapter[Using keycloak-js-adapter]
* https://quarkus.io/guides/security[Security Architecture and Guides]
* https://quarkus.io/guides/security-openid-connect#configuring-using-the-application-properties-file[Configuring using the application.properties file]
* https://quarkus.io/guides/security-openid-connect-multitenancy[Using OpenID Connect multi-tenancy]

[id="con-task-console_{context}"]
== {PRODUCT} Task Console

[role="_abstract"]
The {PRODUCT} Task Console is a user interface for viewing and interacting with user tasks in {PRODUCT} process services.

.{PRODUCT} Task Console
image::kogito/bpmn/kogito-task-console.png[Image of Kogito Task Console]

You can use the Task Console to view your list of assigned tasks, view the task details for each task, and move the task to the next phase of the task lifecycle. For more information about the task lifecycle, see xref:con-task-lifecycle_kogito-developing-process-services[].

The Task Console requires your {PRODUCT} services to use the {PRODUCT} Data Index Service. The Data Index Service enables the Task Console to access stored events related to tasks and domain data from your {PRODUCT} services. The {PRODUCT} Data Index Service requires Infinispan or MongoDB persistence and Apache Kafka messaging for your {PRODUCT} service. For more information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].

[id="proc-task-console-using_{context}"]
=== Using the {PRODUCT} Task Console to interact with user tasks

[role="_abstract"]
You can use the {PRODUCT} Task Console to view and interact with user tasks in {PRODUCT} process services. You can run the Task Console for local {PRODUCT} services or add it to your {PRODUCT} infrastructure on {OPENSHIFT}.

.Prerequisites
* A {PRODUCT} Data Index Service instance is configured and running for your {PRODUCT} service. The Data Index Service enables the Task Console to access stored tasks and process data. The Data Index Service requires Infinispan or MongoDB persistence and Apache Kafka messaging for your {PRODUCT} service. For information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].
* The `application.properties` file of your {PRODUCT} project contains the following system properties for the location where the {PRODUCT} service is deployed, such as `\http://localhost:8080`, and for Quarkus Cross-Origin Resource Sharing (CORS) support.
+
.Application properties for REST URLs
[source,subs="+quotes"]
----
kogito.service.url=http://__HOST__:__PORT__
quarkus.http.cors=true
----

.Procedure
. Go to the https://repository.jboss.org/org/kie/kogito/task-console/[`task-console`] artifacts page, select the latest release of the {PRODUCT} Task Console, and download the `task-console-__VERSION__-runner.jar` file to a local directory.
. In a command terminal, navigate to the directory location of the downloaded `task-console-__VERSION__-runner.jar` file and enter the following command to run the Task Console:
+
--
.Running the Task Console
[source,subs="+quotes"]
----
$ java -Dquarkus.http.port=8280 -jar task-console-__VERSION__-runner.jar
----

[NOTE]
====
The default port for the Task Console is 8080, but this example specifies port 8280 to avoid conflicts with the example {PRODUCT} service running at port 8080.

Also, the Task Console uses the default Data Index Service port 8180. If you modified this port in your Data Index Service instance, you must also modify the port in the Task Console properties by using the start-up property `-Dkogito.dataindex.http.url=http://__HOST__:__PORT__/graphql` when you run the Task Console.
====

To change the logging level of the Task Console, such as for debugging, you can specify the following start-up properties:

.Modifying Task Console logging level for debugging
[source,subs="+quotes"]
----
$ java  \
  -Dquarkus.log.console.level=DEBUG -Dquarkus.log.category.\"org.kie.kogito\".min-level=DEBUG  \
  -Dquarkus.log.category.\"org.kie.kogito\".level=DEBUG  \
  -Dquarkus.http.port=8280  \
  -jar task-console-__VERSION__-runner.jar
----

If your {PRODUCT} project has a custom task lifecycle that defines custom states, you can use the following properties to
configure the Task Console to use those states and show them in the filters:

* `kogito.task.states.list`: Comma-separated list of values containing all the states that you want to show in the Task Console.
Without this property, the Task Console shows the default lifecycle states `Ready`, `Reserved`, `Completed`, `Aborted`, and `Skipped`.
* `kogito.task.active.states.list`: Comma-separated list of values containing the active task states. These states are used in the *Task Inbox* default filter. Without this property, the default active states are `Ready` and `Reserved`.

.Configuring custom task states for the Task Console
[source,subs="+quotes"]
----
$ java  \
  -Dkogito.task.states.list=Started,Pending,Finished,Cancelled \
  -Dkogito.task.active.states.list=Started,Pending \
  -jar task-console-__VERSION__-runner.jar
----

NOTE: For more information about task lifecycles, see xref:con-task-lifecycle_kogito-developing-process-services[].

.{PRODUCT} Task Console
image::kogito/bpmn/kogito-task-console.png[Image of Kogito Task Console]

In this example, the Task Console displays data for the `kogito-travel-agency` extended example application in the https://github.com/apache/incubator-kie-kogito-examples[`kogito-examples`] repository in GitHub.

The *Task Inbox* page lists the available user tasks that you can interact with. You can use the upper toolbar options to filter the tasks or use the column headers to sort the tasks as needed. You can also search for tasks by the full name or by partial name, such as `Apply`.

.Tasks assigned to the current user
image::kogito/bpmn/kogito-task-console-inbox.png[Image of the tasks assigned to the current user]

.Available task status filters
image::kogito/bpmn/kogito-task-console-filters-status.png[Image of status filtering on *Task Inbox*]

.Applied filters
image::kogito/bpmn/kogito-task-console-filters.png[Image of status and names filtering on *Task Inbox*]
--
. Select a task name to view task details and interact with the task:
+
--
.Task details
image::kogito/bpmn/kogito-task-console-details-page.png[Image of *Task Details* page]

Depending on the current phase of the selected task, you can select from the available actions for that task, such as *Abort*, *Release*, *Skip*, or *Complete*, to move the task to the next phase.

For additional task details, you can select *View details*. This panel lists the task ID, state, owner, related process instance ID, and other helpful information about the task.

.Task details panel
image::kogito/bpmn/kogito-task-console-details-expanded.png[Image of task details panel]
--

[id="proc-task-console-security_{context}"]
=== Configuring {PRODUCT} Task Console security

[role="_abstract"]
For security, {PRODUCT} Task Console accesses Keycloak as an authentication service. Once a user is authenticated, Task Console uses bearer tokens to communicate with other {PRODUCT} services. These tokens are issued by OpenID Connect and OAuth 2.0 compliant authorization servers such as https://www.keycloak.org/about.html[Keycloak].

IMPORTANT: This procedure applies only when you are using a locally cloned copy of the https://github.com/apache/incubator-kie-kogito-apps/tree/master/task-console[{PRODUCT} Task Console] repository in GitHub.

.Prerequisites
* You have cloned the https://github.com/apache/incubator-kie-kogito-apps/tree/master/task-console[{PRODUCT} Task Console] repository from GitHub.
* An instance of Keycloak server is running.

IMPORTANT: Ensure that you log in to the administration console of the Keycloak, navigate to the respective client configuration, and add correct URLs of different applications. For easier configuration, you can add `*`  in the *Web Origins*, however, it can cause security issues. You can also add the origin URLs as a parameter to the *Web Origins*, which can prevent the issues related to `Access-Control-Allow-Origin`.

image::kogito/bpmn/kogito-consoles-keycloak-config.png[Image of client config in keycloak server]

.Procedure
. In a command terminal, navigate to the local clone of the {PRODUCT} Task Console repository and enter the following command to run the application with security enabled:
+
--
.Run the Task Console with security enabled
[source]
----
mvn clean compile quarkus:dev
----

IMPORTANT: Ensure that the service is not started at the same port as the security server. You can change the port by adding `-Dquarkus.http.port=__PORT_NUMBER__` to the start-up properties.

--
. Navigate to the `src/main/resources/application.properties` file of the Task Console project and add the following properties:
+
--
.Required security properties in `applications.properties` file
[source]
----
# OpenID Connect configurations
kogito.consoles.keycloak.config.realm=kogito
kogito.consoles.keycloak.config.url=http://localhost:8280/auth/
kogito.consoles.keycloak.config.client-id=kogito-console-quarkus
kogito.consoles.keycloak.config.health-check-url=http://localhost:8280/auth/realms/kogito/.well-known/openid-configuration
kogito.consoles.keycloak.config.disable-health-check=false
kogito.consoles.keycloak.config.update-token-validity=30
----

--
. Replace any property definitions with those of your specific environment, especially the following properties:
+
* `kogito.consoles.keycloak.config.url`: The base URL of the Keycloak server, such as `https://localhost:8280/auth`. All other Keycloak server pages and service URLs are derived from the base URL.
* `kogito.consoles.keycloak.config.client-id`: The client ID of the application. Each application contains a client ID that is used to identify the application.
* `kogito.consoles.keycloak.config.realm`: The realm, containing all the security configurations.
* `kogito.consoles.keycloak.config.health-check-url`: The health check URL that is used to check if the Keycloak server started properly.
* `kogito.consoles.keycloak.config.disable-health-check`: The property to disable the health check. By default, the health check is enabled.
* `kogito.consoles.keycloak.config.update-token-validity`: The property indicates the minimum validity (in seconds) of the token. If the token expires within the specified time, the token is refreshed.

. In the same `application.properties` file, also configure the resources to be exposed and the required permissions for accessing the resources.
+

. Stop and restart the {PRODUCT} Task Console to ensure that the security changes are applied.

[role="_additional-resources"]
.Additional resources
* https://www.keycloak.org/documentation[Setting up and configuring keycloak server]
* https://www.keycloak.org/docs/latest/securing_apps/#_javascript_adapter[Using keycloak-js-adapter]
* https://quarkus.io/guides/security[Security Architecture and Guides]
* https://quarkus.io/guides/security-openid-connect#configuring-using-the-application-properties-file[Configuring using the application.properties file]
* https://quarkus.io/guides/security-openid-connect-multitenancy[Using OpenID Connect multi-tenancy]

[id="con-runtime-tools-dev-ui_{context}"]
== Runtime Tools Quarkus Extension

In {PRODUCT}, Runtime Tools Quarkus Extension helps in developing your {PRODUCT} applications in Quarkus. This extension adds a new user interface with unified features from the different {PRODUCT} Management Console and Task Console, which is accessible in the Quarkus Dev UI. This is intended for the local development environment, can be integrated with Quarkus applications, and allows you to test the {PRODUCT} application without the need of a complex setup.

=== Setting up the Runtime Tools Quarkus Extension

Quarkus Dev UI shows a list of extensions that you can add to your project.

.Procedure

. To enable the Runtime Tools Quarkus extension from your Quarkus project, you must add the following dependency to the `pom.xml` file:
+
--
.Dependency to access {PRODUCT} Runtime Tools Dev UI in Quarkus
[source,xml,subs="attributes+"]
----
<dependency>
    <groupId>org.jbpm</groupId>
    <artifactId>jbpm-quarkus-devui</artifactId>
    <version>{COMMUNITY_VERSION_FINAL}</version>
</dependency>
----
--

. Add the following properties to the `application.properties` file to configure the users and impersonate the users on the task page using the dropdown at the top:
+
--
* `kogito.users.<user>.groups`: This property creates a list of users and assigns specific roles to the users

[source]
----
kogito.users.jdoe.groups=admin
kogito.users.admin.groups=admin
kogito.users.user.groups=user
----
--

=== Accessing Runtime Tools Quarkus Extension

After setting up the Runtime Tools Quarkus Extension, you can access the Quarkus extension in your project.

.Procedure
. To access the Quarkus extension, run your project in development mode and select the `http://localhost:8080/q/dev` URL:
+
--
.Quarkus Dev UI
image::kogito/bpmn/quarkus-dev-ui.png[Image of quarkus dev ui]

The Quarkus extension consists of different menus to navigate to different pages, such as Configuration, Kogito Runtime Tools, and Infinispan Client. Using the *{PRODUCT} Runtime Tools* menu, you can navigate to *Process Instances*, *Tasks*, *Jobs*, and *Forms*. The features are similar to {PRODUCT} Management Console and Task Console.

.{PRODUCT} Runtime Tools Dev UI for Quarkus
image::kogito/bpmn/kogito-runtime-tools-dev-ui-card.png[align="center"][Image of menus in Quarkus extension]

* *Process Instances*: Use this section to view process and subprocess instances by status or business key. For more details, see xref:con-process-instances[].
* *Jobs*: Use this section to view a list of available jobs. You can also filter the jobs by status and perform different actions, such as view details, reschedule, or cancel. For more details, see xref:proc-jobs-management[].
* *Tasks*: Use this section to view the list of available user tasks that you can interact with by filtering based on the status. For more details, see xref:con-task-console_kogito-developing-process-services[].
* *Forms*: Use this section to generate and customize the forms directly in the browser.
--

=== Forms

The {PRODUCT} Quarkus extension enables you to customize the forms directly on the browser by using the dedicated code editor, which can compile HTML code and React code that is written in Typescript. You can use Patternfly components to create React forms. These customized forms are used in Task Inbox.

The Forms page in the Dev UI contains a list of generated forms in a project. To switch between the table view and gallery view, select the toggle on the top-right corner of the page. You can also filter the list of forms by entering the form name.

.Forms in {PRODUCT} Runtime tools Dev UI
image::kogito/bpmn/forms-pages-table-view.png[Image of forms in Dev UI table view]

When you select a form in the *Forms* page, you are redirected to the form displayer. The form displayer contains a code editor, which compiles the source code and displays the results on the right-side panel.

Initially, the form content and the related configuration are added to the code editor. You can make changes to the code in the editor and click the play icon from the toolbar to execute the code immediately on the browser.

The *Source* tab loads the source code of the form in HTML or Typescript format based on the selected form. When the configurations of a form are loaded on the *Connections* tab, a set of resources including CDN links, URLs pointing to JS or CSS files are added to the form.

.Form source in code editor
image::kogito/bpmn/runtime-tools-dev-ui-code-editor.png[Image of form displayer source code editor]

.Form cofigurations in code editor
image::kogito/bpmn/runtime-tools-dev-ui-code-editor-configurations.png[Image of form displayer configuration code editor]

The code editor contains toolbar options, which allow you to undo and redo changes. Clicking on the play button executes the code and changes are applied immediately, while the save option allows you to save the changes on the source or configuration of the forms.

.Toolbar options in code editor
image::kogito/bpmn/runtime-tools-dev-ui-code-editor-toolbar.png[Image of code editor toolbar options]

include::../dmn/chap-kogito-using-dmn-models.adoc[tags=con-kogito-service-execution]

[role="_additional-resources"]
== Additional resources
* {URL_CREATING_RUNNING}[{CREATING_RUNNING}]
* {URL_DECISION_SERVICES}[{DECISION_SERVICES}]
* {URL_CONFIGURING_KOGITO}[{CONFIGURING_KOGITO}]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
