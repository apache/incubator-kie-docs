[id='environment-authoring-con_{context}'] 
ifdef::PAM[]
= Authoring environment
You can deploy an environment for creating and modifying processes using {CENTRAL}. It consists of {CENTRAL} for the authoring work and {KIE_SERVER} for test execution of the processes. If necessary, you can connect additional {KIE_SERVERS} to the {CENTRAL}.

endif::PAM[]
ifdef::DM[]
= Authoring or managed server environment
You can deploy an environment for creating and modifying services using {CENTRAL} and for running them in {KIE_SERVERS} managed by {CENTRAL}. This environment consists of {CENTRAL} and one or more {KIE_SERVERS}.

You can use {CENTRAL} both to develop services and to deploy them to {KIE_SERVERS}. You can connect several {KIE_SERVERS} to one {CENTRAL} to manage deployment of services to each of the servers.

If necessary, you can create separate environments, so that you can use one deployment of {CENTRAL} to author services (_authoring environment_) and another deployment of {CENTRAL} to manage deployment of staging or production services on several {KIE_SERVERS} (_managed server environment_). Usually, one {KIE_SERVER} is sufficient for a dedicated authoring environment. You can use an external Maven repository to store services from an authoring environment and deploy them to a separate managed server environment.

For {PRODUCT}, the procedures to deploy an authoring environment and a managed server environment are the same. You must first deploy an authoring environment template, consisting of {CENTRAL} and one {KIE_SERVER}.

If necessary, you can deploy additional {KIE_SERVER} templates in the same namespace to create an environment with multiple {KIE_SERVERS}. This environment can be a managed server environment for staging and production deployment of services.

endif::DM[]

Depending on your needs, you can deploy either a single authoring environment template or a high-availability (HA) authoring environment template.

A single authoring environment contains two pods. One of the pods runs {CENTRAL}, the other runs {KIE_SERVER}.
ifdef::PAM[The {KIE_SERVER} by default includes an embedded H2 database engine.]
This environment is most suitable for single-user authoring or when your OpenShift infrastructure has limited resources. It does not require persistent volumes that support the `ReadWriteMany` access mode.

In a single authoring environment, you cannot scale {CENTRAL}.
ifdef::PAM[]
By default, you also cannot scale {KIE_SERVER}, as the H2 database engine does not support scaling. However, you can modify the template to use a separate MySQL or PostgreSQL database server pod; in this case, you can scale {KIE_SERVER}. For instructions about modifying the single authoring environment template, see xref:environment-authoring-single-modify-proc_{context}[].
endif::PAM[]
ifdef::DM[]
You can scale {KIE_SERVER}.
endif::DM[]

In an HA authoring environment, both {CENTRAL} and {KIE_SERVER} are provided in scalable pods. When pods are scaled, persistent storage is shared between the copies.
ifdef::PAM[The database is provided by a separate pod.]

To enable high-availability functionality in {CENTRAL}, additional pods with AMQ and Data Grid are required. These pods are configured and deployed by the high-availability authoring template. Use a high-availability authoring environment to provide maximum reliability and responsiveness, especially if several users are involved in authoring at the same time.

In the current version of {PRODUCT}, an HA authoring environment is supported with certain limitations:

* If a {CENTRAL} pod crashes while a user works with it, the user can get an error message and then is redirected to another pod. Logging on again is not required.

* If a {CENTRAL} pod crashes during a user operation, data that was not committed (saved) might be lost.

* If a {CENTRAL} pod crashes during creation of a project, an unusable project might be created.

* If a {CENTRAL} pod crashes during creation of an asset, the asset might be created but not indexed, so it cannot be used. The user can open the asset in {CENTRAL} and save it again to make it indexed.

* When a user deploys a service to the {KIE_SERVER}, the {KIE_SERVER} deployment is rolled out again. Users can not deploy another service to the same {KIE_SERVER} until the roll-out completes.

In a high-availability authoring environment you can also deploy additional managed or immutable {KIE_SERVERS}, if required. {CENTRAL} can automatically discover any {KIE_SERVERS} in the same namespace, including immutable {KIE_SERVERS} and managed {KIE_SERVERS}.

If you want to deploy additional managed or immutable {KIE_SERVERS} in a single authoring environment, you must complete an additional manual step to enable the `OpenShiftStartupStrategy` setting in the environment, as described in xref:startupstrategy-enable-proc_{context}[]]. This setting enables the discovery of other {KIE_SERVERS}.

ifdef::DM[]
For instructions about deploying managed {KIE_SERVERS}, see xref:additional-server-managed-deploy-assy_{context}[].
endif::DM[]
ifdef::PAM[]
For instructions about deploying managed {KIE_SERVERS}, see xref:freeform-server-managed-deploy-assy_{context}[].
endif::PAM[]

// For the following line the xref syntax causes a problem for some reason
For instructions about deploying immutable {KIE_SERVERS}, see <<server-immutable-s2i-deploy-assy_{context}>> and <<server-immutable-kjar-deploy-assy_{context}>>.
