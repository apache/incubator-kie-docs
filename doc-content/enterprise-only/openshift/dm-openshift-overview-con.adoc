[id='dm-openshift-overview-con']
= Overview

If you have an OpenShift environment, you can deploy {PRODUCT} into this environment instead of a regular on-premises deployment.

In this solution, {KIE_SERVER} is deployed as an OpenShift pod. You can scale the pod up and down, providing as few or as many containers as necessary. You can use all standard OpenShift methods to manage the pod, balance the load, and deploy new versions.

You can also deploy {CENTRAL} on the OpenShift infrastructure together with {KIE_SERVER}. In this case, you can use {CENTRAL} to manage the {KIE_SERVER} and to develop new rules.

Alternatively, you can deploy {KIE_SERVER} without {CENTRAL}. To manage {KIE_SERVER} in this case, you have several options:

* Use the _source to image_ (S2I) template and provide a Git repository with the source of your decision service. OpenShift automatically builds the source, installs the decision service into the {KIE_SERVER} image, and starts the service. You do not need to manage the {KIE_SERVER}. If you want to use a new version of the decision service, you can build a new image. This option is often preferable for typical integration approaches in a containerized infrastructure.

* Configure the {KIE_SERVER} to load the service automatically from a Maven repository.

* Use an instance of {CENTRAL}, a {CONTROLLER}, or the REST API to manage the {KIE_SERVER}.

IMPORTANT: All calls to a {KIE_SERVER} that runs on OpenShift must be stateless. While the server accepts stateful calls, the state might not be saved between calls, because the server can be scaled to multiple containers or might be restarted by OpenShift automatically.
