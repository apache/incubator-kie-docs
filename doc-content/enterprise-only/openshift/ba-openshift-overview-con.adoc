[id='ba-openshift-overview-con']
= Overview of {PRODUCT} on {OPENSHIFT}
You can deploy {PRODUCT} into a {OPENSHIFT} environment.

In this solution, components of {PRODUCT} are deployed as separate OpenShift pods. You can scale each of the pods up and down individually, providing as few or as many containers as necessary for a particular component. You can use standard OpenShift methods to manage the pods and balance the load.

The following key components of {PRODUCT} are available on OpenShift:

* {KIE_SERVER}, also known as _Execution Server_ or _KIE Server_, is the infrastructure element that runs decision 
ifdef::DM[]
services
endif::DM[]
ifdef::PAM[]
services, process applications,
endif::PAM[] 
and other deployable assets (collectively referred to as _services_) . All logic of the services runs on execution servers.
ifdef::PAM[]
+
A database server is normally required for {KIE_SERVER}. You can provide a database server in another OpenShift pod or configure an execution server on OpenShift to use any other database server. Alternatively, {KIE_SERVER} can use an H2 database; in this case, the pod cannot be scaled. 
endif::PAM[]
+
You can freely scale up a {KIE_SERVER} pod, providing as many copies as necessary, running on the same host or different hosts. As you scale a pod up or down, all its copies 
ifdef::PAM[use the same database server and]
run the same services. OpenShift provides load balancing and a request can be handled by any of the pods.
+
You can deploy a separate {KIE_SERVER} pod to run a different group of services. That pod can also be scaled up or down. You can have as many separate replicated {KIE_SERVER} pods as necessary.
+
* {CENTRAL} is a web-based interactive environment for authoring services. It also provides a management
ifdef::PAM[and monitoring]
console. You can use {CENTRAL} to develop services and deploy them to {KIE_SERVERS}.
ifdef::PAM[You can also use {CENTRAL} to monitor the execution of processes.]
+
{CENTRAL} is a centralized application. However, you can configure it for high availability, where multiple pods run and share the same data.
+
{CENTRAL} includes a Git repository that holds the source for the services that you develop on it. It also includes a built-in Maven repository. Depending on configuration, {CENTRAL} can place the compiled services (KJAR files) into the built-in Maven repository or (if configured) into an external Maven repository.
+
[IMPORTANT]
====
In the current version, high-availability {CENTRAL} functionality is for Technology Preview only. For more information on Red Hat Technology Preview features, see https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Scope].
====
ifdef::PAM[]
+
* {CENTRAL} Monitoring is a web-based management and monitoring console. It can manage deployment of services to {KIE_SERVERS} and provide monitoring information, but does not include authoring capabilities. You can use this component to manage staging and production environments.
+
* Smart Router is an optional layer between {KIE_SERVERS} and other components that interact with them. It is required if you want {CENTRAL} or {CENTRAL} Monitoring to interact with several different {KIE_SERVERS}. Also, when your environment includes many services running on different {KIE_SERVERS}, Smart Router provides a single endpoint to all client applications. A client application can make a REST API call requiring any service. Smart Router automatically determines which {KIE_SERVER} must be called for any particular request.
endif::PAM[]

You can arrange these and other components into various environment configurations within OpenShift. 

ifeval::["{context}"=="openshift-freeform"]
A freeform server environment can include any number of {KIE_SERVERS} to run existing services for staging and production purposes. You can use {CENTRAL} Monitoring to deploy, run, and stop the services and to monitor their execution. You can also build the services into the server images, making the images immutable, so that you do not need to manage the execution; monitoring is still available.
endif::[]

ifeval::["{context}"!="openshift-operator"]
ifeval::["{context}"!="openshift-freeform"]
The following environment types are typical:
  
ifdef::PAM[]
* _Authoring_: An environment for creating and modifying services using {CENTRAL}. It consists of pods that provide {CENTRAL} for the authoring work and a {KIE_SERVER} for test execution of the services. 
ifeval::["{context}"!="openshift-ansible-playbook"]
For instructions about deploying this environment, see {URL_DEPLOYING_AUTHORING_ON_OPENSHIFT}[_{DEPLOYING_AUTHORING_ON_OPENSHIFT}_].
endif::[]
* _Managed deployment_: An environment for running existing services for staging and production purposes. This environment includes several groups of {KIE_SERVER} pods; you can deploy and undeploy services on every such group and also scale the group up or down as necessary. Use {CENTRAL} Monitoring to deploy, run, and stop the services and to monitor their execution. 
ifeval::["{context}"!="openshift-ansible-playbook"]
For instructions about deploying this environment, see {URL_DEPLOYING_MANAGED_ON_OPENSHIFT}[_{DEPLOYING_MANAGED_ON_OPENSHIFT}_]. 
endif::[]
endif::PAM[]
ifdef::DM[]
* _Authoring or managed environment_: An environment architecture that can be used for creating and modifying services using {CENTRAL} and also for running services on {KIE_SERVERS}. It consists of pods that provide {CENTRAL} for the authoring work and one or more {KIE_SERVERS} for execution of the services. Each {KIE_SERVER} is a pod that you can replicate by scaling it up or down as necessary. You can deploy and undeploy services on each {KIE_SERVER} using {CENTRAL}.
ifeval::["{context}"!="openshift-ansible-playbook"]
For instructions about deploying this environment, see {URL_DEPLOYING_AUTHORING_MANAGED_ON_OPENSHIFT}[_{DEPLOYING_AUTHORING_MANAGED_ON_OPENSHIFT}_].
endif::[]
endif::DM[]
* _Deployment with immutable servers_: An alternate environment for running existing services for staging and production purposes. In this environment, when you deploy a {KIE_SERVER} pod, it builds an image that loads and starts a service or group of services. You cannot stop any service on the pod or add any new service to the pod. If you want to use another version of a service or modify the configuration in any other way, you deploy a new server image and displace the old one. In this system, the {KIE_SERVER} runs like any other pod on the OpenShift environment; you can use any container-based integration workflows and do not need to use any other tools to manage the pods. 
ifdef::PAM[]
Optionally, you can use {CENTRAL} Monitoring to monitor the performance of the environment and to stop and restart some of the service instances, but not to deploy additional services to any {KIE_SERVER} or undeploy any existing ones (you can not add or remove containers). 
endif::PAM[]
ifeval::["{context}"!="openshift-ansible-playbook"]
For instructions about deploying this environment, see {URL_DEPLOYING_IMMUTABLE_ON_OPENSHIFT}[_{DEPLOYING_IMMUTABLE_ON_OPENSHIFT}_].
endif::[]

You can also deploy a _trial_ or evaluation environment. This environment includes {CENTRAL} and a {KIE_SERVER}. You can set it up quickly and use it to evaluate or demonstrate developing and running assets. However, the environment does not use any persistent storage, and any work you do in the environment is not saved.
ifeval::["{context}"!="openshift-ansible-playbook"]
For instructions about deploying this environment, see {URL_DEPLOYING_TRIAL_ON_OPENSHIFT}[_{DEPLOYING_TRIAL_ON_OPENSHIFT}_].
endif::[]

ifeval::["{context}"!="openshift-ansible-playbook"]
To deploy a {PRODUCT} environment on OpenShift, you can use the templates that are provided with {PRODUCT}. 
ifdef::PAM[You can modify the templates to ensure that the configuration suits your environment.]
endif::[]
ifeval::["{context}"=="openshift-ansible-playbook"]
You can use the Automation Broker with the {PRODUCT} Ansible Playbook to deploy a {PRODUCT} environment on OpenShift in interactive mode. You can set all possible configuration values during this procedure. During the installation, the Automation Broker can generate all the required secrets automatically. However, for production environments, you need to create correct secrets before the installation.
endif::[]
endif::[]
endif::[]
