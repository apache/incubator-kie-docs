[id='architecture-authoring-con-{context}']
= Architecture of an authoring environment

In {PRODUCT}, the {CENTRAL} component provides a web-based interactive user interface for authoring services. The {KIE_SERVER} component runs the services. 

ifdef::PAM[]
The {KIE_SERVER} uses a database server to store the state of process services. 
endif::PAM[]


You can also use {CENTRAL} to deploy the services that you develop onto a {KIE_SERVER}.  You can use several {KIE_SERVERS} to run different services and control the servers from the same {CENTRAL}.

[float]
== Single authoring environment

In a single authoring environment, only one instance of {CENTRAL} is running. Multiple users can access its web interface at the same time, however the performance can be limited and there is no failover capability.

{CENTRAL} includes a built-in Maven repository that stores the built versions of the services that you develop (KJAR files/artifacts). You can use your continuous integration and continuous deployment (CICD) tools to retrieve these artifacts from the repository and move them as necessary.

{CENTRAL} stores the source code in a built-in Git repository, stored in the `.niogit` directory. It uses a built-in indexing mechanism to index the assets in your services.

{CENTRAL} uses persistent storage for the Maven repository and for the Git repository.

A single authoring environment, by default, includes one {KIE_SERVER}. 
ifdef::PAM[]
This {KIE_SERVER} uses a built-in H2 database engine to store the state of process services. 
endif::PAM[]

ifeval::["{context}"!="openshift-operator"]
A single authoring environment, by default, uses the _controller strategy_.
endif::[]
ifeval::["{context}"=="openshift-operator"]
A single authoring environment can use the _controller strategy_.
endif::[]
{CENTRAL} includes the _Controller_, a component that can manage {KIE_SERVERS}. When you configure a {KIE_SERVER} to connect to {CENTRAL}, the {KIE_SERVER} uses a REST API to connect to the Controller. This connection opens a persistent WebSocket. In an OpenShift deployment that uses the controller strategy, each {KIE_SERVER} is initially configured to connect to the {CENTRAL} Controller. 

When you use the {CENTRAL} user interface to deploy or manage a service on the {KIE_SERVER}, the {KIE_SERVER} receives the request through the Controller connection WebSocket. To deploy a service, the {KIE_SERVER} requests the necessary artifact from the Maven repository that is a part of {CENTRAL}. 

Client applications use a REST API to use services that run on the {KIE_SERVER}.

.Architecture diagram for a single authoring environment
ifdef::PAM[]
image::Overview/architecture-authoring-nonha.png[]
endif::PAM[]
ifdef::DM[]
image::Overview/architecture-authoring-nonha-dm.png[]
endif::DM[]

[float]
== Clustering {KIE_SERVERS} and using multiple {KIE_SERVERS}

You can scale a {KIE_SERVER} pod to run a clustered {KIE_SERVER} environment.
ifdef::PAM[]
To scale a {KIE_SERVER}, you must ensure that it uses a database server in a separate pod or an external database server, and not a built-in H2 database engine.
endif::PAM[]

In a clustered deployment, several instances of the {KIE_SERVER} run the same services. These servers can connect to the {CENTRAL} Controller using the same server ID, so they can receive the same requests from the controller. {OPENSHIFT} provides load-balancing between the servers. 
ifdef::PAM[]
Decision services and business optimizer services that run on a clustered {KIE_SERVER} 
endif::PAM[]
ifdef::DM[]
The services that run on a clustered {KIE_SERVER}
endif::DM[]
must be stateless, because requests from the same client might be processed by different instances.

You can also deploy several independent {KIE_SERVERS} to run different services. In this case, the servers connect to the {CENTRAL} Controller with different server ID values. You can use the {CENTRAL} UI to deploy services to each of the servers.

[float]
== Smart Router

The optional Smart Router component provides a layer between client applications and {KIE_SERVERS}. It can be useful if you are using several independent {KIE_SERVERS}.

The client application can use services running on different {KIE_SERVERS}, but always connects to the Smart Router. The Smart Router automatically passes the request to the {KIE_SERVERS} that runs the required service. The Smart Router also enables management of service versions and provides an additional load-balancing layer.

[float]
== High-availability authoring environment

In a high-availability (HA) authoring environment, the {CENTRAL} pod is scaled, so several instances of {CENTRAL} are running. {OPENSHIFT} provides load balancing for user requests. This environment provides optimal performance for multiple users and supports failover.

Each instance of {CENTRAL} includes the Maven repository for the built artifacts and uses the `.niogit` Git repository for source code. The instances use shared persistent storage for the repositories. A persistent volume with `ReadWriteMany` access is required for this storage.

An instance of Red Hat DataGrid provides indexing of all projects and assets developed in {CENTRAL}.

An instance of Red Hat AMQ propagates Java CDI messages between all instances of {CENTRAL}. For example, when a new project is created or when an asset is locked or modified on one of the instances, this information is immediately reflected in all other instances.

The controller strategy is not suitable for clustered deployment. In an OpenShift deployment, a high-availability {CENTRAL} must manage {KIE_SERVERS} using the _OpenShift startup strategy_.

Each {KIE_SERVER} deployment (which can be scaled) creates a ConfigMap that reflects its current state. The {CENTRAL} discovers all {KIE_SERVERS} by reading their ConfigMaps.

When the user requests a change in {KIE_SERVER} configuration (for example, deploys or undeploys a service), {CENTRAL} initiates a connection to the {KIE_SERVER} and sends a REST API request. The {KIE_SERVER} changes the ConfigMap to reflect the new configuration state and then triggers its own redeployment, so that all instances are redeployed and reflect the new configuration.

You can deploy several independent {KIE_SERVERS} in your OpenShift environment. Each of the {KIE_SERVERS} has a separate ConfigMap with the necessary configuration. You can scale each of the {KIE_SERVERS} separately.

You can include Smart Router in the OpenShift deployment. 

.Architecture diagram for a high-availability authoring environment
ifdef::PAM[]
image::Overview/architecture-authoring-ha.png[]
endif::PAM[]
ifdef::DM[]
image::Overview/architecture-authoring-ha-dm.png[]
endif::DM[]
