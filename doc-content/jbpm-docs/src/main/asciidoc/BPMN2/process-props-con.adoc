[id='process-props']

[[_process_properties]]
= Process properties
Every process has the following properties:

* *ID*: The unique ID of the process.
* *Name*: The display name of the process.
* *Version*: The version number of the process.
* *Package*: The package (namespace) the process is defined in.
* *Variables* (optional): Variables to store data during the execution of your process.
* *Swimlanes*: Swimlanes used in the process for assigning human tasks.

= Data
Throughout the execution of a process, data can be retrieved, stored, passed on, and used. To store runtime data during the execution of the process, process variables are used. A variable is defined with a name and a data type. A basic data type could include the following: boolean, int, String, or any kind of object subclass.

Variables can be defined inside a variable scope. The top-level scope is the variable scope of the process itself. Sub-scopes can be defined using a sub-process. Variables that are defined in a sub-scope are only accessible for nodes within that scope.

Whenever a variable is accessed, the process will search for the appropriate variable scope that defines the variable. Nesting variable scopes are allowed. A node will always search for a variable in its parent container; if the variable cannot be found, the node will look in the parent's parent container, and so on, until the process instance itself is reached. If the variable cannot be found, a read access yields null, and a write access produces an error message. All of this occurs with the process continuing execution.

Variables can be used in the following ways:

* Process-level variables can be set when starting a process by providing a map of parameters to the invocation of the startProcess method. These parameters will be set as variables on the process scope.

* Script actions can access variables directly simply by using the name of the variable as a local parameter in their script. For example, if the process defines a variable of type "org.jbpm.Person" in the process, a script in the process could access this directly:
+
[source,java]
----
// call method on the process variable "person"

person.setAge(10);
----
+
Changing the value of a variable in a script can be done through the knowledge context:
+
[source,java]
----
kcontext.setVariable(variableName, value);
----
+
[WARNING]
====
Do not create a script variable with the same name as a process variable. Otherwise, an error similar to the following error is thrown during the deployment of your application. In the following case, the variable `person` has been declared both in a script task and as a process variable.

[source]
----
ERROR [org.drools.compiler.kie.builder.impl.AbstractKieModule] (default task-16) Unable to build KieBaseModel:defaultKieBase
Process Compilation error : Process com.myteam.scripttask.ScriptTaskBP(ScriptTask.ScriptTaskBP)
	com/myteam/scripttask/Process_com$u46$myteam$u46$scripttask$u46$ScriptTaskBP95786628.java (9:437) : Duplicate local variable person
----
====

* Service tasks (and reusable sub-processes) can pass the value of process variables to the outside world (or another process instance) by mapping the variable to an outgoing parameter. For example, the parameter mapping of a service task could define that the value of the process variable `x` should be mapped to a task parameter `y` just before the service is invoked. You can also inject the value of the process variable into a hard-coded parameter String using `#{expression}`. For example, the description of a human task could be defined as the following:
+
[source]
----
You need to contact person #{person.getName()}
----
+
Where `person` is a process variable. This will replace this expression with the actual name of the person when the service needs to be invoked. Similar results of a service (or reusable sub-process) can also be copied back to a variable using result mapping.

* Various other nodes can also access data. Event nodes, for example, can store the data associated to the event in a variable. Check the properties of the different node types for more information.


Finally, processes (and rules) have access to globals, for example, globally defined variables and data in the Knowledge Session. Globals are directly accessible in actions like variables. Globals need to be defined as part of the process before they can be used. Globals can be set using the following:

[source,java]
----
ksession.setGlobal(name, value)
----

Globals can also be set from inside process scripts using:

[source,java]
----
kcontext.getKieRuntime().setGlobal(name,value);.
----

[[_data1]]
== Variables
Variables are elements that serve for storing a particular type of data during runtime. The type of data a variable contains is defined by its data type.

Just like any context data, every variable has its scope that defines its "visibility". An element, such as a process, sub-process, or task can only access variables in its own and parent contexts: variables defined in the element's child elements cannot be accessed. Therefore, when an elements requires access to a variable on runtime, its own context is searched first. If the variable cannot be found directly in the element's context, the immediate parent context is searched. The search continues to "level up" until the process context is reached; in case of globals, the search is performed directly on the session container. If the variable cannot be found, a read access request returns `null` and a write access produces an error message, and the process continues its execution. Variables are searched for based on their ID.

In {PRODUCT}, variables can live in the following contexts:

* _Session context_: `Globals` are visible to all process instances and assets in the given session and are intended to be used primarily by business rules and by constrains. The are created dynamically by the rules or constrains.
* _Process context_: `Process variables` are defined as properties in the BPMN2 definition file and are visible within the process instance. They are initialized at process creation and destroyed on process finish.
* _Element context_: `Local variables` are available within their process element, such as an activity. They are initialized when the element context is initialized, that is, when the execution workflow enters the node and execution of the `OnEntry` action finished if applicable. They are destroyed when the element context is destroyed, that is, when the execution workflow leaves the element.
+
Values of local variables can be mapped to global or process variables using the assignment mechanism (see <<_assignment1>>). This allows you to maintain relative independence of the parent element that accommodates the local variable. Such isolation may help prevent technical exceptions.

[[_assignment1]]
== Assignment
The assignment mechanism allows you to assign a value to an object, such as a variable, before or after the particular element is executed.

When defining assignment on an activity element, the value assignment is performed either before or after activity execution. If the assignment defines mapping to a local variable, the time when the assignment is performed depends on whether the local variable is defined as an `DataInput` or `DataOutput` item.

For example, if you need to assign a task to a user whose ID is a process variable, use the assignment to map the variable to the parameter `ActorId`.

Assignment is defined in the `Assignments` property in case of activity elements and in the `DataInputAssocations` or `DataOutputAssociations` property in case of non-activity elements.

[NOTE]
.Data types in an assignment
====
As parameters of the type String can make use of the assignment mechanism by applying the respective syntax directly in their value, `#{userVariable}`, assignment is rather intended for mapping of properties that are not of type String.
====

[[_action_scripts]]
== Action scripts
Action scripts are pieces of code that define the `Script` property or an element's interceptor action. Action scripts have access to global variables, process variables, and the predefined variable `kcontext`. Accordingly, `kcontext` is an instance of the `ProcessContext` interface. See the `ProcessContext` http://docs.jboss.org/jbpm/v6.4/javadocs/org/kie/api/runtime/process/ProcessContext.html[Javadoc] for more information.

Currently, Java and MVEL are supported as dialects for action scripts definitions. MVEL accepts any valid Java code and additionally provides support for nested access to parameters. For example, the MVEL equivalent of Java call `person.getName()` is `person.name`.

.Sample action script
====
The following action script prints out the name of the person:

[source]
----
// Java dialect
System.out.println(person.getName());
----

[source]
----
// MVEL dialect
System.out.println(person.name);
----
====

=== Process instance action scripts

You can use action scripts to view information about process instances.

Use the following commands to:

* Return the ID of a process instance:
+
[source]
----
System.out.println(kcontext.getProcessInstance().getId());
----

* Return the parent process instance ID if a process instance has a parent:
+
[source]
----
System.out.println(kcontext.getProcessInstance().getParentProcessInstanceId());
----

* Return the ID of a process definition that is related to a process instance:
+
[source]
----
System.out.println(kcontext.getProcessInstance().getProcessId());
----

* Return the name of a process definition that is related to a process instance:
+
[source]
----
System.out.println(kcontext.getProcessInstance().getProcessName());
----

* Return the state of a process instance:
+
[source]
----
System.out.println(kcontext.getProcessInstance().getState());
----

To set a process variable in an action script, use `kcontext.setVariable("_VARIABLE_NAME_", "_VALUE_")`.

[[_constraints]]
== Constraints

There are two types of constraints in business processes: _code constraints_ and _rule constraints_.

* _Code constraints_ are boolean expressions evaluated directly whenever they are reached; these constraints are written in either Java or MVEL. Both Java and MVEL code constraints have direct access to the globals and variables defined in the process.
+
Here is an example of a valid Java code constraint, person being a variable in the process:
+
[source]
----
return person.getAge() > 20;
----
+
Here is an example of a valid MVEL code constraint, person being a variable in the process:
+
[source]
----
return person.age > 20;
----

Rule constraints are equal to normal Drools rule conditions. They use the Drools Rule Language (DRL) syntax to express complex constraints. These rules can, like any other rule, refer to data in the working memory. They can also refer to globals directly. Here is an example of a valid rule constraint:
+
[source]
----
Person(age > 20)
----
+
This tests for a person older than 20 in the working memory.

Rule constraints do not have direct access to variables defined inside the process. However, it is possible to refer to the current process instance inside a rule constraint by adding the process instance to the working memory and matching for the process instance in your rule constraint. Logic is included to make sure that a variable `processInstance` of type `WorkflowProcessInstance` will only match the current process instance and not other process instances in the working memory. Note, it is necessary to insert the process instance into the session. If it is necessary to update the process instance, use Java code or an on-entry, on-exit, or explicit action in the process. The following example of a rule constraint will search for a person with the same name as the value stored in the variable `name` of the process:

[source]
----
processInstance : WorkflowProcessInstance()
Person(name == (processInstance.getVariable("name")))
# add more constraints here ...
----

[[_timers]]
== Timers

Timers wait for a predefined amount of time before triggering, once, or repeatedly. You can use timers to trigger certain logic after a certain period, or to repeat some action at regular intervals.

=== Configuring a timer
A timer node is set up with a delay and a period. The delay specifies the amount of time to wait after node activation before triggering the timer for the first time. The period defines the time between subsequent trigger activations. A period of `0` results in a one-shot timer. The (period and delay) expression must be of the form `[\#d][#h][#m][#s][#[ms]]`. You can specify the amount of days, hours, minutes, seconds, and milliseconds. Milliseconds is the default value. For example, the expression `1h` waits one hour before triggering the timer again.

[[_configuring_timer_iso_date_format]]
==== Configuring timer ISO-8601 date format
Since version 6, you can configure timers with valid _ISO8601_ date format that supports both one shot timers and repeatable timers. You can define timers as date and time representation, time duration or repeating intervals. For example:

[source]
----
Date - 2013-12-24T20:00:00.000+02:00 - fires exactly at Christmas Eve at 8PM
Duration - PT1S - fires once after 1 second
Repeatable intervals - R/PT1S - fires every second, no limit.
	Alternatively R5/PT1S fires 5 times every second
----

==== Configuring a timer with process variables
In addition to the above mentioned configuration options, you can specify timers using process variable that consists of string representation of either delay and period or ISO8601 date format. By specifying `#{variable}`, the engine dynamically extracts process variable and uses it as timer expression. The timer service is responsible for making sure that timers get triggered at the appropriate times. You can cancel timers so that they are no longer triggered. You can use timers in the following ways inside a process:

* You can add a timer event to a process flow. The process activation starts the timer, and when it triggers, once or repeatedly, it activates the timer node's successor. Subsequently, the outgoing connection of a timer with a positive period is triggered multiple times. Canceling a Timer node also cancels the associated timer, after which no more triggers occur.
* You can associate timer with a sub-process or tasks as a boundary event.

[float]
[[_updating_timer_within_a_running_process_instance]]
==== Updating a timer within a running process instance

Sometimes a process requires the possibility to dynamically alter the timer period or delay without the need to restart the entire process workflow. In that case, an already scheduled timer can be rescheduled to meet the new requirements: for example to prolong or shorten the timer expiration time or change the delay, period, and repeat limit.

For this reason, jBPM offers a corresponding `UpdateTimerCommand` class which allows you to perform these several steps as an atomic operation. All of them are then done within the same transaction.

[source,java]
----
org.jbpm.process.instance.command.UpdateTimerCommand
----

It is supported to update the _boundary_ timer events as well as the _intermediate_ timer events.

You can reschedule the timer by specifying the two mandatory parameters and one of the three optional parameter sets of the `UpdateTimerCommand` class.

Both of the following two parameters are mandatory:

* process instance ID (`long`);
* timer node name (``String``).

Next, choose and configure one of the three following parameter sets:

* delay (`long`);
* period (`long`) and repeat limit (`int`);
* delay, period, and repeat limit.

.Rescheduling a timer event
====
[source,java]
----
// Start the process instance and record its ID:
long id = kieSession.startProcess(BOUNDARY_PROCESS_NAME).getId();

// Set the timer delay to 3 seconds:
kieSession.execute(new UpdateTimerCommand(id, BOUNDARY_TIMER_ATTACHED_TO_NAME, 3));
----
====

The rescheduling is performed using the `kieSession` executor to ensure execution within the same transaction.

=== Troubleshooting timers

Getting an IllegalStateException exception::
--
The Intelligent {KIE_SERVER} uses EJB timer service by default for implementation of timer-based nodes. Consequently, the limitations described in the warning message about Singleton strategy and CMT are valid for the out-of-the-box Intelligent {KIE_SERVER} setup. To resolve the issue:

* Change the `RuntimeManager` strategy.
* Disable the default EJB timer service for timer nodes by setting the system property `org.kie.timer.ejb.disabled` to `true`.
--

The Intelligent {KIE_SERVER} throws InactiveTransactionException when using timers::
--
When you deploy the Intelligent {KIE_SERVER} on {EAP_LONG} {EAP_VERSION} and configure a database for the EJB timer service, processes that require timers end in the `InactiveTransactionException` exception similar to the following:

[source]
----
WFLYEJB0018: Ignoring exception during setRollbackOnly: com.arjuna.ats.jta.exceptions.InactiveTransactionException: ARJUNA016102: The transaction is not active! Uid is ...
----

To resolve this issue:

. Update your {PRODUCT} to version 6.4.2 or higher.
. Set the property `org.jbpm.ejb.timer.tx` to `true`.
+
Note that the property is not available in previous versions of {PRODUCT}. See chapter https://access.redhat.com/documentation/en-us/red_hat_jboss_bpm_suite/6.4/html/administration_and_configuration_guide/configuration_properties#system_properties[System Properties] of _{PRODUCT} Administration and Configuration Guide_ for further information.
--

[[_sect_multi_threading]]
== Multi-threading
In the following section, we will refer to two types of "multi-threading": logical and technical. Technical multi-threading is what happens when multiple threads or processes are started on a computer, for example by a Java or C program. Logical multi-threading is what we see in a BPM process after the process reaches a parallel gateway. From a functional standpoint, the original process will then split into two processes that are executed in a parallel fashion.

The BPM engine supports logical multi-threading; for example, processes that include a parallel gateway are supported. We've chosen to implement logical multi-threading using one thread; accordingly, a business process that includes logical multi-threading will only be executed in one technical thread. The main reason for doing this is that multiple (technical) threads need to be able to communicate state information with each other if they are working on the same process. This requirement brings with it a number of complications. While it might seem that multi-threading would bring performance benefits with it, the extra logic needed to make sure the different threads work together well means that this is not guaranteed. There is also the extra overhead incurred because we need to avoid race conditions and deadlocks.

[[_engine_execution]]
== Engine execution

In general, the BPM engine executes actions in serial. For example, when the engine encounters a script task in a process, it will synchronously execute that script and wait for it to complete before continuing execution. Similarly, if a process encounters a parallel gateway, it will sequentially trigger each of the outgoing branches, one after the other. This is possible since execution is almost always instantaneous, meaning that it is extremely fast and produces almost no overhead. As a result, the user will usually not even notice this. Similarly, action scripts in a process are also synchronously executed, and the engine will wait for them to finish before continuing the process. For example, doing a `Thread.sleep(...)` as part of a script will not make the engine continue execution elsewhere but will block the engine thread during that period.

The same principle applies to service tasks. When a service task is reached in a process, the engine will also invoke the handler of this service synchronously. The engine will wait for the `completeWorkItem(...)` method to return before continuing execution. It is important that your service handler executes your service asynchronously if its execution is not instantaneous.

To implement an asynchronous service handler, implement the service in a new thread using the `executeWorkItem()` method in the work item handler that allows the process instance to continue its execution.

[source,java]
----
package documentation.wih.async;

import java.util.concurrent.TimeUnit;
import org.kie.api.runtime.process.WorkItem;
import org.kie.api.runtime.process.WorkItemHandler;
import org.kie.api.runtime.process.WorkItemManager;

public class MyServiceTaskHandler implements WorkItemHandler {
    private Thread asyncThread;
    public void executeWorkItem(final WorkItem workItem, final WorkItemManager manager) {

        asyncThread = new Thread(new Runnable() {
            public void run() {
                for (int i = 0; i < 10; i++) {
                    System.out.println("Hello number + " + i + " from async!");
                    waitASecond();
                }
            }
        });
        asyncThread.start();

        manager.completeWorkItem(workItem.getId(), null);
    }
    public void abortWorkItem(WorkItem workItem, WorkItemManager manager) {
        //asyncThread can't be aborted
    }
    private static void waitASecond() {
        try {
            TimeUnit.SECONDS.sleep(1);
        } catch (InterruptedException ignored) {}
    }
}
----

An example of this would be a service task that invokes an external service. Since the delay in invoking this service remotely and waiting for the results might be too long, it might be a good idea to invoke this service asynchronously. This means that the handler will only invoke the service and will notify the engine later when the results are available. In the meantime, the process engine then continues execution of the process.

Human tasks are a typical example of a service that needs to be invoked asynchronously, as we don't want the engine to wait until a human actor has responded to the request. The human task handler will only create a new task (on the task list of the assigned actor) when the human task node is triggered. The engine will then be able to continue execution on the rest of the process (if necessary), and the handler will notify the engine asynchronously when the user has completed the task.


[[_job_executor_for_asynchronous_execution]]
== Job executor for asynchronous execution
In {PRODUCT}, the Job Executor component integrates with the runtime engine for processing asynchronous tasks. You can delegate asynchronous execution operations, such as error handling, retry, cancellation, and history logging in a new thread (using custom implementation of `WorkItemHandler`) and use the Job Executor to handle these operations for you. The Job Executor provides an environment for background execution of commands, which are nothing but business logic encapsulated within a simple interface.

The custom tasks that the process engine delegates to the Job Executor runs as asynchronous `WorkItemHandler`. {PRODUCT} provides `AsyncWorkItemHandler` that is backed by the {PRODUCT} Job Executor. During the execution, the `AsyncWorkItemHandler` sets contextual data available inside the command. You can configure the `AsyncWorkItemHandler` class in two ways:

* As a generic handler where you provide the command name as part of the work item parameters. In {CENTRAL} while modeling a process, if you need to execute some work item asynchronously: specify `async` as the value for the [property]``TaskName`` property, create a data input called `CommandClass` and assign the fully-qualified class name of this [class]``CommandClass`` as the data input.
* As a specific handler which is created to handle a given type of work item, thus allowing you to register different instances of [class]``AsyncWorkItemHandler`` for different work items. Commands are most likely to be dedicated to a particular work item, which allows you to specify the [class]``CommandClass`` at registration time instead of requiring it at design time, as with the first approach. But this means that an additional CDI bean that implements [interface]`` WorkItemHandlerProducer `` interface needs to be provided and placed on the application classpath so that the CDI container can find it. When you are ready to model your process, set the value of the [property]``TaskName`` property to the one provided at registration time.


=== Using the job executor in embedded mode
The Job Executor API is a public API and is available within `kie-api` (`org.kie.api.executor`). You can run your background processes asynchronously using the Job Executor from {CENTRAL} or outside the {CENTRAL} in embedded mode. To use the Job Executor in {CENTRAL}, see <<_using_job_executor_in_business_central>>. Perform the following steps to use the Job Executor in the embedded mode:

. Implement the `Command` interface.
. Transfer business data from the process engine to your `Command` implementation.
. Configure the Job Executor.
. Register the `AsyncWorkItemHandler` handler, which uses the Job Executor.
. Provide the execution results to the process engine.


.Wrapping business logic with the command interface

The Job Executor contains the business logic to be executed and does not have any process runtime related information. The Job Executor works on instances of the `Command` interface. It receives data through the `CommandContext` object and returns results of the execution with `ExecutionResults` class:

[source,java]
----
package org.kie.api.executor;

import org.kie.api.executor.ExecutionResults;

public interface Command {
  public ExecutionResults execute(CommandContext ctx) throws Exception;
}
----

Here, `ctx` is the contextual data given by the executor service.

Since the Job Executor is decoupled from the runtime process engine and provides only the logic that is to be executed as a part of that command, it promotes reuse of already existing logic by wrapping it with `Command` implementation.

.Transferring business data from the process engine to the command interface
The input data is transferred from the process engine to the command using the data transfer object `CommandContext`. It is important that the data `CommandContext` holds is serializable.

[source,java]
----
package org.kie.api.executor;

import java.io.Serializable;

public class CommandContext implements Serializable {

  private static final long serialVersionUID = -1440017934399413860L;
  private Map<String, Object> data;

  public CommandContext() {
    data  = new HashMap<String, Object>();
  }

  public CommandContext(Map<String, Object> data) {
    this.data = data;
  }

  public void setData(Map<String, Object> data) {
    this.data = data;
  }

  public Map<String, Object> getData() {
    return data;
  }

  public Object getData(String key) {
    return data.get(key);
  }

  public void setData(String key, Object value) {
    data.put(key, value);
  }

  public Set<String> keySet() {
    return data.keySet();
  }

  @Override
  public String toString() {
    return "CommandContext{" + "data=" + data + '}';
  }
}
----

`CommandContext` should provide the following:

** `businessKey`:  a unique identifier of the caller.
** `callbacks`: the fully qualified classname (FQCN) of the `CommandCallback` instance to be called on command completion.

.Configuring the executor

The Job Executor API usage scenarios are identical when used from {CENTRAL} and when used outside of {CENTRAL}. See the following example Job Executor configuration options:

. In-memory Job Executor with optional configuration:
+
[source,java]
----
import org.jbpm.executor.ExecutorServiceFactory;

..

// Configuration of in-memory executor service.
executorService = ExecutorServiceFactory.newExecutorService();

// Set number of threads which will be used by executor - default is 1.
executorService.setThreadPoolSize(1);

// Sets interval at which executor threads are running in seconds - default is 3.
executorService.setInterval(1);

// Sets time unit of interval - default is SECONDS.
executorService.setTimeunit(TimeUnit.SECONDS);

// Number of retries in case of excepting during execution of command - default is 3.
executorService.setRetries(1);

executorService.init();
----

. Executor configuration using `EntityManagerFactory` to store jobs into a database:
+
[source,java]
----
emf = Persistence.createEntityManagerFactory("org.jbpm.executor");

// Configuration of database executor service.
executorService = ExecutorServiceFactory.newExecutorService(emf);

// Optional configuration is skipped.
executorService.init();
----


.Registering the AsyncWorkItemHandler handler

The `AsyncWorkItemHandler` handler uses Job Executor for scheduling tasks. See the following code sample to register the `AsyncWorkItemHandler` handler:

[source,java]
----
import java.util.List;
import java.util.Map;

import org.kie.api.event.process.ProcessEventListener;
import org.kie.api.io.ResourceType;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.manager.RuntimeEngine;
import org.kie.api.runtime.manager.RuntimeEnvironment;
import org.kie.api.runtime.manager.RuntimeEnvironmentBuilder;
import org.kie.api.runtime.manager.RuntimeManagerFactory;
import org.kie.api.runtime.process.ProcessInstance;
import org.kie.api.runtime.process.WorkItemHandler;
import org.kie.internal.io.ResourceFactory;
import org.kie.internal.runtime.manager.context.EmptyContext;
import org.jbpm.runtime.manager.impl.DefaultRegisterableItemsFactory;

...

 RuntimeEnvironment environment = RuntimeEnvironmentBuilder
  .Factory.get().newDefaultBuilder()
  .userGroupCallback(userGroupCallback)
  .addAsset(ResourceFactory.newClassPathResource
    ("BPMN2-ScriptTask.bpmn2"), ResourceType.BPMN2)
  .registerableItemsFactory(new DefaultRegisterableItemsFactory() {

    @Override
    public Map<String, WorkItemHandler> getWorkItemHandlers(RuntimeEngine runtime) {
      Map<String, WorkItemHandler> handlers = super.getWorkItemHandlers(runtime);
      handlers.put("async", new AsyncWorkItemHandler
        (executorService, "org.jbpm.executor.commands.PrintOutCommand"));
      return handlers;
    }

    @Override
    public List<ProcessEventListener> getProcessEventListeners( RuntimeEngine runtime) {
      List<ProcessEventListener> listeners = super.getProcessEventListeners(runtime);
      listeners.add(countDownListener);
      return listeners;
    }
  })

  .get();

manager = RuntimeManagerFactory.Factory.get().newSingletonRuntimeManager(environment);
assertNotNull(manager);

RuntimeEngine runtime = manager.getRuntimeEngine(EmptyContext.get());
KieSession ksession = runtime.getKieSession();
assertNotNull(ksession);

ProcessInstance processInstance = ksession.startProcess("ScriptTask");
assertEquals(ProcessInstance.STATE_ACTIVE, processInstance.getState());

Thread.sleep(3000);

processInstance = runtime.getKieSession().getProcessInstance(processInstance.getId());
assertNull(processInstance);
----

.Providing execution results to the process engine

The outcome of the command is provided to process engine using the `ExecutionResults` class. `ExecutionResults` is a data transfer object. The data provided by this class must be serializable.

[source,java]
----
package org.kie.api.executor;

import org.kie.api.executor.ExecutorService;
import java.io.Serializable;

public class ExecutionResults implements Serializable {

  private static final long serialVersionUID = -1738336024526084091L;
  private Map<String, Object> data = new HashMap<String, Object>();

  public ExecutionResults() {}

  public void setData(Map<String, Object> data) {
    this.data = data;
  }

  public Map<String, Object> getData() {
    return data;
  }

  public Object getData(String key) {
    return data.get(key);
  }

  public void setData(String key, Object value) {
    data.put(key, value);
  }

  public Set<String> keySet() {
    return data.keySet();
  }

  @Override
  public String toString() {
    return "ExecutionResults{" + "data=" + data + '}';
  }
}
----


=== Hello World example with an embedded job executor
The following example uses the Job Executor in embedded mode. The following example uses Red Hat CodeReady Studio to model and execute the project. To use the Job Executor in embedded mode:

. In your jBPM project, add the `src/main/resources/META-INF/drools.rulebase.conf` file with the following content:
+
[source]
----
drools.workDefinitions = WorkDefinitions.wid
----

. Add the `src/main/resources/META-INF/WorkDefinitions.wid` file with the following content:
+
[source]
----
import org.drools.core.process.core.datatype.impl.type.ObjectDataType;
import java.lang.Long;
import java.lang.Integer;
import java.lang.Boolean;
import java.lang.String;


[
  [
    "name" : "AsyncWIH",
    "results" : [
        "Result" : new ObjectDataType(),
    ],
    "displayName" : "AsyncWIH",
    "icon" : "async-16x15.png"
  ],
]
----

. Add the following BPMN diagram in the `src/main/resources` directory:
+
image::processes/asyncWIH.png[]
+
In your diagram, create an `org.kie.api.executor.ExecutionResults` variable and map it to the Output variable of the asynchronous work item.

. Create a `Command` implementation in `src/main/java`:
+
[source,java]
----
package com.sample;

import org.kie.api.executor.Command;
import org.kie.api.executor.CommandContext;
import org.kie.api.executor.ExecutionResults;

public class HelloWorldCommand implements Command {

	@Override
	public ExecutionResults execute(CommandContext arg0) throws Exception {
		System.out.println("Hello World from Business Command!");
		return new ExecutionResults();
	}
}
----

. Create the main class that will register the work item handler and execute the process:
+
[source,java]
----
package com.sample;

import java.util.Properties;

import javax.persistence.EntityManagerFactory;
import javax.persistence.Persistence;

import org.jbpm.test.JBPMHelper;
import org.kie.api.KieBase;
import org.kie.api.KieServices;
import org.kie.api.runtime.KieContainer;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.manager.RuntimeEngine;
import org.kie.api.runtime.manager.RuntimeEnvironmentBuilder;
import org.kie.api.runtime.manager.RuntimeManager;
import org.kie.api.runtime.manager.RuntimeManagerFactory;

import bitronix.tm.resource.jdbc.PoolingDataSource;

import org.kie.api.executor.ExecutorService;
import org.jbpm.executor.ExecutorServiceFactory;
import org.jbpm.executor.impl.wih.AsyncWorkItemHandler;

public class ProcessMain {

	static EntityManagerFactory emf;

	public static void main(String[] args) throws InterruptedException {
		KieServices ks = KieServices.Factory.get();
		KieContainer kContainer = ks.getKieClasspathContainer();
		KieBase kbase = kContainer.getKieBase("kbase");

		RuntimeManager manager = createRuntimeManager(kbase);
		RuntimeEngine engine = manager.getRuntimeEngine(null);
		KieSession ksession = engine.getKieSession();

		//Register the work item handler and point it to the FQCN of the command implementation.
		ExecutorService executorService = ExecutorServiceFactory.newExecutorService(ProcessMain.emf);
		ksession.getWorkItemManager().registerWorkItemHandler("AsyncWIH", new AsyncWorkItemHandler(executorService,"com.sample.HelloWorldCommand"));
		executorService.init();

		ksession.startProcess("com.sample.bpmn.hello");
		manager.disposeRuntimeEngine(engine);

		//Wait for the executor to finish. Otherwise, the process finishes before the job executor is checked.
		Thread.sleep(5000);
		System.exit(0);
	}

	private static RuntimeManager createRuntimeManager(KieBase kbase) {
		JBPMHelper.startH2Server();

		// Create a data source if no custom datasource is available
		Properties properties = JBPMHelper.getProperties();
		PoolingDataSource pds = new PoolingDataSource();

		//Note the JNDI name
		pds.setUniqueName("jndi:/example");
		pds.setClassName("bitronix.tm.resource.jdbc.lrc.LrcXADataSource");
		pds.setMaxPoolSize(5);
		pds.setAllowLocalTransactions(true);
		pds.getDriverProperties().put("user", properties.getProperty("persistence.datasource.user", "sa"));
		pds.getDriverProperties().put("password", properties.getProperty("persistence.datasource.password", ""));
		pds.getDriverProperties().put("url", properties.getProperty("persistence.datasource.url", "jdbc:h2:tcp://localhost/~/jbpm-db;MVCC=TRUE"));
		pds.getDriverProperties().put("driverClassName", properties.getProperty("persistence.datasource.driverClassName", "org.h2.Driver"));
		pds.init();

		//Note the persistence unit name
		ProcessMain.emf = Persistence.createEntityManagerFactory("org.jbpm.example");
		RuntimeEnvironmentBuilder builder = RuntimeEnvironmentBuilder.Factory.get()
			.newDefaultBuilder().entityManagerFactory(emf)
			.knowledgeBase(kbase);
		return RuntimeManagerFactory.Factory.get()
			.newSingletonRuntimeManager(builder.get(), "com.sample:example:1.0");
	}

}
----

. Add the `src/main/resource/persistence.xml` file with the following content. If you have a custom datasource, configure your custom persistence unit.
+
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<persistence version="2.0"
             xmlns="http://java.sun.com/xml/ns/persistence" xmlns:orm="http://java.sun.com/xml/ns/persistence/orm"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd
                      http://java.sun.com/xml/ns/persistence/orm http://java.sun.com/xml/ns/persistence/orm_2_0.xsd">

  <persistence-unit name="org.jbpm.example" transaction-type="JTA">
    <provider>org.hibernate.ejb.HibernatePersistence</provider>
    <jta-data-source>jndi:/example</jta-data-source>
    <mapping-file>META-INF/Executor-orm.xml</mapping-file>
    <properties>
      <property name="hibernate.dialect" value="org.hibernate.dialect.H2Dialect" />
      <property name="hibernate.max_fetch_depth" value="3" />
      <property name="hibernate.hbm2ddl.auto" value="update" />
      <property name="hibernate.show_sql" value="false" />

      <!-- BZ 841786: AS7/EAP 6/Hib 4 uses new (sequence) generators which seem to cause problems -->
      <property name="hibernate.id.new_generator_mappings" value="false" />
      <property name="hibernate.transaction.jta.platform" value="org.hibernate.service.jta.platform.internal.BitronixJtaPlatform" />
    </properties>
  </persistence-unit>
</persistence>
----

. When you execute the main class, the expected output is:
+
----
[main] INFO org.jbpm.executor.impl.ExecutorImpl - Starting Executor Component ...
 	 - Thread Pool Size: 1
 	 - Interval: 3 SECONDS
 	 - Retries per Request: 3

[main] WARN org.jbpm.executor.impl.ExecutorImpl - Disabling JMS support in executor because: unable to initialize JMS configuration for executor due to unable to find a bound object at name 'java:/JmsXA'
Hello World from Business Command!
----

[[_using_job_executor_in_business_central]]
=== Using Job Executor in {CENTRAL}

`AsyncWorkItemHandler` accepts the following input parameters:

* `CommandClass`: A fully-qualified class name (FQCN) of the command to be executed. Mandatory unless the handler is configured with a default command class.
* `Retries`: The number of retries for the command execution. This parameter is optional.
* `RetryDelay`: A single value or a comma separated list of time expressions used in case of multiple retries. For example: `5s, 2m, 4h`. This parameter is optional.
+
If you provide a comma separated list of time expressions and if the number of retry delays is smaller than the number of retries, the executor uses the last available value from the list.
+
If you provide a single time expression for retry delay, the retries will be equally spaced.
+
* `Delay`: A start delay for jobs. The value is a time expression: `5s`, `2m`, or `4h`. The delay is calculated from the current time. This parameter is optional.
* `AutoComplete`: Allows to use the _fire and forget_ execution style. Thus, the handler does not wait for job completion. The default value is `false`.
* `Priority`: Priority for the job execution. The value is a range from 0 (the lowest) to 9 (the highest).

The following data are available inside of the command during execution:

* `businessKey`: A String generated from the process instance ID and the work item ID in the following format: [processInstanceId]:[workItemId].
* `workItem`: A work item instance that is being executed, including all its parameters.
* `processInstanceId`: The process instance ID that triggered this work item execution.


To register the Asynchronous Work Item handler in {CENTRAL}:

. Implement the `Command` interface, for example:
+
[source,java]
----
package docs.command;

import org.kie.api.executor.Command;
import org.kie.api.executor.CommandContext;
import org.kie.api.executor.ExecutionResults;

public class HelloWorldCommand implements Command {

	public ExecutionResults execute(CommandContext commandContext) throws Exception {
		System.out.println("Hello World from Business Command!");
	    return new ExecutionResults();
	}

}
----
+
Use the following `pom.xml`:
+
[source,xml]
----
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>org.docs</groupId>
  <artifactId>hello-commandimpl</artifactId>
  <version>1.0</version>
  <name>commandImpl</name>
  <description>Hello world command implementation</description>

  <dependencies>
    <dependency>
        <groupId>org.kie</groupId>
        <artifactId>kie-api</artifactId>
        <version>6.4.0.Final-redhat-8</version>
      <scope>provided</scope>
    </dependency>
  </dependencies>
</project>
----
+
See the https://access.redhat.com/documentation/en/red-hat-jboss-bpm-suite/6.4/single/installation-guide/#supported_comps[Supported Component Versions] of the _{PRODUCT} Installation Guide_ for the current version number. Also note that you must configure Maven to work with the Red Hat middleware repository.
+
. Build your Maven project, upload the JAR file to the {CENTRAL}, and add into your project dependencies. See the https://access.redhat.com/documentation/en-us/red_hat_jboss_bpm_suite/6.4/html-single/user_guide/#registering_a_work_item_handler[Registering Work Item handler in {CENTRAL}] chapter for further information.
. In your project, define a custom (WID) that will trigger your `Command` implementation:
.. Click *Work Item Definitions* -> *Work Definitions*. The Work Item Definitions editor opens.
.. Add your definition, specifying all parameters you want to use, for example:
+
[source,json]
----
[
    "name" : "async",
    "displayName" : "Async Hello World!",
    "icon" : "defaultemailicon.gif",
    "parameters" : [
        "CommandClass" : new StringDataType()
        ]
]
----
+
.. Click *Save* and *Validate* to ensure correctness of your Work Item Definition (WID) file.
. Click *New Item* -> *Business Process* to create a new Business Process.
. On your canvas, click image:processes/3898.png[] to open the Object Library pallet, expand *Service Tasks* and drag and drop the Work Item you created on the canvas, for example the `Async Hello World!` Service Task.
. Connect the Work Item with the start and end event.
. Click the Work Item and click image:processes/3897.png[] to open the *Properties* tab. Click the *1 data inputs, 0 data outputs* value and click image:processes/6563.png[] to open the *Data I/O* window.
. Set the `CommandClass` attribute to `docs.command.HelloWorldCommand`. Alternatively, if you used a different package, enter the fully-qualified class name of your implementation.
. Click *Save* to save the data input mappings.
. Click *Save* to save your process.
. Register `AsyncWorkItemHandler` in {CENTRAL}:
.. Click *Open Project Editor* and navigate to the *Deployment Descriptor* for your project.
.. Click *Add* under the *Work Item handlers* category.
.. Set the first `Value` field to `async`.
.. Set the second `Value` field to:
+
[source,java]
----
new org.jbpm.executor.impl.wih.AsyncWorkItemHandler(org.jbpm.executor.ExecutorServiceFactory.newExecutorService(null))
----
+
.. Set the resolver to `mvel`.
.. Click *Save* and *Validate* to ensure correctness of your deployment descriptor.

You can now build, deploy, and start your process.  If you followed the example above, you will see similar output in the in the command line:

[source]
----
09:46:03,473 INFO  [stdout] (Thread-637 (HornetQ-client-global-threads-1573025029)) Hello World from Business Command!

=== Executor configuration

When you are not running the Executor Service in the embedded mode, you can use the following properties:

. [property]``org.kie.executor.disabled``: `true` or `false` to enable or disable the executor.
. [property]``org.kie.executor.pool.size``: an Integer that specifies the thread pool size for the executor. The default value is 1.
. [property]``org.kie.executor.retry.count``: an Integer that specifies the default number of retries in case of an error executing a job. The default value is 3.
. [property]``org.kie.executor.interval``: an Integer that specifies the time to wait between checking for waiting jobs. The default value is 3 seconds.
. [property]``org.kie.executor.timeunit``: `NANOSECONDS`, `MICROSECONDS`, `MILLISECONDS`, `SECONDS`, `MINUTES`, `HOURS`, or `DAYS`. Specifies the unit for the interval property. The default is `SECONDS`.

[[_multiple_sessions_and_persistence]]
=== Multiple sessions and persistence


The simplest way to run multiple process instances is to run them in one knowledge session.
However, it is possible to run multiple process instances in different knowledge sessions or in different technical threads.

When using multiple knowledge session with multiple processes and adding persistence, use a database that allows row-level as well as table-level locks: There could be a situation when there are 2 or more threads running, each within its own knowledge session instance.
On each thread, a process is being started using the local knowledge session instance.
In this use case, a race condition exists in which both thread A and thread B have coincidentally simultaneously finished a process instance.
At this point, both thread A and B are committing changes to the database.
If row-level locks are not possible, then the following situation can occur:

* Thread A has a lock on the ProcessInstanceInfo table, having just committed a change to that table.
* Thread A wants a lock on the SessionInfo table in order to commit a change.
* Thread B has the opposite situation: It has a lock on the SessionInfo table, having just committed a change.
* Thread B wants a lock on the ProcessInstanceInfo table, even though Thread A already has a lock on it.


This is a deadlock situation which the database and application are not be able to solve, unless row-level locks are possible and enabled in the database and tables used.

=== Asynchronous events
In cases where several process instances from different process definitions are waiting for the same signal, they are generally executed sequentially in the same single thread. However, if one of those process instances throws a runtime exception, all the other process instances are affected, usually resulting in a rolled back transaction. To avoid this, {PRODUCT} supports using asynchronous signals events for:

* Throwing Intermediate Signal Events
* End Events

From the {CENTRAL}, set the *Data Input*
 value of the throw event to async to automatically set the Executor Service on each ksession.
This ensures that each process instance is signaled in a different transaction.

[[_sect_technical_exceptions]]
=== Technical exceptions
Technical exceptions occur when a technical component of a Process acts in an unexpected way. When using Java-based systems, this often results in a Java Exception. As these exceptions cannot be handled using BPMN2, it is important to handle them in expected ways.

The following types of code might throw exceptions:

* Code present directly in the process definition
* Code that is not part of the product executed during a process
* Code that interacts with a technical component outside of the process engine


This includes the following:

* Code in element properties, such as the [property]``Script`` property of a [path]_Script Task_ element or in the definitions of the interception actions, that is, the `onEntry` and `onExit` properties
* Code in `WorkItemHandlers` associated with `task` and task-type nodes

[float]
==== Code in element properties
Exceptions thrown by code defined in Element properties can cause the Process instance to fail in an unrecoverable way.
Often, it is the code that starts the Process that will end up throwing the exception generated by a Process without returning a reference to the Process instance.
Such code includes for example the `onEntry` and `onExit` properties, Script defined for the Script Task, etc.

Therefore, it is important to limit the scope of the code in these Elements so that is operates only over Process variables.
Using a `scriptTask` to interact with a different technical component, such as a database or web service has _significant risks_ because any exceptions thrown will corrupt or abort the Process instance.

To interact with other systems, use `task` Elements, `serviceTask` Elements and other ``task``-type Elements.
Do not use the `scriptTask` nodes for these purposes.

[NOTE]
====
If the script defined in a `scriptTask` causes the problem, the Process Engine usually throws the `WorkflowRuntimeException` with information on the Process (see <<_extracting_information_from_workflowruntimeexception>>).
====

[float]
==== Code in WorkItemHandlers
WorkItemHandlers are used when your Process interacts with other technical systems. You can either build exception handling into your own WorkItemhandler implementations or wrap your implementation into the `handler decorator` classes (for examples and detailed information see <<_exception_handling_classes>>). These classes include the logic that is executed when an exception is thrown during the execution or abortion of a work item:

SignallingTaskHandlerDecorator::
catches the exception and signals it to the Process instance using a configurable event type when the `executeWorkItem()` or `abortWorkItem` methods of the original [class]``WorkItemHandler`` instance throw an exception.
The exception thrown is passed as part of the event.
This functionality can be also used to signal to an Event sub-process defined in the Process definition.

LoggingTaskHandlerDecorator::
logs error about any exceptions thrown by the `executeWorkItem()` and `abortWorkItem()` methods.
It also saves any exceptions thrown to an internal list so that they can be retrieved later for inspection or further logging.
The content and format of the message logged are configurable.

While the classes described above covers most cases involving exception handling as it catches any throwable objects, you might still want to write a custom WorkItemHandler that includes exception handling logic.
In such a case, consider the following:

* Does the implementation catch all exceptions the code could return?
* Does the implementation complete or abort the work item after an exception has been caught or uses a mechanisms to retry the process later (in some cases, incomplete process instances might be acceptable)?
* Does the implementation define any other actions that need to be taken when an exception is caught? Would it be beneficial to interact with other technical systems? Should a sub-process be triggered to handle the exception?


[IMPORTANT]
====
If WorkItemManager signals that the work item has been completed or aborted, make sure the signal is sent after any signals to the Process instance were sent.
Depending on how your Process definition, calling WorkItemManager.completeWorkItem() or WorkItemManager.abortWorkItem() triggers the completion of the Process instance as these methods trigger further execution of the Process execution flow.
====

[[_sect_technical_exception_examples]]
==== Technical exception examples

[[_service_task_handlers]]
==== Service Task handlers
The following example uses a Throwing Error Intermediate Event to throw an error. An Error Event sub-process then catches and handles the error.

When the Throwing Error Intermediate Event throws an error, the process instance is interrupted:

. Execution of the process instance stops: no other parts of the process are executed.
. The process instance finishes as ABORTED.

The process starts with a start event and continues to the Throw Exception service task. The task produces an exception, which is propagated as a signal object through the process instance and caught by the sub-process start event in the Exception Handler event sub-process. The workflow continues to the Handle Exception task and the process instance finishes with the sub-process end event.

.Process with an exception handling Event sub-process
image::processes/3389.png[]

The following XML is a representation of the process. It contains elements and IDs that are referenced in <<_exception_handling_classes>>.

[source,xml]
----
 <itemDefinition id="_stringItem" structureRef="java.lang.String" /> (1)
  <message id="_message" itemRef="_stringItem"/>  # (2)

  <interface id="_serviceInterface" name="org.jbpm.examples.exceptions.service.ExceptionService">
    <operation id="_serviceOperation" name="throwException">
      <inMessageRef>_message</inMessageRef> (2)
    </operation>
  </interface>

  <error id="_exception" errorCode="code" structureRef="_exceptionItem"/> (3)

  <itemDefinition id="_exceptionItem" structureRef="org.kie.api.runtime.process.WorkItem"/> (4)
  <message id="_exceptionMessage" itemRef="_exceptionItem"/> (4)

  <interface id="_handlingServiceInterface" name="org.jbpm.examples.exceptions.service.ExceptionService">
    <operation id="_handlingServiceOperation" name="handleException">
      <inMessageRef>_exceptionMessage</inMessageRef> (4)
    </operation>
  </interface>

  <process id="ProcessWithExceptionHandlingError" name="Service Process" isExecutable="true" processType="Private">
    <!-- properties -->
    <property id="serviceInputItem" itemSubjectRef="_stringItem"/> (1)
    <property id="exceptionInputItem" itemSubjectRef="_exceptionItem"/> (4)

    <!-- main process -->
    <startEvent id="_1" name="Start" />
    <serviceTask id="_2" name="Throw Exception" implementation="Other" operationRef="_serviceOperation">

    <!-- rest of the serviceTask element and process definition... -->

    <subprocess id="_X" name="Exception Handler" triggeredByEvent="true" >
      <startEvent id="_X-1" name="subStart">
        <dataOutput id="_X-1_Output" name="event"/>
        <dataOutputAssociation>
          <sourceRef>_X-1_Output</sourceRef>
          <targetRef>exceptionInputItem</targetRef> (4)
        </dataOutputAssociation>
        <errorEventDefinition id="_X-1_ED_1" errorRef="_exception" /> (3)
      </startEvent>

      <!-- rest of the subprocess definition... -->

    </subprocess>

  </process>
----

. This `<itemDefinition>` element defines a data structure that is used in the `serviceInputItem` property in the process.
. This `<message>` element (first reference) defines a message that has a String as its content, as defined by the `<itemDefinition>` element on line above. The `<interface>` element below it refers to it (second reference) in order to define what type of content the service (defined by the `<interface>`) expects.
. This `<error>` element (first reference) defines an error for use later in the process: an Event sub-process is defined that is triggered by this error (second reference). The content of the error is defined by the `<itemDefinition>` element defined below the `<error>` element.
. This `<itemDefinition>` element (first reference) defines an item that contains a WorkItem instance. The `<message>` element (second reference) then defines a message that uses this item definition to define its content. The `<interface>` element below that refers to the `<message>` definition (third reference) in order to define the type of content that the service expects.
+
In the process itself, a `<property>` element (fourth reference) is defined as having the content defined by the initial `<itemDefinition>`. This is helpful because it means that the Event sub-process can then store the error it receives in that property (5th reference).


[[_exception_handling_classes]]
==== Exception handling classes

The BPMN process defined in <<_service_task_handlers>> contains two `<serviceTask>` activities. The `org.jbpm.bpmn2.handler.ServiceTaskHandler` class is the default task handler class used for `<serviceTask>` tasks. If you do not specify a Work Item Handler implementation for a `<serviceTask>` activity, the `ServiceTaskHandler` class is used.

The example below decorates the `ServiceTaskHandler` class with a `SignallingTaskHandlerDecorator` instance in order to define behavior when the `ServiceTaskHandler` class throws an exception.

In the example, the ServiceTaskHandler throws an exception because it calls the `ExceptionService.throwException` method, which throws an exception. (See the `_handlingServiceInterface` `<interface>` element in the BPMN2 XML schema.)

The example also configures which (error) event is sent to the process instance by the `SignallingTaskHandlerDecorator` instance. The `SignallingTaskHandlerDecorator` object does this when an exception is thrown in a task. In this example, because of the `<error>` definition with the error code `code` in the BPMN2 process, the signal is set to `Error-code`.

.Rules for sending signals
[IMPORTANT]
====
When sending a signal of an event to the Process Engine, consider the rules for signaling process events:

* Error events are signaled by sending an `Error-_ERRORCODE ATTRIBUTE VALUE_` value to the session.
* Signal events are signaled by sending the name of the signal to the session.
* If you wanted to send an error event to a Boundary Catch Error Event, the error type should be of the format: ``"Error-" + $AttachedNodeID + "-" + $ERROR_CODE``. For example, `Error-SubProcess_1-888` would be a valid error type.
+
However, this is _NOT_ a recommended practice because sending the signal this way bypasses parts of the boundary error event functionality and it relies on internal implementation details that might be changed in the future.
For a way to programmatically trigger a boundary error event when an Exception is thrown in [class]``WorkItemHandler`` see this KnowledgeBase https://access.redhat.com/solutions/1213663[article].

====

.Using SignallingTaskHandlerDecorator
====
The [class]``ServiceTaskHandler`` calls the `ExceptionService.throwException()` method to throw an exception (refer to the `_handlingServiceInterface` interface element in the BPMN2).

The [class]``SignallingTaskHandlerDecorator`` that wraps the [class]``ServiceTaskHandler`` sends to the Process instance the [class]``error`` with the set [path]_error code_.

[source,java]
----

import java.util.HashMap;
import java.util.Map;

import org.jbpm.bpmn2.handler.ServiceTaskHandler;
import org.jbpm.bpmn2.handler.SignallingTaskHandlerDecorator;
import org.jbpm.examples.exceptions.service.ExceptionService;
import org.kie.api.KieBase;
import org.kie.api.io.ResourceType;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.process.ProcessInstance;
import org.kie.internal.builder.KnowledgeBuilder;
import org.kie.internal.builder.KnowledgeBuilderFactory;
import org.kie.internal.io.ResourceFactory;

public class ExceptionHandlingErrorExample {

public static final void main(String[] args) {
runExample();
}

public static ProcessInstance runExample() {
KieSession ksession = createKieSession();

String eventType = "Error-code"; <1>
SignallingTaskHandlerDecorator signallingTaskWrapper <2>
= new SignallingTaskHandlerDecorator(ServiceTaskHandler.class, eventType);
signallingTaskWrapper.setWorkItemExceptionParameterName(ExceptionService.exceptionParameterName); <3>
ksession.getWorkItemManager().registerWorkItemHandler("Service Task", signallingTaskWrapper);

Map<String, Object> params = new HashMap<String, Object>();
params.put("serviceInputItem", "Input to Original Service");
ProcessInstance processInstance = ksession.startProcess("ProcessWithExceptionHandlingError", params);
return processInstance;
}

private static KieSession createKieSession() {
KnowledgeBuilder kbuilder = KnowledgeBuilderFactory.newKnowledgeBuilder();
kbuilder.add(ResourceFactory.newClassPathResource("exceptions/ExceptionHandlingWithError.bpmn2"), ResourceType.BPMN2);
KieBase kbase = kbuilder.newKnowledgeBase();
return kbase.newKieSession();
}
----
<1> Definition of the `Error-code` event to be sent to the process instance when the wrapped `WorkItemHandler` implementation throws an exception.
<2>  Construction of the `SignallingTaskHandlerDecorator` class instance with the `WorkItemHandler` implementation and `eventType` as parameters: Note that a `SignallingTaskHandlerDecorator` class constructor that takes an instance of a `WorkItemHandler` implementation as its parameter is also available. This constructor is useful if the `WorkItemHandler` implementation does not allow a no-argument constructor.
<3>  Registering the `WorkItemHandler` with the session: When an exception is thrown by the wrapped `WorkItemHandler`, the `SignallingTaskHandlerDecorator` saves it as a parameter in the `WorkItem` instance with a parameter name configured in the `SignallingTaskHandlerDecorator` (see the code below for the `ExceptionService`).


[[_exception_service]]
===== Exception service
In <<_service_task_handlers>>, the BPMN2 process definition defines the exception service using the [class]``ExceptionService`` class as follows:

[source,xml]
----
<interface id="_handlingServiceInterface" name="org.jbpm.examples.exceptions.service.ExceptionService">
<operation id="_handlingServiceOperation" name="handleException">
----

The exception service uses the [class]``ExceptionService`` class to provide the exception handling abilities. The class is implemented as follows:

[source,java]
----
import org.kie.api.runtime.process.WorkItem;
...
public class ExceptionService {

  public static String exceptionParameterName = "my.exception.parameter.name";
  public void handleException(WorkItem workItem) {
    System.out.println( "Handling exception caused by work item '" + workItem.getName() + "' (id: " + workItem.getId() + ")");
    Map<String, Object> params = workItem.getParameters();
    Throwable throwable = (Throwable) params.get(exceptionParameterName);
    throwable.printStackTrace();
  }
  public String throwException(String message) {
    throw new RuntimeException("Service failed with input: " + message );
  }
  public static void setExceptionParameterName(String exceptionParam) {
    exceptionParameterName = exceptionParam;
  }

}
----

You can specify any Java class with the default or another no-argument constructor as the class to provide the exception service so that it is executed as part of a [class]``serviceTask``.

[[_handling_errors_with_signals]]
===== Handling errors with signals
In the example in <<_service_task_handlers>>, an [path]_Error event_ occurs during Process execution and the execution is interrupted immediately: no other Flows or Activities are executed.

However, you might want to complete the execution. In such case you can use a [path]_Signal event_ as the Process execution continues after the Signal is processed (that is, after the _Signal Event SubProcess_ or another Activities that the Signal triggered, finish their execution). Also, the Process execution finished successfully, _not_ in an aborted state, which is the case if an Error is used.

In the example process, we define the `error` element which is then used to throw the Error:

[source,xml]
----
 <error id="_exception" errorCode="code" structureRef="_exceptionItem"/>
----

To use a signal instead, remove the line defining the `error` element and define a `<signal>` element:
+

[source,xml]
----
 <signal id="exception-signal" structureRef="_exceptionItem"/>
----
. Change all references from the `_exception` value in the `<error>` XML tag to the `exception-signal` value of the `<signal>` XML tag.
+
Change the `<errorEventDefinition>` element in the ``<startEvent>``,
+

[source,xml]
----
 <errorEventDefinition id="_X-1_ED_1" errorRef="_exception" />
----
+
to a ``<signalEventDefinition>``:
+

[source,xml]
----
 <signalEventDefinition id="_X-1_ED_1" signalRef="exception-signal"/>
----

[[_extracting_information_from_workflowruntimeexception]]
===== Extracting information from WorkflowRuntimeException
If a scripts in your process definition throws an exception, you need to retrieve more information about the exception and related information.

If it is a `scriptTask` element that causes an exception, you can extract the information from the [class]``WorkflowRuntimeException`` as it is the wrapper of the scriptTask.

The `WorkflowRuntimeException` instance stores the information outlined in <<_workflowruntimeexception>>. Values of all fields listed can be obtained using the standard `get*` methods.

[[_workflowruntimeexception]]
.Information in WorkflowRuntimeException instances
[cols="20%,20%,60%a", frame="all", options="header"]
|===
|
										Field name

|
										Type

|
										Description


|``processInstanceId``
|``long``
|

The id of the `ProcessInstance` instance in which the exception occurred

Note that the `ProcessInstance` may not exist anymore or be available in the database if using persistence.

|``processId``
|``String``
|The id of the process definition that was used to start the process (that is, "ExceptionScriptTask" in

[source,java]
----
ksession.startProcess("ExceptionScriptTask");
----
)

|``nodeId``
|``long``
|
										The value of the (BPMN2) id attribute of the node that threw the exception


|``nodeName``
|``String``
|
										The value of the (BPMN2) name attribute of the node that threw the exception


|``variables``
|``Map<String, Object>``
|
										The map containing the variables in the process instance (__experimental__)


|``message``
|``String``
|
										The short message with information on the exception


|``cause``
|``Throwable``
|
										The original exception that was thrown

|===


The following code illustrates how to extract extra information from a process instance that throws a `WorkflowRuntimeException` exception instance.

[source,java]
----

import org.jbpm.workflow.instance.WorkflowRuntimeException;
import org.kie.api.KieBase;
import org.kie.api.io.ResourceType;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.process.ProcessInstance;
import org.kie.internal.builder.KnowledgeBuilder;
import org.kie.internal.builder.KnowledgeBuilderFactory;
import org.kie.internal.io.ResourceFactory;

public class ScriptTaskExceptionExample {

 public static final void main(String[] args) {
  runExample();
 }

 public static void runExample() {
  KieSession ksession = createKieSession();
  Map < String, Object > params = new HashMap < String, Object > ();
  String varName = "var1";
  params.put(varName, "valueOne");
  try {
   ProcessInstance processInstance = ksession.startProcess("ExceptionScriptTask", params);
  } catch (WorkflowRuntimeException wfre) {
   String msg = "An exception happened in " + "process instance [" + wfre.getProcessInstanceId() + "] of process [" + wfre.getProcessId() + "] in node [id: " + wfre.getNodeId() + ", name: " + wfre.getNodeName() + "] and variable " + varName + " had the value [" + wfre.getVariables().get(varName) + "]";
   System.out.println(msg);
  }
 }
 private static KieSession createKieSession() {
  KnowledgeBuilder kbuilder = KnowledgeBuilderFactory.newKnowledgeBuilder();
  kbuilder.add(ResourceFactory.newClassPathResource("exceptions/ScriptTaskException.bpmn2"), ResourceType.BPMN2);
  KieBase kbase = kbuilder.newKnowledgeBase();
  return kbase.newKieSession();
 }
}
----

Use the following Maven dependencies:

[source,xml]
----
<dependencies>
  ...
  <dependency>
      <groupId>org.kie</groupId>
      <artifactId>kie-api</artifactId>
      <version>6.5.0.Final-redhat-2</version>
  </dependency>
  <dependency>
    <groupId>org.jbpm</groupId>
    <artifactId>jbpm-flow</artifactId>
    <version>6.5.0.Final-redhat-2</version>
  </dependency>
  <dependency>
    <groupId>org.kie</groupId>
    <artifactId>kie-internal</artifactId>
    <version>6.5.0.Final-redhat-2</version>
</dependency>
  ...
</dependencies>
----

For the current Maven artifact version, see chapter
ifdef::BPMS[]
https://access.redhat.com/documentation/en/red-hat-jboss-bpm-suite/6.4/single/installation-guide/#supported_comps[Supported Component Versions]
endif::BPMS[]
ifdef::BRMS[]
https://access.redhat.com/documentation/en/red-hat-jboss-brms/6.4/single/installation-guide/#supported_comps[Supported Component Versions]
endif::BRMS[]
 of the _{PRODUCT} Installation Guide_.


[[_sect_process_fluent_api]]
== Process Fluent API

[[_using_the_process_fluent_api_to_create_business_process]]
=== Using the Process Fluent API to Create Business Process

While it is recommended to define processes using the graphical editor or the underlying XML, you can also create a business process using the Process API directly. The most important process model elements are defined in the packages `org.jbpm.workflow.core` and `org.jbpm.workflow.core.node`.

{PRODUCT} provides you a fluent API that allows you to easily construct processes in a readable manner using factories. You can then validate the process that you were constructing manually.

[[_process_fluent_api_example]]
=== Process Fluent API example

Here is an example of a basic process using a script task:

[source,java]
----
import org.kie.api.KieServices;
import org.kie.api.builder.KieFileSystem;
import org.kie.api.builder.ReleaseId;
import org.kie.api.io.Resource;
import org.jbpm.ruleflow.core.RuleFlowProcessFactory;
import org.jbpm.ruleflow.core.RuleFlowProcess;
import org.jbpm.bpmn2.xml.XmlBPMNProcessDumper;

...

RuleFlowProcessFactory factory = RuleFlowProcessFactory.createProcess("org.jbpm.HelloWorld");

factory
  // Header
  .name("HelloWorldProcess")
  .version("1.0")
  .packageName("org.jbpm")
  // Nodes
  .startNode(1).name("Start").done()
  .actionNode(2).name("Action")
  .action("java", "System.out.println(\"Hello World\");").done()
  .endNode(3).name("End").done()
  // Connections
  .connection(1, 2)
  .connection(2, 3);

RuleFlowProcess process = factory.validate().getProcess();
KieServices ks = KieServices.Factory.get();
KieFileSystem kfs = ks.newKieFileSystem();
Resource resource = ks.getResources().newByteArrayResource(
  XmlBPMNProcessDumper.INSTANCE.dump(process).getBytes());

resource.setSourcePath("helloworld.bpmn2");
kfs.write(resource);
ReleaseId releaseId = ks.newReleaseId("org.jbpm", "helloworld", "1.0");
kfs.generateAndWritePomXML(releaseId);
ks.newKieBuilder(kfs).buildAll();
ks.newKieContainer(releaseId).newKieSession().startProcess("org.jbpm.HelloWorld");
----

In this example, we call the static `createProcess()` method from the `RuleFlowProcessFactory` class. This method creates a new process and returns the `RuleFlowProcessFactory` that can be used to create the process.

A process consists of three parts:

* _Header_: The header section comprises global elements such as the name of the process, imports, and variables.
+
In the previous example, the header contains the name and version of the process and the package name.

* _Nodes_: The nodes section comprises all the different nodes that are part of the process.
+
In the previous example, nodes are added to the current process by calling the `startNode()`, `actionNode()` and `endNode()` methods. These methods return a specific `NodeFactory` that allows you to set the properties of that node. Once you have finished configuring that specific node, the `done()` method returns you to the current `RuleFlowProcessFactory` so you can add more nodes, if necessary.

* _Connections_: The connections section links the nodes to create a flow chart.
+
In the previous example, once you add all the nodes, you must connect them by creating connections between them. This can be done by calling the method `connection`, which links the nodes.
+
You can validate the generated process by calling the `validate()` method and retrieve the created `RuleFlowProcess` object.

[[_sect_testing_business_processes]]
== Testing a business process
Although business processes should not contain any implementation details and should be as high-level as possible, they have a life cycle similar to other development artifacts. Because business processes can be updated dynamically and modifying them can cause errors, testing a process definition is a part of creating business processes.

Process unit tests ensure that the process behaves as expected in specific use cases. For example, an output can be tested based on a particular input. To simplify unit testing, {PRODUCT} includes the `org.jbpm.test.JbpmJUnitBaseTestCase` class, which provides the following:

* Helper methods for creating a new knowledge base and a session for one or more given processes, with the possibility of using persistence. For more information, see <<_configuring_persistence1>>.
* Assert statements to check:
  ** The state of a process instance. A process instance can be active, completed, or aborted.
  ** The node instances that are currently active.
  ** Which nodes have been triggered. This enables to inspect the followed path.
  ** The value of different variables.

.JUnit Test of `hello.bpmn` Process
====
The process below contains a start event, a script task, and an end event. The example JUnit test creates a new session, starts the `hello.bpmn` process, verifies whether the process instance has completed successfully, and whether the `StartProcess`, `Hello`, and `EndProcess` nodes were executed.

image::processes/1211.png[]

[source,java]
----
import org.jbpm.test.JbpmJUnitBaseTestCase;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.manager.RuntimeEngine;
import org.kie.api.runtime.process.ProcessInstance;

public class ProcessPersistenceTest extends JbpmJUnitBaseTestCase {
  public ProcessPersistenceTest() {
    // Set up a data source and enable persistence:
    super(true, true);
  }

  @Test
  public void testProcess() {
    // Create a runtime manager with the hello.bpmn process:
    createRuntimeManager("hello.bpmn");
    // Get a runtime engine:
    RuntimeEngine runtimeEngine = getRuntimeEngine();
    // Get an access to an instance of a session:
    KieSession ksession = runtimeEngine.getKieSession();
    // Start the process:
    ProcessInstance processInstance = ksession.startProcess("com.sample.bpmn.hello");
    // Check whether the process instance has completed successfully:
    assertProcessInstanceCompleted(processInstance.getId());
    // Check whether the given nodes were executed:
    assertNodeTriggered(processInstance.getId(), "StartProcess", "Hello", "EndProcess");
  }
}
----
====

[[_JbpmJUnitBaseTestCase]]
=== JbpmJUnitBaseTestCase

The `JbpmJUnitBaseTestCase` class acts as a base test case class that you can use for {PRODUCT}-related tests. It provides four usage areas:

* JUnit life cycle methods
* Knowledge base and knowledge session management methods
* Assertions
* Helper methods

For the complete list of all methods, see the https://maven.repository.redhat.com/nexus/content/unzip/unzip/org/jbpm/jbpm-test/6.5.0.Final/jbpm-test-6.5.0.Final-javadoc.jar-unzip/org/jbpm/test/JbpmJUnitBaseTestCase.html[JbpmJUnitBaseTestCase Javadoc].

.JUnit Life Cycle Methods
[cols="40%,60%a", frame="all", options="header"]
|===
|Method
|Description

|`setUp`
|This method is annotated as `@Before`. It configures a data source and `EntityManagerFactory` and deletes the session ID of a Singleton.

|`tearDown`
|This method is annotated as `@After`. It removes history, closes `EntityManagerFactory` and a data source, and disposes `RuntimeManager` and ``RuntimeEngine``s.
|===

To create a session, create `RuntimeManager` and `RuntimeEngine` first. Use the following methods to create and dispose of `RuntimeManager`:

.RuntimeManager Management Methods
[cols="40%,60%a", frame="all", options="header"]
|===
|Method
|Description

|`+createRuntimeManager(String... process)+`
|Creates one `RuntimeManager` with the Singleton strategy for one test. Each process is added to the knowledge base.

|`+createRuntimeManager(Strategy strategy, String identifier, String... process)+`
|Creates `RuntimeManager` with the given strategy and with all processes added to the knowledge base. The `identifier` parameter specifies a concrete `RuntimeManager`.

|`createRuntimeManager(Map<String, ResourceType> resources)`
|Creates `RuntimeManager` with the Singleton strategy and with all resources, such as processes and rules, added to the knowledge base.

|`createRuntimeManager(Map<String, ResourceType> resources, String identifier)`
|Creates `RuntimeManager` with the Singleton strategy and with all resources, such as processes and rules, added to the knowledge base. The `identifier` parameter specifies a concrete `RuntimeManager`.

|`createRuntimeManager(Strategy strategy, Map<String, ResourceType> resources)`
|Creates one `RuntimeManager` with the given strategy for one test, with all resources, such as processes and rules, added to the knowledge base.

|`createRuntimeManager(Strategy strategy, Map<String, ResourceType> resources, String identifier)`
|Creates one `RuntimeManager` with the given strategy for one test, with all resources, such as processes and rules, added to the knowledge base. The `identifier` parameter specifies a concrete `RuntimeManager`.

|`createRuntimeManager(Strategy strategy, Map<String, ResourceType> resources, RuntimeEnvironment environment, String identifier)`
|Creates the lowest level of `RuntimeManager` without any particular configuration, which enables you to configure each of its parts manually. Specify the following parameters:

* `strategy`: one of the supported strategies.
* `resources`: all the resources, such as rules and processes, that are added to the knowledge base.
* `environment`: the runtime environment used for creating `RuntimeManager`.
* `identifier`: the unique identifier of `RuntimeManager`.

|`disposeRuntimeManager`
|Disposes of the currently active `RuntimeManager` in the test scope.
|===

.RuntimeEngine Management Methods
[cols="40%,60%", frame="all", options="header"]
|===
|Method
|Description

|`getRuntimeEngine()`
|Returns a new `RuntimeEngine` built from the manager of a test case. The method uses the `EmptyContext` context suitable for the Singleton and Per Request strategies.

|`getRuntimeEngine(Context<?> context)`
|Returns a new `RuntimeEngine` built from the manager of a test case. The `context` parameter specifies an instance of the context used to create `RuntimeEngine`. To maintain the same session for process instances, use `ProcessInstanceIdContext`.
|===

To test the current state of various assets, the following methods are available:

.Assertions
[cols="40%,60%", frame="all", options="header"]
|===
|Assertion
|Description

|`assertProcessInstanceActive(long processInstanceId, KieSession ksession)`
|Checks whether a process instance with the given ID is active.

|`assertProcessInstanceCompleted(long processInstanceId)`
|Checks whether a process instance with the given ID has completed successfully. Use this method in case session persistence is enabled. Otherwise, use `assertProcessInstanceNotActive(long processInstanceId, KieSession ksession)`.

|`assertProcessInstanceAborted(long processInstanceId)`
|Checks whether a process instance with the given ID was aborted. Use this method in case session persistence is enabled. Otherwise, use `assertProcessInstanceNotActive(long processInstanceId, KieSession ksession)`.

|`+assertNodeExists(ProcessInstance process, String... nodeNames)+`
|Checks whether the given nodes exist within the specified process.

|`+assertNodeActive(long processInstanceId, KieSession ksession, String... name)+`
|Checks whether a process instance with the given ID contains at least one active node with the specified node names.

|`+assertNodeTriggered(long processInstanceId, String... nodeNames)+`
|For each given node name, checks whether a node instance was triggered during the execution of the specified process instance.

|`getVariableValue(String name, long processInstanceId, KieSession ksession)`
|Retrieves the value of the given variable from the specified process instance.

|`+assertProcessVarExists(ProcessInstance process, String... processVarNames)+`
|Checks whether the given process contains the specified process variables.

|`assertProcessNameEquals(ProcessInstance process, String name)`
|Checks whether the given name matches the name of the specified process.

|`assertVersionEquals(ProcessInstance process, String version)`
|Checks whether the given process version matches the version of the specified process.
|===

.Helper Methods
[cols="40%,60%", frame="all", options="header"]
|===
|Method
|Description

|`setupPoolingDataSource`
|Configures a data source.

|`getDs`
|Returns the currently configured data source.

|`getEmf`
|Returns the currently configured `EntityManagerFactory`.

|`getTestWorkItemHandler`
|Returns a test work item handler that can be registered in addition to what is registered by default.

|`clearHistory`
|Clears a history log.
|===

`JbpmJUnitBaseTestCase` supports all the predefined `RuntimeManager` strategies as part of the unit testing. Specify which strategy should be used whenever creating a runtime manager as part of a single test. The following example uses the `PerProcessInstance` strategy:

[source,java]
----
import java.util.List;

import org.jbpm.test.JbpmJUnitBaseTestCase;
import org.junit.Test;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.manager.RuntimeEngine;
import org.kie.api.runtime.manager.RuntimeManager;
import org.kie.api.runtime.process.ProcessInstance;
import org.kie.api.task.TaskService;
import org.kie.api.task.model.TaskSummary;
import org.kie.internal.runtime.manager.context.ProcessInstanceIdContext;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class ProcessHumanTaskTest extends JbpmJUnitBaseTestCase {
  private static final Logger logger = LoggerFactory.getLogger(ProcessHumanTaskTest.class);
  public ProcessHumanTaskTest() {
    super(true, false);
  }

  @Test
  public void testProcessProcessInstanceStrategy() {
    RuntimeManager manager = createRuntimeManager
      (Strategy.PROCESS_INSTANCE, "manager", "humantask.bpmn");
    RuntimeEngine runtimeEngine = getRuntimeEngine(ProcessInstanceIdContext.get());
    KieSession ksession = runtimeEngine.getKieSession();
    TaskService taskService = runtimeEngine.getTaskService();

    int ksessionID = ksession.getId();
    ProcessInstance processInstance = ksession.startProcess("com.sample.bpmn.hello");

    assertProcessInstanceActive(processInstance.getId(), ksession);
    assertNodeTriggered(processInstance.getId(), "Start", "Task 1");

    manager.disposeRuntimeEngine(runtimeEngine);

    runtimeEngine = getRuntimeEngine(ProcessInstanceIdContext.get(processInstance.getId()));

    ksession = runtimeEngine.getKieSession();
    taskService = runtimeEngine.getTaskService();

    assertEquals(ksessionID, ksession.getId());

    // Let John execute Task 1:
    List<TaskSummary> list = taskService.getTasksAssignedAsPotentialOwner("john", "en-UK");
    TaskSummary task = list.get(0);
    logger.info("John is executing task {}", task.getName());

    taskService.start(task.getId(), "john");
    taskService.complete(task.getId(), "john", null);

    assertNodeTriggered(processInstance.getId(), "Task 2");

    // Let Mary execute Task 2:
    list = taskService.getTasksAssignedAsPotentialOwner("mary", "en-UK");
    task = list.get(0);

    logger.info("Mary is executing task {}", task.getName());

    taskService.start(task.getId(), "mary");
    taskService.complete(task.getId(), "mary", null);

    assertNodeTriggered(processInstance.getId(), "End");
    assertProcessInstanceCompleted(processInstance.getId());
  }
}
----

//For a list of Maven dependencies, see section <<_testing_dependencies>>.

[[_configuring_persistence1]]
=== Configuring persistence

Persistence allows to store states of all process instances in a database and uses a history log to check assertions related to the execution history. When persistence is not used, process instances are stored in the memory and an in-memory logger is used for history transactions.

By default, the performed JUnit tests do _not_ use persistence. To change this behavior, invoke a constructor of the superclass in one of the following ways:

* `default`: This option uses a no-argument constructor; it does not initialize a data source and does not configure session persistence. This option is usually used for in-memory process management without any human task interaction.
* `super(boolean, boolean)`: This option allows to explicitly configure persistence and a data source. This is the most common way of bootstrapping test cases for {PRODUCT}. Use
** `super(true, false)` for execution with in-memory process management and human tasks persistence.
** `super(true, true)` for execution with persistent process management and human tasks persistence.
* `super(boolean, boolean, string)`: This option is very similar to the last one, however, it enables you to use a different persistence unit name than the default one, which is `org.jbpm.persistence.jpa`.

[source,java]
----
import org.jbpm.test.JbpmJUnitBaseTestCase;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class ProcessHumanTaskTest extends JbpmJUnitBaseTestCase {

  private static final Logger logger = LoggerFactory
    .getLogger(ProcessHumanTaskTest.class);

  public ProcessHumanTaskTest() {
    // Persistence will not be used for the
    // process engine but will be used for human tasks:
    super(true, false);
  }
}
----

[[_testing_integration_with_external_services]]
=== Testing integration with external services

Business processes often include the invocation of external services. Unit testing of a business process allows you to register test handlers that verify whether the specific services are requested correctly, and provide test responses for those services as well.

To test the interactions with external services, use the `TestWorkItemHandler` handler, which is provided by default. `TestWorkItemHandler` can be registered to collect all the work items of a given type and contains data related to a task. A work item represents one unit of work, such as sending one specific email or invoking one specific service. This test handler then checks whether a specific work item was actually requested during an execution of a process, and whether the data associcated with the work item are correct.

.Testing the email task
====
This example shows how to test a process that sends an email and whether an exception is raised if the email cannot be sent. This is accomplished by notifying the engine about the email delivery failure.

image::processes/1212.png[]

Further notes describing the following source code are below.

[source,java]
----
// Not used in the snippet below but your class must extend JbpmJUnitBaseTestCase.
import org.jbpm.test.JbpmJUnitBaseTestCase;
import org.kie.api.runtime.KieSession;
import org.kie.api.runtime.manager.RuntimeEngine;
import org.kie.api.runtime.process.ProcessInstance;
import org.kie.api.runtime.process.WorkItem;

...

public void testProcess2() {

  // Create a runtime manager with a single process:
  createRuntimeManager("sample-process.bpmn");
  // Get a runtime engine:
  RuntimeEngine runtimeEngine = getRuntimeEngine();
  // Get an access to an instance of a session:
  KieSession ksession = runtimeEngine.getKieSession();
  // Register a test handler for "Email":
  TestWorkItemHandler testHandler = getTestWorkItemHandler();
  ksession.getWorkItemManager().registerWorkItemHandler("Email", testHandler);

  // Start the process:
  ProcessInstance processInstance = ksession.startProcess("com.sample.bpmn.hello2");

  assertProcessInstanceActive(processInstance.getId(), ksession);
  assertNodeTriggered(processInstance.getId(), "StartProcess", "Email");

  // Check whether the email has been requested:
  WorkItem workItem = testHandler.getWorkItem();

  assertNotNull(workItem);
  assertEquals("Email", workItem.getName());
  assertEquals("me@mail.com", workItem.getParameter("From"));
  assertEquals("you@mail.com", workItem.getParameter("To"));

  // Simulate a failure of sending the email:
  ksession.getWorkItemManager().abortWorkItem(workItem.getId());

  assertProcessInstanceAborted(processInstance.getId());
  assertNodeTriggered(processInstance.getId(), "Gateway", "Failed", "Error");
}
----
The unit test uses a test handler that is executed when an email is requested and allows you to test the data related to the email, such as its sender and recipient. Once the `abortWorkItem()` method notifies the engine about the email delivery failure, the unit test verifies that the process handles such case by generating an error and logging the action. In this case, the process instance is eventually aborted.
====
