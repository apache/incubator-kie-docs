[id="chap-kogito-developing-process-services"]
= Developing process services with {PRODUCT}
ifdef::context[:parent-context: {context}]
:context: kogito-developing-process-services

// Purpose statement for the assembly
[role="_abstract"]
As a developer of business processes, you can use {PRODUCT} business automation to develop process services using Business Process Model and Notation (BPMN) 2.0 models. BPMN process models are graphical representations of the steps required to achieve a business goal. You can design your BPMN processes with the {PRODUCT} BPMN modeler in VSCode or import existing BPMN processes into your {PRODUCT} projects for deployment and execution.

For more information about BPMN, see the Object Management Group (OMG) https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification].

// Modules - concepts, procedures, refs, etc.
include::{asciidoc-dir}/creating-running/chap-kogito-creating-running.adoc[tags=ref-kogito-app-examples]

[id="con-bpmn_{context}"]
== Business Process Model and Notation (BPMN) 2.0

[role="_abstract"]
Business Process Model and Notation (BPMN) 2.0 is a standard established by the Object Management Group (OMG) for describing and modeling business processes. BPMN defines an XML schema that enables BPMN models to be shared between BPMN-compliant platforms and across organizations so that business analysts and business process developers can collaborate in designing and implementing BPMN process services. The BPMN standard is similar to and can be used together with the Decision Model and Notation (DMN) standard for designing and modeling business decisions.

For more information about BPMN, see the Object Management Group (OMG) https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification].

[id="ref-bpmn-model-example_{context}"]
=== BPMN model example

[role="_abstract"]
A typical BPMN business process consists of the following basic components:

* Start events to initiate the process
* Tasks or other steps that are completed as part of the process
* Connectors to link the process nodes and create a sequence flow
* End events to terminate the process

The following example is a real-world BPMN model scenario that demonstrates how you can use process modeling to reach a business goal based on business decisions, tasks, or other services. In this scenario, an order service uses business processes for ordering items, for verifying the order, and for evaluating customer age.

NOTE: This example is based on the `process-quarkus-example` application in the https://github.com/kiegroup/kogito-examples[`kogito-examples`] repository in GitHub. However, this example may differ from the exact example source code as {PRODUCT} continues to be developed. Be sure to explore this and other {PRODUCT} examples in GitHub to help you develop your own applications.

The `orders.bpmn2` process in the example describes the steps that need to be followed when ordering items. The process includes a script task for writing debug information and a call activity for invoking a subprocess, using a custom `Order` data object.

.Example `orders.bpmn2` process
image::kogito/bpmn/bpmn-model-example-orders.png[Image of `orders.bpmn` example process]

The `Add items` subprocess invokes the following `orderItems.bpmn2` process, which uses a `CalculationService.calculateTotal` custom Java service and a user task to verify the order.

.Example `orderItems.bpmn2` process invoked as a subprocess
image::kogito/bpmn/bpmn-model-example-order-items.png[Image of `orderItems.bpmn` example process]

The `persons.bpmn2` process invokes a Decision Model and Notation (DMN) model in a business rule task to determine customer age, followed by a user task for special handling requirements for children, if applicable.

.Example `persons.bpmn2` process invoked as a subprocess
image::kogito/creating-running/kogito-bpmn-example-person.png[Image of `persons.bpmn` example process]

Based on these processes and on application configurations, {PRODUCT} generates a set of REST operations to create new orders, to list and delete active orders, and to determine the age of a specified person.

For example, the following REST operations use the endpoint `/orders` to interact with customer orders. You can use a REST client, curl utility, or the Swagger UI configured for the application at http://localhost:8080/swagger-ui/ to send API requests to interact with the running application.

.Swagger UI to interact with all application endpoints (\http://localhost:8080/swagger-ui/)
image::kogito/creating-running/kogito-swagger-example-jbpm.png[Image of Swagger UI for example application]

NOTE: For the predefined {PRODUCT} example applications, the Swagger UI for interacting with service endpoints is available only on Quarkus examples that you run in
ifdef::KOGITO-ENT[]
development mode.
endif::[]
ifdef::KOGITO-COMM[]
development mode or in native mode.
endif::[]

.Example POST request body to create an order (JSON)
[source,json]
----
{
  "approver": "john",
  "order": {
    "orderNumber": "12345",
    "shipped": false
  }
}
----

.Example curl command to create an order
[source]
----
curl -X POST http://localhost:8080/orders -H 'content-type: application/json' -H 'accept: application/json' -d '{"approver" : "john", "order" : {"orderNumber" : "12345", "shipped" : false}}'
----

The returned order displays an `"id"` field with a generated UUID that you can use to retrieve details about this specific order, if needed.

.Example curl command to view active orders
[source]
----
curl -X GET http://localhost:8080/orders -H 'content-type: application/json' -H 'accept: application/json'
----

.Example curl command to view order details by returned UUID
[source]
----
curl -X GET http://localhost:8080/orders/6b53c227-6d5e-40b7-8c8c-a541a2a47d58 -H 'content-type: application/json' -H 'accept: application/json'
----

You use the `"id"` value for the order that was returned when you created the order or when you retrieved active orders.

.Example curl command to cancel the order by returned UUID
[source]
----
curl -X DELETE http://localhost:8080/orders/6b53c227-6d5e-40b7-8c8c-a541a2a47d58 -H 'content-type: application/json' -H 'accept: application/json'
----

The following is the BPMN source file for the `orders.bpmn2` process model, as an example:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<!-- origin at X=0.0 Y=0.0 -->
<bpmn2:definitions xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:bpmn2="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:bpmn20="http://www.omg.org/bpmn20" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:bpsim="http://www.bpsim.org/schemas/1.0" xmlns:dc="http://www.omg.org/spec/DD/20100524/DC" xmlns:di="http://www.omg.org/spec/DD/20100524/DI" xmlns:drools="http://www.jboss.org/drools" xmlns="http://www.jboss.org/drools" xmlns:ns="http://www.w3.org/2001/XMLSchema" xsi:schemaLocation="http://www.omg.org/spec/BPMN/20100524/MODEL BPMN20.xsd http://www.jboss.org/drools drools.xsd http://www.bpsim.org/schemas/1.0 bpsim.xsd" id="_gfw8oEcJEemyodG9iPy-Bw" exporter="org.eclipse.bpmn2.modeler.core" exporterVersion="1.5.0.Final-v20180515-1642-B1" targetNamespace="http://www.omg.org/bpmn20">
  <bpmn2:itemDefinition id="_OrderItem" isCollection="false" structureRef="org.kie.kogito.examples.demo.Order"/>
  <bpmn2:itemDefinition id="_approverItem" isCollection="false" structureRef="String"/>
  <bpmn2:itemDefinition id="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputXItem" isCollection="false" structureRef="org.kie.kogito.examples.demo.Order"/>
  <bpmn2:itemDefinition id="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputXItem" isCollection="false" structureRef="org.kie.kogito.examples.demo.Order"/>
  <bpmn2:process id="demo.Orders" drools:packageName="org.kie.kogito.examples" drools:version="1.0" drools:adHoc="false" name="Orders" isExecutable="true">
    <bpmn2:documentation id="_gfw8oUcJEemyodG9iPy-Bw"><![CDATA[Deals with orders created by customer]]></bpmn2:documentation>
    <bpmn2:property id="order" itemSubjectRef="_OrderItem" name="order"/>
    <bpmn2:property id="approver" itemSubjectRef="_approverItem" name="approver"/>
    <bpmn2:sequenceFlow id="_8216C810-34D8-4BFA-B814-1AA01907810F" sourceRef="_9484CB12-FE52-434C-AE9F-3C3C267D1C96" targetRef="_2D876EF2-93F4-4CBE-959A-04EF7BFA9CED"/>
    <bpmn2:sequenceFlow id="_58684613-0155-48B2-8746-7675AFF24439" sourceRef="_0617D7DF-047A-4EC4-85E7-E201D640F4F5" targetRef="_9484CB12-FE52-434C-AE9F-3C3C267D1C96">
      <bpmn2:extensionElements>
        <drools:metaData name="isAutoConnection.target">
          <drools:metaValue><![CDATA[true]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
    </bpmn2:sequenceFlow>
    <bpmn2:sequenceFlow id="_B7B4282B-F317-4BF9-95E9-962B046EE815" sourceRef="_B44545AB-8B78-4FE4-B6B9-1D467954C070" targetRef="_0617D7DF-047A-4EC4-85E7-E201D640F4F5"/>
    <bpmn2:scriptTask id="_0617D7DF-047A-4EC4-85E7-E201D640F4F5" name="Dump order" scriptFormat="http://www.java.com/java">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[Dump order]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:incoming>_B7B4282B-F317-4BF9-95E9-962B046EE815</bpmn2:incoming>
      <bpmn2:outgoing>_58684613-0155-48B2-8746-7675AFF24439</bpmn2:outgoing>
      <bpmn2:script>System.out.println(&quot;Order has been created &quot; + order + &quot; with assigned approver &quot; + approver.toUpperCase());</bpmn2:script>
    </bpmn2:scriptTask>
    <bpmn2:endEvent id="_2D876EF2-93F4-4CBE-959A-04EF7BFA9CED">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:incoming>_8216C810-34D8-4BFA-B814-1AA01907810F</bpmn2:incoming>
    </bpmn2:endEvent>
    <bpmn2:callActivity id="_9484CB12-FE52-434C-AE9F-3C3C267D1C96" drools:independent="false" drools:waitForCompletion="true" name="Add items" calledElement="demo.orderItems">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[Add items]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:incoming>_58684613-0155-48B2-8746-7675AFF24439</bpmn2:incoming>
      <bpmn2:outgoing>_8216C810-34D8-4BFA-B814-1AA01907810F</bpmn2:outgoing>
      <bpmn2:ioSpecification id="_gfw8okcJEemyodG9iPy-Bw">
        <bpmn2:dataInput id="_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputX" drools:dtype="org.kie.kogito.examples.demo.Order" itemSubjectRef="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputXItem" name="order"/>
        <bpmn2:dataOutput id="_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputX" drools:dtype="org.kie.kogito.examples.demo.Order" itemSubjectRef="__9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputXItem" name="order"/>
        <bpmn2:inputSet id="_gfw8o0cJEemyodG9iPy-Bw">
          <bpmn2:dataInputRefs>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputX</bpmn2:dataInputRefs>
        </bpmn2:inputSet>
        <bpmn2:outputSet id="_gfw8pEcJEemyodG9iPy-Bw">
          <bpmn2:dataOutputRefs>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputX</bpmn2:dataOutputRefs>
        </bpmn2:outputSet>
      </bpmn2:ioSpecification>
      <bpmn2:dataInputAssociation id="_gfw8pUcJEemyodG9iPy-Bw">
        <bpmn2:sourceRef>order</bpmn2:sourceRef>
        <bpmn2:targetRef>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderInputX</bpmn2:targetRef>
      </bpmn2:dataInputAssociation>
      <bpmn2:dataOutputAssociation id="_gfw8pkcJEemyodG9iPy-Bw">
        <bpmn2:sourceRef>_9484CB12-FE52-434C-AE9F-3C3C267D1C96_orderOutputX</bpmn2:sourceRef>
        <bpmn2:targetRef>order</bpmn2:targetRef>
      </bpmn2:dataOutputAssociation>
    </bpmn2:callActivity>
    <bpmn2:startEvent id="_B44545AB-8B78-4FE4-B6B9-1D467954C070">
      <bpmn2:extensionElements>
        <drools:metaData name="elementname">
          <drools:metaValue><![CDATA[]]></drools:metaValue>
        </drools:metaData>
      </bpmn2:extensionElements>
      <bpmn2:outgoing>_B7B4282B-F317-4BF9-95E9-962B046EE815</bpmn2:outgoing>
    </bpmn2:startEvent>
  </bpmn2:process>
  <bpmndi:BPMNDiagram id="_gfw8p0cJEemyodG9iPy-Bw">
    <bpmndi:BPMNPlane id="_gfw8qEcJEemyodG9iPy-Bw" bpmnElement="demo.Orders">
      <bpmndi:BPMNShape id="shape__B44545AB-8B78-4FE4-B6B9-1D467954C070" bpmnElement="_B44545AB-8B78-4FE4-B6B9-1D467954C070">
        <dc:Bounds height="56.0" width="56.0" x="100.0" y="100.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNShape id="shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96" bpmnElement="_9484CB12-FE52-434C-AE9F-3C3C267D1C96" isExpanded="true">
        <dc:Bounds height="101.0" width="153.0" x="458.5" y="78.0"/>
        <bpmndi:BPMNLabel>
          <dc:Bounds height="11.0" width="41.0" x="514.0" y="123.0"/>
        </bpmndi:BPMNLabel>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNShape id="shape__2D876EF2-93F4-4CBE-959A-04EF7BFA9CED" bpmnElement="_2D876EF2-93F4-4CBE-959A-04EF7BFA9CED">
        <dc:Bounds height="56.0" width="56.0" x="712.0" y="100.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNShape id="shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5" bpmnElement="_0617D7DF-047A-4EC4-85E7-E201D640F4F5">
        <dc:Bounds height="102.0" width="154.0" x="236.0" y="77.0"/>
        <bpmndi:BPMNLabel>
          <dc:Bounds height="11.0" width="48.0" x="289.0" y="122.0"/>
        </bpmndi:BPMNLabel>
      </bpmndi:BPMNShape>
      <bpmndi:BPMNEdge id="edge_shape__B44545AB-8B78-4FE4-B6B9-1D467954C070_to_shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5" bpmnElement="_B7B4282B-F317-4BF9-95E9-962B046EE815" sourceElement="shape__B44545AB-8B78-4FE4-B6B9-1D467954C070" targetElement="shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5">
        <di:waypoint xsi:type="dc:Point" x="156.0" y="128.0"/>
        <di:waypoint xsi:type="dc:Point" x="236.0" y="128.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNEdge>
      <bpmndi:BPMNEdge id="edge_shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5_to_shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96" bpmnElement="_58684613-0155-48B2-8746-7675AFF24439" sourceElement="shape__0617D7DF-047A-4EC4-85E7-E201D640F4F5" targetElement="shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96">
        <di:waypoint xsi:type="dc:Point" x="313.0" y="128.0"/>
        <di:waypoint xsi:type="dc:Point" x="458.5" y="128.5"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNEdge>
      <bpmndi:BPMNEdge id="edge_shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96_to_shape__2D876EF2-93F4-4CBE-959A-04EF7BFA9CED" bpmnElement="_8216C810-34D8-4BFA-B814-1AA01907810F" sourceElement="shape__9484CB12-FE52-434C-AE9F-3C3C267D1C96" targetElement="shape__2D876EF2-93F4-4CBE-959A-04EF7BFA9CED">
        <di:waypoint xsi:type="dc:Point" x="535.0" y="128.5"/>
        <di:waypoint xsi:type="dc:Point" x="740.0" y="128.0"/>
        <bpmndi:BPMNLabel/>
      </bpmndi:BPMNEdge>
    </bpmndi:BPMNPlane>
  </bpmndi:BPMNDiagram>
</bpmn2:definitions>
----

[id="ref-bpmn-support_{context}"]
=== BPMN2 support in {PRODUCT}

[role="_abstract"]
{PRODUCT} currently supports a subset of the https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification]. Although the {PRODUCT} BPMN modeler displays many BPMN components in the canvas palette, the {PROCESS_ENGINE} (process runtime component) in {PRODUCT} currently executes only the supported subset of components. If you use any BPMN components from the {PRODUCT} BPMN modeler palette that are not supported by the {PROCESS_ENGINE}, your {PRODUCT} project might fail to compile or execute. Additional BPMN components are added to {PRODUCT} runtime support with every release.

The following tables list the components from the BPMN2 specification that are currently supported by the {PRODUCT} runtime:

.Support status icons
[cols="30%,70%" options="header"]
|===
|Key
|Description

a|image:kogito/bpmn/grn_check.png[] | Supported by {PRODUCT} runtime
a|image:kogito/bpmn/bk_x.png[] | Not supported by {PRODUCT} runtime
|===

.BPMN2 components
[cols="25%,25%,30%,20%" options="header"]
|===
2+|Component type
|Component
|Support status

2.12+|Start events  |None              |image:kogito/bpmn/grn_check.png[]
                    |Message           |image:kogito/bpmn/grn_check.png[]
                    |Timer             |image:kogito/bpmn/grn_check.png[]
                    |Signal            |image:kogito/bpmn/grn_check.png[]
                    |Compensation      |image:kogito/bpmn/grn_check.png[]
                    |Error             |image:kogito/bpmn/bk_x.png[]
                    |Escalation        |image:kogito/bpmn/bk_x.png[]
                    |Cancel            |image:kogito/bpmn/bk_x.png[]
                    |Conditional       |image:kogito/bpmn/bk_x.png[]
                    |Link              |image:kogito/bpmn/bk_x.png[]
                    |Multiple          |image:kogito/bpmn/bk_x.png[]
                    |Parallel multiple |image:kogito/bpmn/bk_x.png[]
1.32+|Intermediate events  .11+|Catching    |Message           |image:kogito/bpmn/grn_check.png[]
                                            |Timer             |image:kogito/bpmn/grn_check.png[]
                                            |Signal            |image:kogito/bpmn/grn_check.png[]
                                            |Link              |image:kogito/bpmn/grn_check.png[]
                                            |Compensation      |image:kogito/bpmn/grn_check.png[]
                                            |Error             |image:kogito/bpmn/bk_x.png[]
                                            |Escalation        |image:kogito/bpmn/bk_x.png[]
                                            |Cancel            |image:kogito/bpmn/bk_x.png[]
                                            |Conditional       |image:kogito/bpmn/bk_x.png[]
                                            |Multiple          |image:kogito/bpmn/bk_x.png[]
                                            |Parallel multiple |image:kogito/bpmn/bk_x.png[]
                          .10+|Boundary     |Message           |image:kogito/bpmn/grn_check.png[]
                                            |Timer             |image:kogito/bpmn/grn_check.png[]
                                            |Signal            |image:kogito/bpmn/grn_check.png[]
                                            |Compensation      |image:kogito/bpmn/grn_check.png[]
                                            |Error             |image:kogito/bpmn/bk_x.png[]
                                            |Escalation        |image:kogito/bpmn/bk_x.png[]
                                            |Cancel            |image:kogito/bpmn/bk_x.png[]
                                            |Conditional       |image:kogito/bpmn/bk_x.png[]
                                            |Multiple          |image:kogito/bpmn/bk_x.png[]
                                            |Parallel multiple |image:kogito/bpmn/bk_x.png[]
                          .11+|Throwing     |Message           |image:kogito/bpmn/grn_check.png[]
                                            |Timer             |image:kogito/bpmn/bk_x.png[]
                                            |Signal            |image:kogito/bpmn/bk_x.png[]
                                            |Error             |image:kogito/bpmn/bk_x.png[]
                                            |Escalation        |image:kogito/bpmn/bk_x.png[]
                                            |Cancel            |image:kogito/bpmn/bk_x.png[]
                                            |Compensation      |image:kogito/bpmn/bk_x.png[]
                                            |Conditional       |image:kogito/bpmn/bk_x.png[]
                                            |Link              |image:kogito/bpmn/bk_x.png[]
                                            |Multiple          |image:kogito/bpmn/bk_x.png[]
                                            |Parallel multiple |image:kogito/bpmn/bk_x.png[]
2.9+|End events    |None              |image:kogito/bpmn/grn_check.png[]
                    |Message           |image:kogito/bpmn/grn_check.png[]
                    |Error             |image:kogito/bpmn/grn_check.png[]
                    |Terminate         |image:kogito/bpmn/grn_check.png[]
                    |Compensation      |image:kogito/bpmn/grn_check.png[]
                    |Signal            |image:kogito/bpmn/bk_x.png[]
                    |Escalation        |image:kogito/bpmn/bk_x.png[]
                    |Cancel            |image:kogito/bpmn/bk_x.png[]
                    |Multiple          |image:kogito/bpmn/bk_x.png[]
2.6+|Tasks    |Business rule    |image:kogito/bpmn/grn_check.png[]
              |Script           |image:kogito/bpmn/grn_check.png[]
              |User             |image:kogito/bpmn/grn_check.png[]
              |Service          |image:kogito/bpmn/grn_check.png[]
              |Send             |image:kogito/bpmn/bk_x.png[]
              |Receive          |image:kogito/bpmn/bk_x.png[]
2.4+|Subprocesses   |Embedded           |image:kogito/bpmn/grn_check.png[]
                    a|Reusable
                    (call activity)   |image:kogito/bpmn/grn_check.png[]
                    |Ad hoc             |image:kogito/bpmn/grn_check.png[]
                    |Event              |image:kogito/bpmn/bk_x.png[]
2.6+|Gateways   |Inclusive      |image:kogito/bpmn/grn_check.png[]
                |Exclusive      |image:kogito/bpmn/grn_check.png[]
                |Parallel       |image:kogito/bpmn/grn_check.png[]
                |Event-based    |image:kogito/bpmn/grn_check.png[]
                |Complex        |image:kogito/bpmn/bk_x.png[]
                |Chaining       |image:kogito/bpmn/bk_x.png[]

2.3+|Connectors   |Sequence flow     |image:kogito/bpmn/grn_check.png[]
                  |Message flow      |image:kogito/bpmn/bk_x.png[]
                  |Association       |image:kogito/bpmn/bk_x.png[]
2.2+|Collaborators    |Lane             |image:kogito/bpmn/bk_x.png[]
                      |Pool             |image:kogito/bpmn/bk_x.png[]
2.3+|Artifacts        |Group            |image:kogito/bpmn/bk_x.png[]
                      |Text annotation  |image:kogito/bpmn/bk_x.png[]
                      |Data object      |image:kogito/bpmn/bk_x.png[]
|===

For more information about BPMN components, see the Object Management Group (OMG) https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification].

[id="ref-bpmn-start-events_{context}"]
=== Start events supported in {PRODUCT}

[role="_abstract"]
BPMN start events initiate a business process. A start event cannot have an incoming sequence flow and must have only one outgoing sequence flow. You can use start events in top-level processes, embedded subprocess, and callable subprocesses where applicable.

//All start events, with the exception of the `None` start event, are catch events.  For example, a `Signal` start event starts the process only when the referenced signal (event trigger) is received.  You can configure start events in event subprocesses to be interrupting or non-interrupting. An interrupting start event for an event subprocess stops or interrupts the execution of the containing or parent process. A non-interrupting start event does not stop or interrupt the execution of the containing or parent process.

{PRODUCT} currently supports the following start events:

.Supported start events
[cols="25%,25%,25%,25%" options="header"]
|===
|Start event type
|Top-level processes
2+|Subprocesses

|
|
h|Interrupt
h|Non-interrupt

|None
|image:kogito/bpmn/bpmn-start-node.png[]
|Not applicable
|Not applicable

|Message
|image:kogito/bpmn/bpmn-message-node.png[]
|image:kogito/bpmn/bpmn-message-node.png[]
|image:kogito/bpmn/bpmn-message-non-interrupt.png[]

|Timer
|image:kogito/bpmn/bpmn-timer-start.png[]
|image:kogito/bpmn/bpmn-timer-start.png[]
|image:kogito/bpmn/bpmn-timer-non-interrupt.png[]

|Signal
|image:kogito/bpmn/bpmn-signal-start.png[]
|image:kogito/bpmn/bpmn-signal-start.png[]
|image:kogito/bpmn/bpmn-signal-non-interrupt.png[]
|===

////
|Conditional
|image:kogito/bpmn/bpmn-conditional-start.png[]
|image:kogito/bpmn/bpmn-conditional-start.png[]
|image:kogito/bpmn/bpmn-conditional-non-interrupt.png[]

|Compensation
|image:kogito/bpmn/bpmn-compensation-start.png[]
|image:kogito/bpmn/bpmn-compensation-start.png[]
|

|Error
|
|image:kogito/bpmn/bpmn-error-start.png[]
|

|Escalation
|image:kogito/bpmn/bpmn-escalation-start.png[]
|image:kogito/bpmn/bpmn-escalation-start.png[]
|image:kogito/bpmn/bpmn-escalation-non-interrupt.png[]
////

None::
+
--
The none start event is a start event without a trigger condition. A process or a subprocess can contain at most one none start event, which is triggered on process or subprocess start by default, and the outgoing flow is taken immediately.

When you use a none start event in a subprocess, the execution of the process flow is transferred from the parent process into the subprocess and the none start event is triggered. This means that the token (the current location within the process flow) is passed from the parent process into the subprocess activity and the none start event of the subprocess generates a token of its own.
--

Message::
+
--
A process can contain multiple message start events, which are triggered by a particular message. The process instance with a message start event starts its execution from this event after it has received the respective message. After the message is received, the process is instantiated and its message start event is executed immediately (its outgoing flow is taken).

Because a message can be consumed by an arbitrary number of processes and process elements, including no elements, one message can trigger multiple message start events and therefore instantiate multiple processes.
--

Timer::
+
--
The timer start event is a start event with a timing mechanism that is triggered at the start of the process. A process can contain multiple timer start events.

When you use a timer start event in a subprocess, execution of the process flow is transferred from the parent process into the subprocess and the timer start event is triggered. The token is taken from the parent subprocess activity and the timer start event of the subprocess is triggered and waits for the timer to trigger.

After the time defined by the timer definition is reached, the outgoing flow is taken.
--

Signal::
+
--
The signal start event is triggered by a signal with a particular signal code. The signal start event is triggered when the process instance receives the required signal, and then the signal start event is executed and its outgoing flow is taken. A process can contain multiple signal start events.
--

////
.Conditional

The conditional start event is a start event with a Boolean condition definition. The execution is triggered when the condition is first evaluated to `false` and then to ``true``. The process execution starts only if the condition is evaluated to `true` after the start event has been instantiated.

A process can contain multiple conditional start events.

.Compensation

A compensation start event is used to start a compensation event subprocess when using a subprocess as the target activity of a compensation intermediate event.

.Error
A process or subprocess can contain multiple error start events, which are triggered when an error object with a particular `ErrorRef` property is received.
The error object can be produced by an error end event. It indicates an incorrect process ending. The process instance with the error start event starts execution after it has received the respective error object. The error start event is executed immediately upon receiving the error object and its outgoing flow is taken.

.Escalation


The escalation start event is a start event that is triggered by an escalation with a particular escalation code. Processes can contain multiple escalation start events. The process instance with an escalation start event starts its execution when it receives the defined escalation object. The process is instantiated and the escalation start event is executed immediately and its outgoing flow is taken.
////

[id="ref-bpmn-intermediate-events_{context}"]
=== Intermediate events supported in {PRODUCT}

[role="_abstract"]
BPMN intermediate events drive the flow of a business process. Intermediate events catch or throw an event during the execution of the business process. You can add these events between start and end events or as a catch event on the boundary of an activity, such as a subprocess or a user task. You can configure boundary catch events as interrupting or non-interrupting events. An interrupting boundary catch event cancels the bound activity whereas a non-interrupting event does not.

An intermediate event handles a particular situation that occurs during process execution. The situation is a trigger for an intermediate event. In a process, you can add an intermediate event with one outgoing flow to an activity boundary.

If the event occurs while the activity is being executed, the event triggers its execution to the outgoing flow. One activity may have multiple boundary intermediate events. Note that depending on the behavior you require from the activity with the boundary intermediate event, you can use either of the following intermediate event types:

* Interrupting: The activity execution is interrupted and the execution of the intermediate event is triggered.
* Non-interrupting: The intermediate event is triggered and the activity execution continues.

{PRODUCT} currently supports the following intermediate events:

.Supported intermediate events
[cols="20%,20%,20%,20%,20%", options="header"]
|===
|Intermediate event type
|Catching
|Boundary
|
|Throwing

h|
h|
h|Interrupt
h|Non-interrupt
h|

|Message
|image:kogito/bpmn/bpmn-intermediate-message.png[]
|image:kogito/bpmn/bpmn-intermediate-message.png[]
|image:kogito/bpmn/bpmn-message-noninterrupt.png[]
|image:kogito/bpmn/bpmn-message-throwing.png[]

|Timer
|image:kogito/bpmn/bpmn-intermediate-timer.png[]
|image:kogito/bpmn/bpmn-intermediate-timer.png[]
|image:kogito/bpmn/bpmn-timer-noninterrupt.png[]
|Not applicable

|Signal
|image:kogito/bpmn/bpmn-intermediate-signal.png[]
|image:kogito/bpmn/bpmn-intermediate-signal.png[]
|image:kogito/bpmn/bpmn-signal-noninterrupt.png[]
|Not applicable
//image:kogito/bpmn/bpmn-signal-throwing.png[]  (@comment: Use for Throwing here when supported. Stetson, 17 Mar 2020)

|Link
|image:kogito/bpmn/bpmn-link-catching.png[]
|Not applicable
|Not applicable
|image:kogito/bpmn/bpmn-link-throwing.png[]

|Compensation
|image:kogito/bpmn/bpmn-intermediate-catch.png[]
|image:kogito/bpmn/bpmn-intermediate-catch.png[]
|Not applicable
|image:kogito/bpmn/bpmn-intermediate-compensation-throwing.png[]
|===

////
|Error
|
|image:kogito/bpmn/bpmn-intermediate-error.png[]
|
|

|Conditional
|image:kogito/bpmn/bpmn-intermediate-conditional.png[]
|image:kogito/bpmn/bpmn-intermediate-conditional.png[]
|image:kogito/bpmn/bpmn-conditional-noninterrupt.png[]
|

|Escalation
|image:kogito/bpmn/bpmn-intermediate-escalation.png[]
|image:kogito/bpmn/bpmn-intermediate-escalation.png[]
|image:kogito/bpmn/bpmn-intermediate-escalation-non-interrupting.png[]
|image:kogito/bpmn/bpmn-intermediate-escalation-throwing.png[]
////

Message::
+
--
A message intermediate event is an intermediate event that enables you to manage a message object. Use one of the following events:

* A throwing message intermediate event produces a message object based on the defined properties.
* A catching message intermediate event listens for a message object with the defined properties.
--

Timer::
+
--
A timer intermediate event enables you to delay workflow execution or to trigger the workflow execution periodically. It represents a timer that can trigger one or multiple times after a specified period of time. When the timer intermediate event is triggered, the defined timer condition is checked and the outgoing flow is taken.

When you add a timer intermediate event in the process workflow, it has one incoming flow and one outgoing flow. Its execution starts when the incoming flow transfers to the event. When you add a timer intermediate event on an activity boundary, the execution is triggered at the same time as the activity execution.

The timer is canceled if the timer element is canceled, for example, by completing or aborting the enclosing process instance.
--

Signal::
+
--
A signal intermediate event enables you to produce or consume a signal object. Use either of the following options:

* A throwing signal intermediate event produces a signal object based on the defined properties.
* A catching signal intermediate event listens for a signal object with the defined properties.
--

Link::
+
--
A link intermediate event enables you to jump from one place of the diagram to another. A link intermediate event is equivalent to the `goto` functionality in older programming languages.

Use throwing and catching link intermediate events together, where each functions in the following way:

* A throwing link intermediate event refers to the target catching node.
* A catching link intermediate event refers to the source throwing node.
--

Compensation::
+
--
A compensation intermediate event is a boundary event attached to an activity in a transaction subprocess. It can finish with a compensation end event or a cancel end event. The compensation intermediate event must be associated with a flow, which is connected to the compensation activity.

The activity associated with the boundary compensation intermediate event is executed if the transaction subprocess finishes with the compensation end event. The execution continues with the respective flow.
--

////
.Conditional

A conditional intermediate event is an intermediate event with a boolean condition as its trigger. The event triggers further workflow execution when the condition evaluates to `true` and its outgoing flow is taken.

The event must define the [property]``Expression`` property. When a conditional intermediate event is placed in the process workflow, it has one incoming flow, one outgoing flow, and its execution starts when the incoming flow transfers to the event. When a conditional intermediate event is placed on an activity boundary, the execution is triggered at the same time as the activity execution. Note that if the event is non-interrupting, the event triggers continuously while the condition is ``true``.


.Error

An error intermediate event is an intermediate event that can be used only on an activity boundary. It enables the process to react to an error end event in the respective activity.
The activity must not be atomic. When the activity finishes with an error end event that produces an error object with the respective `ErrorCode` property, the error intermediate event catches the error object and execution continues to its outgoing flow.



.Escalation

An escalation intermediate event is an intermediate event that enables you to produce or consume an escalation object. Depending on the action the event element should perform, you need to use either of the following options:

* A throwing escalation intermediate event produces an escalation object based on the defined properties.
* A catching escalation intermediate event listens for an escalation object with the defined properties.
////

[id="ref-bpmn-end-events_{context}"]
=== End events supported in {PRODUCT}

[role="_abstract"]
BPMN end events terminate a business process. An end event has one or more incoming sequence flows and typically has no outgoing flows. A business process can contain multiple end events. All end events, with the exception of the none and terminate end events, are throw events. A process must contain at least one end event.

During runtime, an end event finishes the process workflow. The end event can finish only the workflow that reached it, or all workflows in the process instance, depending on the end event type.

{PRODUCT} currently supports the following end events:

.Supported end events
[cols="30%,70%" options="header"]

|===
h|End event type
h|Icon

|None
|image:kogito/bpmn/bpmn-end-node.png[]

|Message
|image:kogito/bpmn/bpmn-end-message.png[]

|Error
|image:kogito/bpmn/bpmn-end-error.png[]

|Terminate
|image:kogito/bpmn/bpmn-end-terminate.png[]

|Compensation
|image:kogito/bpmn/bpmn-end-compensation.png[]
|===

////
|Escalation
|image:kogito/bpmn/bpmn-end-escalation.png[]

|Signal
|image:kogito/bpmn/bpmn-end-signal.png[]
////

None::
+
--
The none end event specifies that no other special behavior is associated with the end of the process.
--

Message::
+
--
When a flow enters a message end event, the flow finishes and the end event produces a message as defined in its properties.
--

Error::
+
--
The throwing error end event finishes the incoming workflow (consumes the incoming token) and produces an error object. Any other running workflows in the process or subprocess remain uninfluenced.
--

Terminate::
+
--
The terminate end event finishes all execution flows in the specified process or subprocess instance. Activities being executed are canceled. A terminate end event inside a subprocess ends the subprocess instance but does not automatically end the parent process instance.
--

Compensation::
+
--
A compensation end event is used to finish a transaction subprocess and trigger the compensation defined by the compensation intermediate event attached to the boundary of the subprocess activities.
--

////
.Signal

A throwing signal end event is used to finish a process or subprocess flow. When the execution flow enters the element, the execution flow finishes and produces a signal identified by its `SignalRef` property.

.Escalation

The escalation end event finishes the incoming workflow, which means consumes the incoming token, and produces an escalation signal as defined in its properties, triggering the escalation process.
////

[id="ref-bpmn-tasks_{context}"]
=== Tasks supported in {PRODUCT}

[role="_abstract"]
BPMN tasks identify actions to be completed in a business process model and are the smallest unit of work in a process flow.

{PRODUCT} currently supports the following tasks:

.Supported tasks
[cols="40%,60%", options="header"]
|===
| Task type
| Task node

| Business rule task
| image:kogito/bpmn/bpmn-business-rule-task.png[]

| Script task
| image:kogito/bpmn/bpmn-script-task.png[]

| User task
| image:kogito/bpmn/bpmn-user-task.png[]

| Service task
| image:kogito/bpmn/bpmn-service-task.png[]
|===

////
//@comment: Currently unavailable in VSCode. (Stetson, 26 Mar 2020)
In addition, the BPMN2 specification provides the ability to create custom tasks. The following predefined custom tasks are included with {PRODUCT}:

* Rest service tasks: Used to invoke a remote RESTful service
* Email service tasks: Used to send an email
* Log service tasks: Used to log a message
* Java service tasks: Used to call Java code
* WebService service tasks: Used to invoke a remote WebService call
* DecisionTask tasks: Used to execute a DMN diagram
////

Business rule task::
+
--
A business rule task specifies a business decision to be executed either through a Decision Model and Notation (DMN) model or a Drools Rule Language (DRL) rule unit.

When a process reaches a business rule task defined by a DMN model, the {PROCESS_ENGINE} executes the DMN model decision with the inputs provided.

When a process reaches a business rule task defined by a DRL rule unit, the {PROCESS_ENGINE} begins executing the rules in the designated rule unit group. When there are no more active rules in the rule unit, the execution continues to the next element. During the rule unit execution, new activations in the rule unit are added to the {DECISION_ENGINE} agenda because these activations are changed by other rules.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected business rule task:

.Business rule task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Rule Language*
| Determines whether the task invokes a decision from a Decision Model and Notation (DMN) model or a Drools Rule Language (DRL) rule unit.

| *Rule Flow Group* (for DRL)
| Defines the DRL rule unit in the format `unit:__PACKAGE_NAME__.__UNIT_NAME__`, such as `unit:org.acme.PersonRules`. This rule unit syntax specifies that you are using a rule unit instead of a traditional rule flow group.

| *Namespace*, *Decision Name*, *DMN Model Name* (for DMN)
| Identifies the relevant DMN model as found in the DMN model file.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the task, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the task, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.
|===
--

Script task::
+
--
A script task represents a script to be executed during the process execution. The associated script can access process variables. When a script task is reached during execution, the script is executed and the outgoing flow is taken.

Review the following list of suggestions before using a script task:

* Avoid low-level implementation details in the process. Although you can use a script task to manipulate variables, consider using a service task when modeling more complex operations.
* Ensure that the script is executed immediately. If the script is not intended to be executed immediately, consider using an asynchronous service task.
* Avoid contacting external services through a script task. Use a service task to model communication with an external service.
* Ensure scripts do not generate exceptions. Runtime exceptions should be caught and managed inside the script or transformed into signals or errors that can then be handled inside the process.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected script task:

.Script task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Script*
| Defines a Java, JavaScript, or MVEL script to be executed by the task and specifies the script type.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.
|===
--

User task::
+
--
A user task is an activity in the process workflow that cannot be performed automatically by the system and therefore requires the intervention of a human user, or _actor_.

On execution, the user task element is instantiated as a task that appears in the list of tasks of one or more actors. If a user task element defines the `Groups` property, the task is displayed in task lists of all users that are members of the group. Any user who is a member of the group can claim the task. After a user task is claimed, the task disappears from the task list of the other users.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected user task:

.User task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Task Name*
| Identifies the name of the task as it is displayed to human user (actor).

| *Subject*
| Defines the subject for the task.

| *Actors*
| Specifies the authorized human users (actors) who can complete the user task. Click *Add* to add a row and then select an actor from the list or click *New* to add a new actor.

| *Groups*
| Specifies the authorized group of human users (actors) who can complete the user task. Click *Add* to add a row and then select a group from the list or click *New* to add a new group. Any actor in the group can complete the user task.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.

| *Reassignments*
| Specifies a different actor to complete the task.

| *Notifications*
| Defines notifications associated with the task.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *Skippable*
| Determines whether the task is optional and can be skipped.

| *Priority*
| Defines a priority for the task.

| *Description*
| Describes the task as it is displayed to a human user (actor).

| *Created By*
| Specifies the human user (actor) who created the task. Click *Add* to add a row and then select a user from the list or click *New* to add a new user.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *Multiple Instance*
| Determines whether this task has multiple instances.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the task, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the task, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *Content*
| Defines the content of the script.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.
|===
--

Service task::
+
--
A service task is an activity that is completed automatically by an external software service and does not require human interaction.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected service task:

.Service task properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the task.

| *Documentation*
| Describes the task. The text in this field is included in the process documentation, if applicable.

| *Implementation*
| Determines whether the task is implemented in Java or is a web service.

| *Interface*
| Defines the class used to implement the script, for example, `org.xyz.HelloWorld`.

| *Operation*
| Defines the method called by the interface, for example, `sayHello()`.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.

| *AdHoc Autostart*
| Determines whether this is an ad hoc task that is started automatically. This option enables the task to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.

| *Is Async*
|  Determines whether this task is invoked asynchronously. Make tasks asynchronous if they cannot be executed instantaneously, such as a task performed by an outside service.

| *Multiple Instance*
| Determines whether this task has multiple instances.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the task, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the task, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.
|===
--

////
.None task
None tasks are completed on activation. This is a conceptual model only. A none task is never actually executed by an IT system.

image::kogito/bpmn/bpmn-none-task.png[]
////

[id="ref-bpmn-custom-tasks_{context}"]
=== Custom tasks supported in {PRODUCT}

[role="_abstract"]
The BPMN specification supports the ability to extend the `bpmn2:task` element to create custom tasks in a software implementation. Similar to standard BPMN tasks, custom tasks identify actions to be completed in a business process model, but they also include specialized functionality, such as compatibility with an external service of a specific type (REST, email, or web service) or checkpoint behavior within a process (milestone).

{PRODUCT} provides predefined custom tasks under *Custom Tasks* in the BPMN modeler palette, but currently does not support the ability for you to define your own custom task extensions.

{PRODUCT} currently supports the following predefined custom tasks:

.Supported custom tasks
[cols="40%,60%", options="header"]
|===
| Custom task type
| Custom task node

| Milestone
| image:kogito/bpmn/bpmn-milestone.png[]
|===


Milestone::
+
--
A milestone represents a single point of achievement within a process instance. You can use milestones to flag certain events to trigger other tasks or track the progress of the process. Milestones are useful for Key Performance Indicator (KPI) tracking or for identifying the tasks that are still to be completed. Milestones can occur at the end of a stage in a process or they can be the result of achieving other milestones.

A milestone typically uses a defined input condition that must be met in order to complete the milestone. If no input condition is defined, the milestone is completed automatically when the process reaches the milestone. You can also configure milestones with the `AdHoc Autostart` property to be triggered automatically when the process starts or you can set the *Signal* definition in a signal event in the process to trigger the milestone explicitly. Milestones can be triggered as many times as required. A milestone is achieved when the condition is met or is achieved automatically if no condition is defined.

In the following example process, several milestones control the process for IT hardware orders. For example, when the condition for the `Order placed` milestone is met, the completed milestone triggers a notification script task and leads to an end signal event that triggers the next `Order shipped` milestone, and so on to subsequent milestones until the process is complete.

.Example process with milestones
image::kogito/bpmn/bpmn-milestone-example.png[Image of example process with milestones]

.Example end signal event configured to trigger the next milestone
image::kogito/bpmn/bpmn-milestone-example-signal.png[Image of example signal configuration with a milestone]

Milestones can reach the following states during process execution:

* `Active`: A milestone condition has been defined for the milestone node but it has not been met.
* `Completed`: A milestone condition has been met (if applicable), the milestone has been achieved, and the process can proceed to the next task or can end.
//* `Terminated`: The milestone is no longer a part of the process and is no longer required.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected milestone:

.Milestone properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the milestone.

| *Documentation*
| Describes the milestone. The text in this field is included in the process documentation, if applicable.

| *Is Async*
|  Determines whether this milestone is invoked asynchronously. Make milestones asynchronous if they cannot be executed instantaneously, such as in a process performed by an outside service.

| *AdHoc Autostart*
| Determines whether this is an ad hoc milestone that is started automatically. This option enables the milestone to automatically start when the process is created instead of being started by a signal event.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the milestone, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the milestone, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Assignments*
a| Defines data input and output for the milestone. Click to open the *Data I/O* window and add data input and output as required. A milestone typically uses a defined input condition that must be met in order to complete the milestone. If no input condition is defined, the milestone is completed automatically when the process reaches the milestone.

For each milestone that requires a condition, enter at least one input data assignment with the following values:

* *Name*: `Condition`
* *Data Type*: `String`
* *Source*: Enter a Java expression for the condition to be met, such as `order.isShipped()` in a process that uses an `order` process variable.
|===
--

[id="ref-bpmn-subprocesses_{context}"]
=== Subprocesses supported in {PRODUCT}

[role="_abstract"]
BPMN subprocesses are portions of a parent process that contain process nodes. You can embed part of the parent process within a subprocess. You can also include variable definitions within the subprocess. These variables are accessible to all nodes inside the subprocess.

A subprocess must have one incoming connection and one outgoing connection. A terminate end event inside a subprocess ends the subprocess instance but does not automatically end the parent process instance. A subprocess ends when there are no more active elements in it.

//@comment: Excluded for now until multiple-instance subprocesses are officially supported in Kogito. (Stetson, 19 June 2020)
//A multiple-instance subprocess is instantiated multiple times when its execution is triggered. The instances are created sequentially. A new subprocess instance is created only after the previous instance has finished. A multiple-instance subprocess has one incoming connection and one outgoing connection.

In the following example, the `Place order` subprocess checks whether sufficient stock is available to place the order and updates the stock information if the order can be placed. The customer is then notified through the main process based on whether the order was placed.

.Example subprocess
image::kogito/bpmn/subprocess.png[]

{PRODUCT} currently supports the following subprocesses:

.Supported subprocesses
[cols="40%,60%", options="header"]
|===
| Subprocess type
| Subprocess node

| Embedded subprocess
| image:kogito/bpmn/bpmn-embedded-subprocess.png[]

| Ad hoc subprocess
| image:kogito/bpmn/bpmn-adhoc-subprocess.png[]

| Reusable subprocess
| image:kogito/bpmn/bpmn-reusable-subprocess.png[]
|===

Embedded subprocess::
+
--
An embedded subprocess encapsulates a part of the parent process and shares the parent process data. This subprocess must contain a start event and at least one end event. You can define local subprocess variables that are accessible to all elements inside this container.

NOTE: Multiple-instance behavior is currently not supported for embedded subprocesses in {PRODUCT}.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected embedded subprocess:

.Embedded subprocess properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the subprocess.

| *Documentation*
| Describes the subprocess. The text in this field is included in the process documentation, if applicable.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *Is Async*
|  Determines whether this subprocess is invoked asynchronously. Make subprocesses asynchronous if they cannot be executed instantaneously, such as a subprocess performed by an outside service.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Process Variables*
| Defines any process variables for the subprocess. Process variables are visible within the specific subprocess instance. Process variables are initialized at subprocess creation and destroyed on subprocess completion. Variable *Tags* provide greater control over the variable behavior, such as whether the variable is `required` or `internal`. For more information about variable tags, see xref:con-bpmn-variables_kogito-developing-process-services[].
|===
--

Ad hoc subprocess::
+
--
An ad hoc subprocess contains embedded inner activities and is intended to be executed with a more flexible ordering compared to the typical routing of processes. Unlike typical processes, an ad hoc subprocess does not contain a complete, structured BPMN diagram description, such as from a start event to an end event. Instead, the ad hoc subprocess contains only activities, sequence flows, gateways, and intermediate events. An ad hoc subprocess can also contain data objects and data associations.

The activities within ad hoc subprocesses are not required to have incoming and outgoing sequence flows. However, you can specify sequence flows between some of the contained activities. Sequence flows provide the same ordering constraints in ad hoc subprocesses as in a typical process. Any intermediate events must have outgoing sequence flows and they can be triggered multiple times while the ad hoc subprocess is active.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected ad hoc subprocess:

.Ad hoc subprocess properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the subprocess.

| *Documentation*
| Describes the subprocess. The text in this field is included in the process documentation, if applicable.

| *AdHocActivationCondition*
a| Defines a Java expression that determines when the subprocess is activated, such as `order.isShipped()` in a process that uses an `order` process variable. To activate the subprocess automatically when the parent process starts, leave this field empty with no condition specified.

NOTE: This field supports only Java expressions and does not support Drools expressions as indicated in the field label. This label will be updated in a future release.

| *AdHocCompletionCondition*
a| Defines a Java expression that determines when the subprocess is completed, such as `order.isDelivered()` in a process that uses an `order` process variable. By default, this field contains the value `autocomplete` to complete the subprocess automatically when the subprocess ends.

NOTE: This field supports only Java expressions and does not support Drools and MVEL expressions as indicated in the field label. This label will be updated in a future release.

| *AdHocOrdering*
| Not supported in {PRODUCT}. This property specifies whether the subprocess is executed in *Sequential* or *Parallel* order in the parent process, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *AdHoc Autostart*
| Determines whether this ad hoc subprocess is started automatically. This option enables the subprocess to automatically start when the subprocess is created instead of being started by the completion of the previous node or by a signal event.

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *Is Async*
|  Determines whether this subprocess is invoked asynchronously. Make subprocesses asynchronous if they cannot be executed instantaneously, such as a subprocess performed by an outside service.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Process Variables*
| Defines any process variables for the subprocess. Process variables are visible within the specific subprocess instance. Process variables are initialized at subprocess creation and destroyed on subprocess completion. Variable *Tags* provide greater control over the variable behavior, such as whether the variable is `required` or `internal`. For more information about variable tags, see xref:con-bpmn-variables_kogito-developing-process-services[].
|===
--

Reusable subprocess::
+
--
A reusable subprocess calls another process or subprocess instance to be used within a parent process. This subprocess enables you to reuse the same process repeatedly without manually duplicating the subprocess.  This subprocess typically appears collapsed within the parent process.

In the {PRODUCT} BPMN modeler, you can modify the following properties for a selected reusable subprocess:

.Reusable subprocess properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Identifies the name of the subprocess.

| *Documentation*
| Describes the subprocess. The text in this field is included in the process documentation, if applicable.

| *Called Element*
| Specifies the ID of the process or subprocess that the activity calls and instantiates.

| *Independent*
| Determines whether the subprocess is started and completed independently of the parent process or whether the subprocess is canceled when the parent process is terminated.

| *Abort Parent*
| (Available only when *Independent* is not selected.) Determines whether a dependent reusable subprocess can abort the parent process when the subprocess is aborted or when an error occurs during the subprocess execution.

| *Wait for completion*
| Determines whether the parent process must wait for this subprocess to complete before continuing.

| *Is Async*
|  Determines whether this subprocess is invoked asynchronously. Make subprocesses asynchronous if they cannot be executed instantaneously, such as a subprocess performed by an outside service.

| *Multiple Instance*
a| Determines whether the subprocess is executed multiple times. When you select this option, the following additional options appear:

* *MI Execution mode*: Specifies whether the multiple subprocess instances are executed in *Sequential* or *Parallel* order as each instance is triggered. In sequential order, a triggered subprocess starts only after the previous subprocess instance completes. In parallel order, a subprocess instance starts whenever it is triggered and can run in parallel with any other triggered subprocesses.
* *MI Collection input*: Specifies the process variable that represents a collection of elements for which new instances are created. The subprocess is instantiated as many times as needed according to the size of the collection.
* *MI Data Input*: Specifies the name of the process variable that contains the selected element in the collection. The variable is used to access elements in the collection.
* *MI Collection output*: (Optional) Specifies the process variable that represents the collection of elements that gather the output of the multi-instance node.
* *MI Data Output*: Specifies the name of the process variable that is added to the output collection that you selected in the *MI Collection output* property.
* *MI Completion Condition*: Not supported in {PRODUCT}. This property defines a Java expression that is evaluated on each completed subprocess instance, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

////
//@comment: MI Completion Condition description for when it is supported. (Stetson, 1 July 2020)
Defines a Java expression that is evaluated on each completed subprocess instance to verify if the specified multi-instance node can complete, such as `order.isShipped()` in a process that uses an `order` process variable. When the completion condition is met, in sequential execution mode, no other subprocess instances are created, and in parallel execution mode, any running subprocess instances are cancelled.

NOTE: The *MI Completion Condition* field supports only Java expressions and does not support MVEL expressions as indicated in the field label. This label will be updated in a future release.
////

| *On Entry Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the start of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *On Exit Action*
| Not supported in {PRODUCT}. This property defines a Java, JavaScript, or MVEL script that directs an action at the end of the subprocess, and is currently available only in distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.

| *SLA Due Date*
| Specifies the date when the service level agreement (SLA) expires.

| *Assignments*
| Defines data input and output for the task. Click to open the *Data I/O* window and add data input and output as required.
|===
--

////
.Event subprocess


An event subprocess becomes active when its start event is triggered. It can interrupt the parent process context or run in parallel with it.

With no outgoing or incoming connections, only an event or a timer can trigger the subprocess. The subprocess is not part of the regular control flow.
Although self-contained, it is executed in the context of the bounding process.

Use an event subprocess within a process flow to handle events that happen outside of the main process flow.
For example, while booking a flight, two events may occur:

* Cancel booking (interrupting)
* Check booking status (non-interrupting)

You can model both of these events using the event subprocess.
////

[id="ref-bpmn-gateways_{context}"]
=== Gateways supported in {PRODUCT}

[role="_abstract"]
BPMN gateways create or synchronize branches in a process workflow using a set of conditions in a gating mechanism. BPMN2 supports _converging gateways_ that merge multiple flows into one flow, and _diverging gateways_ that split one flow into multiple flows. One gateway cannot have multiple incoming and multiple outgoing flows.

In the following business process diagram, the exclusive (XOR) gateway evaluates only the incoming flow whose condition evaluates to true:

.Example process with exclusive gateway
image::kogito/bpmn/gateway.png[]

In this example, the customer details are verified by a user and the process is assigned to a user for approval. If the request is approved, an approval notification is sent to the user. If the request is rejected, a rejection notification is sent to the user.

{PRODUCT} currently supports the following gateways:

.Supported gateways
[cols="30%,70%" options="header"]
|===
h|Gateway type
h|Icon

|Exclusive (XOR)
|image:kogito/bpmn/bpmn-gateway-exclusive.png[]

|Inclusive (OR)
|image:kogito/bpmn/bpmn-gateway-inclusive.png[]

|Parallel (AND)
|image:kogito/bpmn/bpmn-gateway-parallel.png[]

|Event (AND)
|image:kogito/bpmn/bpmn-gateway-event.png[]
|===

Exclusive::
+
--
A diverging exclusive gateway selects only the first incoming flow that evaluates to true and that contains the lowest `priority` number, if applicable. A converging exclusive gateway activates the next node for each triggered incoming flow.

[IMPORTANT]
====
Ensure that at least one of the outgoing flows evaluates to true at runtime. If no outgoing flows evaluate to true, the process instance terminates with a runtime exception.

Although priorities are evaluated in {PRODUCT}, the BPMN2 specification does not guarantee the priority order. Avoid depending on the `priority` attribute in your workflow.
====

A converging exclusive gateway also enables a workflow branch to continue to its outgoing flow as soon as it reaches the gateway. When one of the incoming flows triggers the gateway, the workflow continues to the outgoing flow of the gateway. If a gateway is triggered by more than one incoming flow, the gateway activates the next node for each trigger.
--

Inclusive::
+
--
A diverging inclusive gateway selects the incoming flow and all outgoing flows that evaluate to true. Connections with lower `priority` numbers are triggered before triggering higher `priority` connections. Although priorities are evaluated, the BPMN2 specification does not guarantee the priority order. Avoid depending on the `priority` attribute in your workflow.

[IMPORTANT]
====
Ensure that at least one of the outgoing flows evaluates to true at runtime. If no outgoing flows evaluate to true, the process instance terminates with a runtime exception.

Although priorities are evaluated in {PRODUCT}, the BPMN2 specification does not guarantee the priority order. Avoid depending on the `priority` attribute in your workflow.
====
A converging inclusive gateway also merges all incoming flows previously created by an inclusive diverging gateway. A converging inclusive gateway acts as a synchronizing entry point for the inclusive gateway branches.
--

Parallel::
+
--
A parallel gateway synchronizes and creates parallel flows. A diverging parallel gateway selects the incoming flow and all outgoing flows simultaneously. A converging parallel gateway waits until all incoming flows have entered and then triggers the outgoing flow.
--

Event::
+
--
An event gateway is only diverging and reacts to possible events, as opposed to the data-based exclusive gateway that reacts to the process data. An event gateway selects the outgoing flow based on the event that occurs, and selects only one outgoing flow at a time. An event gateway might act as a start event, where the process is instantiated only if one of the intermediate events connected to the event-based gateway occurs.
--

[id="ref-bpmn-connectors_{context}"]
=== Connectors supported in {PRODUCT}

[role="_abstract"]
BPMN connectors create an association between two components in a process. When a connector is directed, the association is sequential and indicates that one of the elements is executed immediately before the other within an instance of the process. Connectors can start and end at the top, bottom, right, or left of the process components being associated. The BPMN2 specification allows you to use your discretion, placing connectors in a way that makes the process behavior easy to follow and understand.

{PRODUCT} currently supports only sequence flow connectors. A sequence flow connects elements of a process and defines the order in which those elements are executed within an instance.

////
* Sequence flows: Connect elements of a process and define the order in which those elements are executed within an instance.
* Association flows: Connect the elements of a process without execution semantics. Association flows can be undirected or unidirectional.

NOTE: The new process modeler supports only undirected association flows. The legacy modeler supports one direction and Unidirection flows.
////

[id="proc-bpmn-model-creating_{context}"]
== Creating and editing BPMN models in the {PRODUCT} BPMN modeler

[role="_abstract"]
You can use the {PRODUCT} BPMN modeler in VSCode to design BPMN process models and define process logic for a complete and functional BPMN model.

{PRODUCT} currently supports a subset of the https://www.omg.org/spec/BPMN/2.0/About-BPMN[Business Process Model and Notation 2.0 specification]. Although the {PRODUCT} BPMN modeler displays many BPMN components in the canvas palette, the {PROCESS_ENGINE} (process runtime component) in {PRODUCT} currently executes only the supported subset of components. If you use any BPMN components from the {PRODUCT} BPMN modeler palette that are not supported by the {PROCESS_ENGINE}, your {PRODUCT} project might fail to compile or execute. Additional BPMN components are added to {PRODUCT} runtime support with every release.

For more information about BPMN2 support in {PRODUCT}, see xref:ref-bpmn-support_kogito-developing-process-services[].

.Prerequisites
* https://code.visualstudio.com/[VSCode] 1.46.0 or later is installed.
* The *{PRODUCT} Bundle* VSCode extension is installed and enabled in your VSCode IDE. For information about enabling the VSCode extension, see {URL_CREATING_RUNNING}#proc-kogito-vscode-extension_kogito-creating-running[_{CREATING_RUNNING}_].
* You have created a {PRODUCT} project and have included any Java objects required for your {PRODUCT} service. For information about creating a project, see {URL_CREATING_RUNNING}#chap-kogito-creating-running[_{CREATING_RUNNING}_].

.Procedure
. In your VSCode IDE, create or import a BPMN file in the relevant folder of your {PRODUCT} project, typically in `src/main/resources`.
+
NOTE: For a new BPMN file, you can also enter `bpmn.new` in a web browser to design your business process in the {PRODUCT} online BPMN modeler. When you finish creating your process model, you can click *Download* in the online modeler page to import your BPMN file into your {PRODUCT} project.

. Open the new or imported BPMN file to view the process diagram in the {PRODUCT} BPMN modeler.
+
--
If the process diagram does not open in the {PRODUCT} BPMN modeler, ensure that you have installed and enabled the *{PRODUCT} Bundle* VSCode extension.

If the {PRODUCT} BPMN modeler opens only the XML source of the BPMN file and displays an error message, review the reported errors and the BPMN model file to ensure that all BPMN elements are correctly defined.
--
. Select the background of the BPMN modeler canvas and, in the upper-right corner of the modeler, click *Properties* to add or verify information for the BPMN file as described in the following table:
+
--
.General process properties
[cols="30%,70%", options="header"]
|===
|Label
|Description

| *Name*
| Enter the name of the process.

| *Documentation*
| Describes the process. The text in this field is included in the process documentation, if applicable.

| *ID*
| Enter an identifier for this process, such as `orderItems`.

| *Package*
| Enter the package location for this process in your {PRODUCT} project, such as `org.acme`.

| *ProcessType*
| Specify whether the process is public or private (or null, if not applicable).

| *Version*
| Enter the artifact version for the process.

| *Ad hoc*
| Select this option if this process is a flexible process that uses other ad hoc auto-start fragments and that does not require strict start and end events.

| *Process Instance Description*
| Enter a description of the process purpose.

| *Imports*
| Click to open the *Imports* window and add any data object classes required for your process.

| *Executable*
| Select this option to make the process executable as part of your {PRODUCT} project.

| *SLA Due Date*
| Enter the date when the service level agreement (SLA) expires.

| *Process Variables*
| Add any process variables for the process. Process variables are visible within the specific process instance. Process variables are initialized at process creation and destroyed on process completion. Variable *Tags* provide greater control over the variable behavior, such as whether the variable is `required` or `internal`. For more information about variable tags, see xref:con-bpmn-variables_kogito-developing-process-services[].

| *Metadata Attributes*
| Add any custom metadata attribute name and value that you want to use for custom event listeners, such as a listener to implement some action when a metadata attribute is present.

You can also use this field to configure role-based access to the process. To configure role-based access, set the attribute *Name* to `securityRoles` and set the attribute value to the relevant group or groups defined for the process, such as `employees,managers`.

| *Global Variables*
|  Not supported in {PRODUCT}. Global variables are visible to all process instances and assets in a project, and apply only to distributions of the BPMN modeler in jBPM and Red Hat Process Automation Manager.
|===

The *Metadata Attributes* entries are similar to *Process Variables* tags in that they enable new `metaData` extensions to BPMN diagrams. However, process variable tags modify the behavior of specific process variables, such as whether a certain variable is `required` or `internal`, whereas metadata attributes are key-value definitions that modify the behavior of the overall process, such as whether the process contains `securityRoles` or is used in conjunction with a custom event listener.

For example, the following custom metadata attribute `riskLevel` and value `low` in a BPMN process correspond to a custom event listener for starting the process:

.Example metadata attribute and value in the BPMN modeler
image::kogito/bpmn/bpmn-metadata-attributes-custom.png[Image of custom metadata attribute and value]

.Example metadata attribute and value in the BPMN file
[source,xml]
----
<bpmn2:process id="approvals" name="approvals" isExecutable="true" processType="Public">
  <bpmn2:extensionElements>
    <tns:metaData name="riskLevel">
      <tns:metaValue><![CDATA[low]]></tns:metaValue>
    </tns:metaData>
  </bpmn2:extensionElements>
----

.Example event listener with metadata value
[source,java]
----
public class MyListener implements ProcessEventListener {
    ...
    @Override
    public void beforeProcessStarted(ProcessStartedEvent event) {
        Map < String, Object > metadata = event.getProcessInstance().getProcess().getMetaData();
        if (metadata.containsKey("low")) {
            // Implement some action for that metadata attribute
        }
    }
}
----
--
. Begin adding components to your new or imported BPMN process model by clicking and dragging one of the BPMN nodes from the left palette:
+
--
.Adding BPMN components
image::kogito/bpmn/bpmn-drag-nodes.png[]

Although the {PRODUCT} BPMN modeler displays many BPMN components in the canvas palette, the {PROCESS_ENGINE} (process runtime component) in {PRODUCT} currently supports only the following BPMN components:

* *Start events*
** *Start*
** *Start Signal*
** *Start Timer*
** *Start Message*
* *Intermediate events*
** *Intermediate Signal* (catching and boundary)
** *Intermediate Timer* (catching and boundary)
** *Intermediate Message* (catching, boundary, and throwing)
* *End events*
** *End*
** *End Error*
** *End Terminate*
** *End Message*
* *Tasks*
** *Business Rule*
** *User*
** *Service*
** *Script*
* *Subprocesses*
** *Embedded*
** *Reusable*
* *Gateways*
** *Parallel*
** *Event*
** *Exclusive*
** *Inclusive*

--
. In the BPMN modeler canvas, for each new BPMN component that you add, select the new node, and in the upper-right corner of the BPMN modeler, click *Properties* to define the node identity and behavior.
+
--
For more information about BPMN component properties, see xref:ref-bpmn-support_kogito-developing-process-services[].

For this example, use a business rule task based on a Decision Model and Notation (DMN) decision model as your first activity node.

This example assumes that you have the following assets in your {PRODUCT} project:

* A Java object `org.acme.Person`
* A DMN model `PersonDecisions.dmn` with the namespace `\https://kiegroup.org/dmn/_52CEF9FD-9943-4A89-96D5-6F66810CA4C1`
--
. In the left palette, select *Activities* -> *Business Rule*, drag the task to the canvas, and link to it from a start event.
. Select the business rule task and define the following properties:

* *General*: Name the rule task `Evaluate person`.
* *Implementation/Execution*: Set the following values:
** *Rule Language*: `DMN`
** *Namespace*: `\https://kiegroup.org/dmn/_52CEF9FD-9943-4A89-96D5-6F66810CA4C1`
** *Decision Name*: `isAdult`
** *DMN Model Name*: `PersonDecisions`
* *Data Assignments*: Add the following assignments:
** *Data Input*: Add a data input with the name `Person`, with the type `org.acme.Person`, and with the source `person`.
** *Data Output*: Add a data output with the name `isAdult`, with the type `Boolean`, and with the source `isAdult`.
. In the left palette, select *Gateways* -> *Exclusive*, drag the gateway to the canvas, and link to it from the rule task.
. In the left palette, select *Activities* -> *User*, drag the user task to the canvas, and link to it from the exclusive gateway.
. Select the user task and define the following properties:

* *General*: Name the user task `Special handling for children`.
* *Implementation/Execution*: Set the task name to `ChildrenHandling`, and add a data input with the name `person`, the type `org.acme.Person`, and the source `person`.
. In the left palette, select *End Events* -> *End*, drag two end events to the canvas, and link to one end event from the user task and to the other end event from the exclusive gateway.
. Select the connector that connects the exclusive gateway to the end event and for the *Implementation/Execution* property, set the *Condition Expression* to `Java` and enter the condition `return isAdult == true;`.
. Select the connector that connects the exclusive gateway to the user task and for the *Implementation/Execution* property, set the *Condition Expression* to `Java` and enter the condition to `return isAdult == false;`
. Save the BPMN process file.
+
--
The following is the BPMN model for applicant age evaluation in this example:

.Example `persons.bpmn2` BPMN process
image::kogito/creating-running/kogito-bpmn-example-person.png[Image of `persons.bpmn2` process diagram]

You can continue adding or modifying any remaining components and properties of your BPMN process or create a separate example.

The following are additional BPMN models that are used with the `persons.bpmn2` process as part of the same example application:

.Example `orders.bpmn2` process
image::kogito/bpmn/bpmn-model-example-orders.png[Image of `orders.bpmn2` example process]

.Example `orderItems.bpmn2` process invoked as a subprocess
image::kogito/bpmn/bpmn-model-example-order-items.png[Image of `orderItems.bpmn` example process]

As an illustration of a more complex use case, the following is an example BPMN model from a separate mortgage loan application for determining loan approval:

.Example business process for a mortgage loan application
image::kogito/bpmn/bpmn-model-example-mortgage-application.png[Image of mortgage application business process.]

For more {PRODUCT} examples and instructions for using them, see the https://github.com/kiegroup/kogito-examples[`kogito-examples`] repository in GitHub.
--

[id="con-bpmn-variables_{context}"]
== Variables in {PRODUCT} processes

[role="_abstract"]
Variables in {PRODUCT} processes store data that is used during runtime. The {PRODUCT} BPMN modeler supports the following types of variables:

//@comment: Currently not supported/applicable in Kogito. (Stetson, 24 June 2020)
//* *Global variables*: Variables that are visible to all process instances and assets in a project. Global variables are typically used by business rules and constraints, and are created dynamically by the rules or constraints.
* *Process variables*: Variables that are visible within a specific process instance. Process variables are initialized at process creation and destroyed on process completion.
* *Local variables*: Variables that are visible within a specific process component, such as a task. Local variables are initialized when the element context is initialized (when the execution workflow enters the node and execution of the `onEntry` action has finished, if applicable). Local variables are destroyed when the element context is destroyed (when the execution workflow leaves the element).

A BPMN component, such as a process, subprocess, or task, can only access variables in its own context or in its parent context. A component cannot access a variable defined in a child component. When a BPMN component requires access to a variable during runtime, its own context is searched first.

If the variable cannot be found directly in the component context, the immediate parent context is searched. The search continues until the process context is reached.

If the variable cannot be found, a read access request returns `null`, a write access produces an error message, and the process continues its execution. Variables are searched for based on their unique ID.

=== Variable tags in BPMN process files

For greater control over variable behavior, you can tag process variables and local variables in the  BPMN process file. Tags are simple string values that you add as metadata to a specific variable.

{PRODUCT} supports the following tags for process variables and local variables:

* `internal`: Sets the variable as internal only for a process instance and hides the variable from the exposed REST model. For example, you can use this tag with intermediate variables that help hold some state during the execution of the process but are not part of the domain.
* `required`: Sets the variable as a requirement in order to start a process instance. If a process instance starts without the required variable, {PRODUCT} generates a `VariableViolationException` error.
* `readonly`: Indicates that the variable is for informational purposes only and can be set only once during process instance execution. If the value of a read-only variable is modified at any time, {PRODUCT} generates a `VariableViolationException` error.
* `input`: Sets the variable as an input of the process and therefore is not exposed in the returned data model. As a result, the value of an input variable is not returned in response to REST requests.
* `output`: Sets the variable as an output of the process and therefore is not expected for a process start and is included in the returned data model. As a result, the value of an output variable is returned in response to REST requests.
* `business-relevant`: Indicates that the variable is relevant for a particular item of business value. This tag is helpful for monitoring purposes or for implying that the variable is relevant to another application.
* `tracked`: Sets a variable to be tracked for changes so that {PRODUCT} generates events anytime the value of this variable is changed. Events are published to the `kogito-variables-events` topic in {PRODUCT}, where you can access the previous and new values.

You can define a variable tag in the {KOGITO} BPMN modeler in VSCode, or you can add the tag directly in the BPMN process source file as a `customTags` metadata property with the tag value defined in the format `![CDATA[__TAG_NAME__]]`.

For example, the following BPMN process applies the `required` tag to an `approver` process variable:

.Example variable tagged in the BPMN modeler
image::kogito/bpmn/bpmn-variable-tags-ui.png[Image of variable tags in BPMN modeler]

.Example variable tagged in a BPMN file
[source,xml]
----
<bpmn2:property id="approver" itemSubjectRef="ItemDefinition_9" name="approver">
  <bpmn2:extensionElements>
    <tns:metaData name="customTags">
      <tns:metaValue><![CDATA[required]]></tns:metaValue>
    </tns:metaData>
  </bpmn2:extensionElements>
</bpmn2:property>
----

You can use multiple tags for a variable where applicable, but use caution and ensure that the tags are logical and do not conflict. For example, avoid tagging a variable as both `internal` and `required`.

By default, if a process variable has no tag assigned to it, {PRODUCT} assigns an `input` and an `output` tag to it.

You can also define custom variable tags in your BPMN files to make variable data available to {PRODUCT} process event listeners. Custom tags do not influence the {PRODUCT} runtime as the standard variable tags do and are for informational purposes only. You define custom variable tags in the same `customTags` metadata property format that you use for standard {PRODUCT} variable tags.

////
//@comment: Currently not supported/applicable for Kogito. (Stetson, 24 June 2020)
[id="proc-bpmn-variables-global_{context}"]
=== Defining global variables in {PRODUCT} processes

[role="_abstract"]
Global variables are visible to all process instances and assets in a project, and pass information to the {PROCESS_ENGINE}. Global variables are typically used by business rules and constraints, and are created dynamically by the rules or constraints. Every global variable defines its unique ID and item subject reference. The ID serves as the variable name and must be unique within the process definition. The item subject reference defines the data type that the variable stores.

IMPORTANT: Business rules are evaluated at the moment the fact is inserted. Therefore, if you are using a global variable to constrain a fact pattern and the global is not set, the system returns a `NullPointerException`.

Values of global variables can typically be changed during an assignment, which is a mapping between a process variable and an activity variable. The global variable is then associated with the local activity context, local activity variable, or by a direct call to the variable from a child context.

.Procedure
. In your VSCode IDE, open the relevant BPMN process file to view the process in the {PRODUCT} BPMN modeler.
. Select the background of the BPMN modeler canvas and, in the upper-right corner of the modeler, click *Properties*.
. Under *Process* -> *Global Variables*, click the plus icon to add a new global variable and enter the following values:

* *Name*: Enter the name of the global variable, such as `person` for a global variable with person information shared by all assets.
* *Data Type*: Enter a custom or standard data type of the variable, such as `org.acme.Person`.
+
.Example global variable in BPMN modeler
image::kogito/bpmn/bpmn-global-variables.png[Image of global variable example]
////

[id="proc-bpmn-variables-process_{context}"]
=== Defining process variables in {PRODUCT} processes

[role="_abstract"]
Process variables are visible within a specific process instance. Process variables are initialized at process creation and destroyed on process completion. You can map process variables to local variables.

.Procedure
. In your VSCode IDE, open the relevant BPMN process file to view the process in the {PRODUCT} BPMN modeler.
. Select the background of the BPMN modeler canvas and, in the upper-right corner of the modeler, click *Properties*.
. Under *Process Data* -> *Process Variables*, click the plus icon to add a new process variable and enter the following values:

* *Name*: Enter the name of the process variable, such as `order` for a process variable with order information shared by all applicable nodes in the process.
* *Data Type*: Enter a custom or standard data type of the variable, such as `org.acme.Order`.
+
.Example process variables in BPMN modeler
image::kogito/bpmn/bpmn-process-variables.png[Image of process variable example]

[id="proc-bpmn-variables-local_{context}"]
=== Defining local variables in {PRODUCT} processes

[role="_abstract"]
Local variables are visible within a specific process component, typically a task. Local variables are initialized when the element context is initialized (when the execution workflow enters the node and execution of the `onEntry` action has finished, if applicable). Local variables are destroyed when the element context is destroyed (when the execution workflow leaves the element).

You can map local variables to global or process variables. This mapping enables you to maintain relative independence from the parent context that accommodates the local variable. This isolation helps prevent technical exceptions.

For tasks, with the exception of script tasks, you define local variables as data input or output assignments under *Assignments* in the task properties. Data input assignments define variables that enter the task and provide the entry data required for the task execution. Data output assignments refer to the context of the task after execution to acquire output data.

User tasks present data related to the actor who is completing the user task. User tasks also require the actor to provide result data related to the execution.

//To request and provide the data, use task forms and map the data in the Data Input Assignment parameter to a variable. Map the data provided by the user in the Data Output Assignment parameter if you want to preserve the data as output.

.Procedure
. In your VSCode IDE, open the relevant BPMN process file to view the process in the {PRODUCT} BPMN modeler.
. Select the relevant task (non-script task) and, in the upper-right corner of the modeler, click *Properties*.
. Under *Assignments*, click the edit icon to open the *Data I/O* window, and click *Add* to begin adding local variables as data input or output:

* *Name*: Enter the name of the data input or output, such as `person` for a local variable with person information as the input and `isAdult` for a local variable with adult status as the output.
* *Data Type*: Enter a custom or standard data type of the data input or output, such as `org.acme.Person`.
* *Source* or *Target*: Enter the source object for the data input or the target object for the data output, such as `person` for a Java class with person information.
+
.Example local variables in BPMN modeler
image::kogito/bpmn/bpmn-local-variables.png[Image of local variable example]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=con-persistence]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-infinispan-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-mongodb-persistence-enabling]

include::{asciidoc-dir}/configuration/chap-kogito-configuring.adoc[tags=proc-messaging-enabling]

[id="con-knative-eventing_{context}"]
== Knative Eventing in {PRODUCT} services

[role="_abstract"]
https://knative.dev/docs/eventing/[Knative Eventing] is a system that enables you to create event producers and consumers for your applications. Knative Eventing uses standard HTTP POST requests to send and receive events between event producers and consumers. These events conform to the https://github.com/cloudevents/spec[CloudEvents specification], which enables creating, parsing, sending, and receiving events in any programming language.

{PRODUCT} provides a `knative-eventing-addon` add-on that enables you to use Knative Eventing with {PRODUCT} services that consume or publish messages within a Business Process Model and Notation (BPMN) process model or Serverless Workflow. {PRODUCT} runtime events for messages, processes, tasks, and other application activities are published in https://cloudevents.io/[CloudEvents] format so that they can be consumed efficiently by other entities, such as the Knative Eventing system.

NOTE: Knative Eventing is currently supported for {PRODUCT} services on Quarkus only. The {PRODUCT} Operator supports Knative Eventing 0.17 or later.

For example, the following `handle-travelers.bpmn2` process uses messaging start and end events to communicate with travelers:

.Example process with messaging start and end events
image::kogito/bpmn/bpmn-messaging-example.png[Image of BPMN process receiving and publishing messages]

When the Knative Eventing add-on is enabled in the {PRODUCT} project that contains this example process, an event consumer is generated from the message start node and an event producer is generated from the message end node at build time.

The following diagram illustrates a scenario with Knative Eventing and a {PRODUCT} service that contains event consumers:

.Knative Eventing and a {PRODUCT} service with event consumers
image::kogito/bpmn/kogito-knative-impl-listening-event.png[{PRODUCT} service listening to events]

In this scenario, three Knative Eventing https://knative.dev/docs/eventing/triggers/[Triggers] are generated to filter the messages that are received by the {PRODUCT} service. These messages are sent to the default {PRODUCT} service port. A message-routing mechanism in the generated code redirects the message to an inner channel based on the name of the message start event in the BPMN process model. The names of message start and end events serve as unique CloudEvents https://github.com/cloudevents/spec/blob/v1.0/spec.md#type[`type` attribute] definitions in Knative Eventing.

In the example `handle-travlers.bpmn2` process, the message start node is named `travelers`, so a message with a `type` named `travelers` triggers the message start node, as shown in the following example curl request:

.Example request to trigger the `travelers` message start event
[source]
----
$ curl -X POST \
      -H "content-type: application/json"  \
      -H "ce-specversion: 1.0"  \
      -H "ce-source: /from/localhost"  \
      -H "ce-type: travelers"  \
      -H "ce-id: 12346"  \
      -d '{"firstName": "Jane", "lastName": "Doe", "email": "jane.doe@example.com", "nationality": "German"}' \
  http://localhost:8080
----

The following diagram illustrates a scenario with Knative Eventing and a {PRODUCT} service that contains event producers:

.Knative Eventing and a {PRODUCT} service with event producers
image::kogito/bpmn/kogito-knative-impl-producing-event.png[{PRODUCT} service producing events]

In this scenario, the {PRODUCT} service sends HTTP POST messages to the Knative Eventing https://knative.dev/docs/eventing/broker/[Broker] through the `SinkBinding` resource. The `SinkBinding` endpoint is generated by the Knative Eventing platform and is injected in the {PRODUCT} service container as an environment variable named `${K_SINK}`.

The following example message is generated by the {PRODUCT} service:

.Example message generated by the {PRODUCT} service
[source]
----
Context Attributes,
  specversion: 1.0
  type: process/travelers/processedtravellers
  source: /process/Travelers/2f692fd9-fff8-4b0a-bb64-96d1a4772490
  id: 29e43b17-3a70-4b46-aca0-7ab8e2133eee
  time: 2020-08-10T20:52:39.383346Z
Extensions,
  knativearrivaltime: 2020-08-10T20:52:39.391404032Z
  knativehistory: default-kne-trigger-kn-channel.kogito.svc.cluster.local
  kogitoprocessid: Travelers
  kogitoprocessinstanceid: 2f692fd9-fff8-4b0a-bb64-96d1a4772490
  kogitoprocessinstancestate: 1
Data,
  {"firstName":"Jan","lastName":"Kowalski","email":"jan.kowalski@example.com","nationality":"German","processed":true}
----

In this case, the CloudEvents `type` attribute uses the format `process/__PROCESS_ID__/__NODE_NAME__`. This format prevents the messages generated by the {PRODUCT} service from conflicting with other messages being generated within the cluster, and enables the `SinkBinding` objects to filter these messages by a unique `type`. The generated CloudEvents message also contains information about the process instance, such as the process ID, process instance ID, and process instance state.

The following diagram illustrates the overall architecture of a {PRODUCT} service deployed in a Knative Eventing environment on a Kubernetes or OpenShift cluster:

.{PRODUCT} service deployed in Knative Eventing environment on Kubernetes or OpenShift
image::kogito/bpmn/kogito-knative-deployment-architecture.png[{PRODUCT} service deployed on Knative Eventing environment]

[id="proc-knative-eventing-process-services_{context}"]
=== Enabling Knative Eventing for {PRODUCT} services

[role="_abstract"]
You can enable https://knative.dev/docs/eventing/[Knative Eventing] support for {PRODUCT} services that consume or publish messages within a Business Process Model and Notation (BPMN) process model. When you enable Knative Eventing for a {PRODUCT} project, event consumers and producers are generated from message start and end nodes in BPMN processes at build time. You can use these event consumers and producers as part of your {PRODUCT} service deployment in a Knative Eventing environment on Kubernetes or OpenShift clusters.

NOTE: Knative Eventing is currently supported for {PRODUCT} services on Quarkus only. The {PRODUCT} Operator supports Knative Eventing 0.17 or later.

.Prerequisites
* You have installed and deployed Knative Eventing 0.17 or later on a Kubernetes or an OpenShift cluster. For information about Knative Eventing on OpenShift, see https://docs.openshift.com/container-platform/4.5/serverless/installing_serverless/installing-knative-eventing.html[Installing Knative Eventing] in the OpenShift documentation.
* You have created a BPMN model in your {PRODUCT} project with message start or end events that you want to integrate with Knative Eventing. For information about creating BPMN models, see xref:proc-bpmn-model-creating_kogito-developing-process-services[].

.Procedure
. Add the following dependencies to the `pom.xml` file of your {PRODUCT} project:
+
--
.Knative Eventing dependencies
[source,xml,subs="attributes+,+quotes"]
----
<dependencies>
  <dependency>
    <groupId>org.kie.kogito</groupId>
    <artifactId>knative-eventing-addon</artifactId>
  </dependency>
  <dependency>
    <groupId>org.kie.kogito</groupId>
    <artifactId>kogito-cloudevents-quarkus-addon</artifactId>
  </dependency>
  <dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-smallrye-reactive-messaging</artifactId>
  </dependency>
  <dependency>
    <groupId>io.smallrye.reactive</groupId>
    <artifactId>smallrye-reactive-messaging-http</artifactId>
  </dependency>
</dependencies>
----

These dependencies enable Knative Eventing add-on and messaging requirements. When a {PRODUCT} service has the Knative Eventing add-on enabled, {PRODUCT} generates code based on http://www.smallrye.io/smallrye-reactive-messaging/[Smallrye Reactive Messaging] to publish messages.
--
. In your {PRODUCT} project, open the BPMN file that you want to use for consuming or producing messages in the Knative Eventing environment. BPMN files are typically in `src/main/resources`.
+
--
For example, the following `handle-travelers.bpmn2` process uses messaging start and end events to communicate with travelers:

.Example process with messaging start and end events
image::kogito/bpmn/bpmn-messaging-example.png[Image of BPMN process receiving and publishing messages]

The names of message start and end events serve as CloudEvents https://github.com/cloudevents/spec/blob/v1.0/spec.md#type[`type` attribute] definitions in Knative Eventing and must be unique.
--
. For each message event in the BPMN process model, select the node, click *Properties* in the upper-right corner of the modeler, and verify that the node name is clear and unique.
+
--
For example, consider adding the project or process name as a prefix to the message node name, such as `travelagency.travelers` in the following example:

.Set a unique message node name
image::kogito/bpmn/kogito-knative-set-node-name.png[Image of a message node property name]
--
. After you verify and save the message node names, navigate to the `src/main/resources/application.properties` file in your {PRODUCT} project and add the following properties:
+
--
.Required application properties for publishing
[source,subs="attributes+,+quotes"]
----
mp.messaging.incoming.kogito_incoming_stream.connector=smallrye-http
mp.messaging.outgoing.kogito_outgoing_stream.connector=smallrye-http
mp.messaging.outgoing.kogito_outgoing_stream.url=${K_SINK}
----

The `smallrye-http` property defines the HTTP endpoint for the published messages. The `${K_SINK}` property is an environment variable injected by Knative Eventing when you deploy a {PRODUCT} service that references a Knative Eventing https://knative.dev/docs/eventing/samples/sinkbinding/[`SinkBinding`] object.
--
. Build your {PRODUCT} project locally using your usual method, such as `mvn clean package`, and navigate to the `target/generated-sources/kogito` directory in your project and verify the following contents:
+
* Generated classes with the suffixes `MessageConsumer` and `MessageProducer`. These classes are generated based on the message start and end events in your BPMN model.
* Generated `app` folder containing a `CloudEventListenerResource.java` file. This file detects any CloudEvents messages produced by the Knative Eventing source that targets your {PRODUCT} service.

+
If any of these items are missing, ensure that you have configured all required dependencies, applications properties, and message event name. After all checks are complete, rebuild the project.
. After you configure and test your {PRODUCT} project locally, in your Kubernetes or OpenShift environment, add the following custom resources to prepare your {PRODUCT} project for deployment. These resources enable the {PRODUCT} Operator to generate the required resources for consuming or producing events in a Knative Eventing environment.
+
--
* `Broker`: When you deploy a {PRODUCT} service that uses the `knative-eventing-addon` add-on, you must also deploy a Knative Eventing https://knative.dev/docs/eventing/broker/[Broker] in the same namespace. The {PRODUCT} service uses this Broker to publish or listen to CloudEvents messages. You can use any Broker channel for the {PRODUCT} service, such as InMemoryChannel, KafkaChannel, or NatssChannel.
+
By default, the InMemoryChannel channel is used when no channel is specified, as shown in the following `Broker` custom resource example:
+
.Example `Broker` custom resource for Knative Eventing with default InMemoryChannel
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  name: default
----
+
NOTE: InMemoryChannel channels are for development use only. Do not use this channel in a production deployment.

+
For more information about available Broker channels and how to install them, see https://knative.dev/docs/eventing/channels/channels-crds/[Available Channels] in the Knative documentation.

* `KogitoInfra`: To bind the Knative Eventing Broker instance to the {PRODUCT} service being deployed, you must create a `KogitoInfra` instance, as shown in the following example:
+
.Example `KogitoInfra` custom resource for a {PRODUCT} service with `Broker` binding
[source,yaml]
----
apiVersion: app.kiegroup.org/v1beta1
kind: KogitoInfra
metadata:
  name: kogito-knative-infra
spec:
  # Bind Knative Broker to the service
  resource:
    apiVersion: eventing.knative.dev/v1
    kind: Broker
    name: default
----
* `KogitoRuntime`: The `KogitoRuntime` resource used to deploy the {PRODUCT} service using the {PRODUCT} Operator must have this `KogitoInfra` instance linked to it, as shown in the following example:
+
.Example `KogitoRuntime` custom resource for a {PRODUCT} service with `KogitoInfra` bound to it
[source,yaml,subs="+quotes"]
----
apiVersion: app.kiegroup.org/v1beta1
kind: KogitoRuntime
metadata:
  name: process-knative-quickstart-quarkus
spec:
  replicas: 1
  image: quay.io/__NAME_SPACE__/process-knative-quickstart-quarkus:latest
  # Reference to the KogitoInfra resource with the Knative Broker binding
  infra:
  - kogito-knative-infra
----

After you apply these resources to the Kubernetes or OpenShift namespace, if any BPMN or Serverless Workflow files in the {PRODUCT} project contain events to be consumed or produced, the {PRODUCT} Operator automatically creates the required Knative Eventing https://knative.dev/docs/eventing/triggers/[`Trigger`] resource for consuming events and the https://knative.dev/docs/eventing/samples/sinkbinding/[`SinkBinding`] resource for producing events.

The following is an example `Trigger` resource generated by the {PRODUCT} Operator:

.Example `Trigger` custom resource generated by the operator (consuming)
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: travelers-trigger
spec:
  # The default Broker is enabled in the cluster because the namespace is labeled with `knative-eventing-injection=enabled`.
  broker: default
  filter:
    attributes:
      # Name of the message node in the process.
      type: travelers
  # The subscriber is the deployed service. Any event that matches the filter in the Broker is sent here.
  subscriber:
    ref:
      apiVersion: v1
      kind: Service
      name: process-knative-quickstart-quarkus
----

This Knative Eventing Trigger resource filters all messages delivered to the default Broker and sends them to the default service deployed by the {PRODUCT} Operator.

The following is an example `SinkBinding` resource generated by the {PRODUCT} Operator:

.Example `SinkBinding` custom resource generated by the operator (producing)
[source,yaml]
----
apiVersion: sources.knative.dev/v1alpha1
kind: SinkBinding
metadata:
  name: process-knative-quickstart-quarkus-sink
spec:
  subject:
    apiVersion: apps/v1
    kind: Deployment
    selector:
      matchLabels:
        app: process-knative-quickstart-quarkus
  # Any cloud event produced by the application is delivered to the Broker.
  sink:
    ref:
      apiVersion: eventing.knative.dev/v1
      kind: Broker
      name: default
----

This Knative Eventing `SinkBinding` resource injects the `${K_SINK}` environment variable to the `Deployment` resource created by the {PRODUCT} Operator. Every message produced by the {PRODUCT} service is redirected to the default Knative Broker.

NOTE: If you deploy your {PRODUCT} services without the {PRODUCT} Operator, you must create these `Trigger` and `SinkBinding` resources manually.

If any other components need to consume the messages produced by the {PRODUCT} service, you must create an additional Knative Eventing `Trigger` resource as shown in the following example:

.Custom resource for other consuming components
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: event-display-trigger
spec:
  # The default Broker is enabled in the namespace.
  broker: default
  filter:
    # Listens only to events of type `success` emitted by the CloudEvents-processing service.
    attributes:
      # The same type being generated by the custom service.
      type: /process/travelers/processedtravellers
      # The subscriber is the deployed displayer service. Any event that matches the filter in the Broker is sent here.
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: event-display
----

The `spec.filter.attributes.type` value defined in the `Trigger` resource is the same as the value generated by the {PRODUCT} service.
--

For an example {PRODUCT} service with Knative Eventing enabled, see the https://github.com/kiegroup/kogito-examples/tree/stable/process-knative-quickstart-quarkus[`process-knative-quickstart-quarkus`] example application.

[role="_additional-resources"]
.Additional resources
* {URL_DEPLOYING_ON_OPENSHIFT}#chap-kogito-deploying-on-openshift[_{DEPLOYING_ON_OPENSHIFT}_]
* {URL_DEPLOYING_ON_OPENSHIFT}#proc-kogito-deploying-on-kubernetes_kogito-deploying-on-openshift[_{DEPLOYING_ON_OPENSHIFT}_]

[id="con-task-lifecycle_{context}"]
== Task lifecycle in {PRODUCT} processes

[role="_abstract"]
In {PRODUCT} business processes, tasks are implemented as work items and their execution is defined by work item handlers. User tasks in particular are a core construct in {PRODUCT} processes. When a user task is reached in a process, the task progresses through phases of a defined lifecycle until it reaches an end state.

{PRODUCT} supports the following default phases in a work item (task) lifecycle:

* *Active*: Indicates initial state when the work item is activated
* *Abort*: Indicates abnormal completion of the work item
* *Complete*: Indicates normal completion of the work item
* *Claim*: Assigns the work item to a specific actor, restricting access to anyone else
* *Release*: Unassigns the work item from a specific actor, releasing it to any other potential user or group to work on it (by claiming or completing)
* *Skip*: Skips the work item

With {PRODUCT}, you can also add custom lifecycles and lifecycle phases to meet your business needs.

A lifecycle moves a work item across various phases that are not defined by the `WorkItem` interface and defines the behavior of a work item at runtime. You typically add a lifecycle on top of the `WorkItemHandler` interface so that the lifecycle is pluggable with more flexible runtime characteristics.

The `WorkItemHandler` interface provides the option to move between task phases, as shown in the following method example:

.WorkItemHandler support for moving between task phases
[source, java]
----
public void transitionToPhase(WorkItem workItem, WorkItemManager manager, Transition<?> transition)
----

NOTE: This method is a default method that does nothing when not implemented. This functionality maintains backward compatibility with existing work item handler implementations.

You typically implement the `transitionToPhase` method as shown in the following example:

.Example implementation of transitionToPhase method
[source, java]
----
@Override
public void transitionToPhase(WorkItem workItem, WorkItemManager manager, Transition<?> transition) {

    lifeCycle.transitionTo(workItem, manager, (Transition<Map<String, Object>>) transition);
}
----

The `lifeCycle` element is an implementation of `org.kie.{PRODUCT_INIT}.process.workitem.LifeCycle<T>` that defines the execution semantics.

=== User task authorization

The `org.jbpm.process.instance.impl.humantask.BaseHumanTaskLifeCycle` implementation in {PRODUCT} ensures that a user task is worked on by authorized users, based on the user or group assignments that you provide.

You can use the following parameters to provide assignments for authorized users or groups in the relevant BPMN process model. All of the listed parameters support expressions.

.Parameters for authorized users or groups
[cols="35%,35%,30%"]
|===
|Parameter name |Description |Example value

|`ActorId`
|Comma-separated list of authorized users
|`John,Mary,#{actor}`

|`GroupId`
|Comma-separated list of authorized groups of users
|`mangers,#{mygroup}`

|`BusinessAdministratorId`
|Comma-separated list of authorized administrators
|`administrator,#{adminuser}`

|`BusinessAdministratorGroupId`
|Comma-separated list of groups of administrators
|`admins,#{admingroup}`

|`ExcludedOwnerId`
|Comma-separated list of unauthorized users who cannot work on this task
|`paul,#{lastactor}`
|===

NOTE: Authorization is only enforced when the method that calls the work item lifecycle methods uses a security context. This security behavior is dependent on the API that you use.

=== API interaction with task lifecycle phases

The following example API interacts with user tasks (work items) using lifecycle phases:

.Example API to interact with task lifecycle phases
[source, java]
----
// Start process instance
ProcessInstance<?> processInstance = approvalsProcess.createInstance(m);
processInstance.start();

// Set up security policy with identity information
StaticIdentityProvider identity = new StaticIdentityProvider("admin", Collections.singletonList("managers"));
SecurityPolicy policy = SecurityPolicy.of(identity);

// Get list of work items, taking security restrictions into account
List<WorkItem> workItems = processInstance.workItems(policy);

// Work on a task
final String wiId = workItems.get(0).getId();
processInstance.transitionWorkItem(wiId,
                                   new HumanTaskTransition(Claim.ID, null, policy));

processInstance.transitionWorkItem(wiId,
                                   new HumanTaskTransition(Complete.ID, Collections.singletonMap("approved", false), policy));
----

When you interact with user tasks through a REST API, you can also provide the following query parameters for user and group information:

.Query parameters for user or group information in REST APIs
[cols="20%,60%,20%"]
|===
|Parameter name |Description |Multi-value support

|`user`
|User name to be used for the user task authorization check
|No

|`group`
|Zero or more group names to be used for the user task authorization check
|Yes
|===

For example, the following REST endpoints interact with user tasks in an `orderItems.bpmn2` process for verifying customer orders:

.Example GET request to retrieve open tasks using the process UUID
[source]
----
curl -X GET http://localhost:8080/orderItems/66c11e3e-c211-4cee-9a07-848b5e861bc5/tasks
----

.Example response
[source]
----
{"62f1c985-d31c-4ead-9906-2fe8d05937f0":"Verify order"}
----

.Example GET request to retrieve task details by process and task UUID
[source,subs="+quotes"]
----
curl -X GET http://localhost:8080/orderItems/66c11e3e-c211-4cee-9a07-848b5e861bc5/Verify_order/62f1c985-d31c-4ead-9906-2fe8d05937f0
----

.Example response
[source]
----
{"id":"62f1c985-d31c-4ead-9906-2fe8d05937f0","input1":{"orderNumber":"12345","shipped":false,"total":0.537941914075738},"name":"Verify order"}
----

.Example POST request to complete the task and define the authorized group and user
[source]
----
curl -X POST http://localhost:8080/orderItems/66c11e3e-c211-4cee-9a07-848b5e861bc5/Verify_order/62f1c985-d31c-4ead-9906-2fe8d05937f0?group=managers&user=john -H "accept: application/json" -H "content-type: application/json"
----

.Example response
[source]
----
{"id":"66c11e3e-c211-4cee-9a07-848b5e861bc5","order":{"orderNumber":"12345","shipped":false,"total":0.537941914075738}}
----

[id="proc-task-lifecycle-custom_{context}"]
=== Creating a custom task lifecycle and phase

[role="_abstract"]
You can extend the user task lifecycle and lifecycle phases in {PRODUCT} to implement a custom lifecycle and phases as needed.

.Procedure
. To add custom lifecycle phases, implement the `org.kie.kogito.process.workitem.LifeCyclePhase` resource in the Java class for your custom lifecycle phases.
+
--
This resource implements the following key methods:

* `id`: Assigns a unique ID that is used when transitioning through phases
* `canTransition`: Provides a checkpoint between phases, if this phase can be transitioned from a specified phase
* `status`: Defines a human-readable status for this phase
* `isTerminating`: Determines if this phase is a completion stage, and if so, completes the work item and moves on to the next activity in the process
* `apply`: Enables additional updates to the work item when transitioning through phases

You can implement as many phases as needed or extend existing phases.
--
. To add a custom lifecycle, implement the `org.kie.kogito.process.workitem.LifeCycle<Map<String, Object>>` resource in the Java class for your custom lifecycle.
+
--
NOTE: To support user tasks, the parameterized type `LifeCycle` must be `Map<String, Object>`.

This resource implements the following key methods:

* `phaseById`: Retrieves the lifecycle phase by ID to verify if the phase is supported by the lifecycle implementation
* `phases`: Returns all supported phases by a specified lifecycle implementation
* `transitionTo`: Provides the main logic to handle phase transition
* `data`: Returns the current state of data for the work item

The following is an example Java class that extends the `Complete` lifecycle phase from a custom lifecycle implementation:

.Example Java class to extend the `Complete` lifecycle phase
[source,java]
----
package org.acme.travels.usertasks;

import java.util.Arrays;
import java.util.List;

import org.jbpm.process.instance.impl.workitem.Complete;
import org.kie.kogito.process.workitem.LifeCyclePhase;

public class CompleteStartedOnly extends Complete {

    private List<String> allowedTransitions = Arrays.asList(Start.ID);

    @Override
    public boolean canTransition(LifeCyclePhase phase) {
        return allowedTransitions.contains(phase.id());
    }

}
----
--

. After you implement your custom lifecycle or lifecycle phases, create a Java configuration class to enable the {PROCESS_ENGINE} to use the new lifecycle or phase instead of the default lifecycle.
+
--
In this configuration, you use the `WorkItemHandlerConfig` class as you do for any other work item handler, as shown in the following example:

.Example configuration class for a custom lifecycle phase
[source,java]
----
@ApplicationScoped
public class CustomWorkItemHandlerConfig extends DefaultWorkItemHandlerConfig {
 {
  register("Human Task", new HumanTaskWorkItemHandler(new CustomHumanTaskLifeCycle()));
 }
}
----

The work item handler is the same as the default, but instead of the default lifecycle, you pass as a constructor argument the custom implementation of the `LifeCycle` interface.
--

For example {PRODUCT} services with custom task lifecycle configurations, see the following example applications in GitHub:

* https://github.com/kiegroup/kogito-examples/tree/stable/process-usertasks-custom-lifecycle-quarkus[`process-usertasks-custom-lifecycle-quarkus`]: Example on Quarkus
* https://github.com/kiegroup/kogito-examples/tree/stable/process-usertasks-custom-lifecycle-springboot[`process-usertasks-custom-lifecycle-springboot`]: Example on Spring Boot

[id="con-flex-processes_{context}"]
== Flexible processes for case management in {PRODUCT}

[role="_abstract"]
{PRODUCT} does not support the https://www.omg.org/cmmn/[Case Management Model and Notation (CMMN) specification] for case management in process services. Instead, {PRODUCT} uses Business Process Model and Notation (BPMN) extensions to provide similar case-management functionality through _flexible processes_.

A flexible process in {PRODUCT} is any process definition that uses ad hoc components or other features that enable the process to be executed more flexibly than traditional processes. For example, a flexible process does not require a standard start event and does not require all nodes to be connected. Some of the typical components in flexible processes include the `Ad-Hoc` process property that enables the process to use ad hoc auto-start fragments and to not require strict start and end events, ad hoc subprocesses that contain embedded inner activities within another process, and milestones that flag or trigger tasks and events.

Similar to case files in CMMN, flexible processes enable you to define traditional processes with more flexibility when the execution path is not rigid. This flexibility is helpful when the process cannot be fully automated or when the scope of the process is difficult to measure. A typical example of a case or flexible process is related to healthcare. A patient has a file that is accessible to the doctor and to any health professionals (or _knowledge workers_) who are assigned to the patient. These assigned workers take action and make different decisions and assessments until the patient is diagnosed and treated, completing the case or flexible process.

{PRODUCT} currently supports the following key case-related features in flexible processes:

* *Ad hoc processes*: An ad hoc process is any process definition that has the `Ad-Hoc` property enabled in the process diagram *Properties* panel. This property enables the process to use ad hoc auto-start fragments, such as ad hoc subprocesses and ad hoc tasks, and to not require strict start and end events. An ad hoc process is similar to a Case in CMMN.
+
.Ad hoc process property
image::kogito/bpmn/bpmn-ad-hoc-process.png[Image of Ad-Hoc process property]
* *Ad hoc subprocesses*: An ad hoc subprocess contains embedded inner activities within another process and is a standard BPMN component that is supported in {PRODUCT}. An ad hoc subprocess is similar to a Stage in CMMN.
+
.Ad hoc subprocess node
image::kogito/bpmn/bpmn-adhoc-subprocess.png[Image of ad hoc subprocess node in process designer]
* *Ad hoc auto-start fragments*: An ad hoc auto-start fragment is any ad hoc process, ad hoc subprocess, or ad hoc task with the `AdHoc Autostart` property enabled. This property enables the fragment to automatically start when the process is created instead of being started by the completion of the previous node or by a signal event.
+
.Ad hoc auto-start property
image::kogito/bpmn/bpmn-adhoc-subprocess-autostart.png[Image of ad hoc subprocess node in process designer]
* *Milestones*: A milestone is a standard CMMN component that is incorporated in {PRODUCT} as a BPMN custom task. A milestone represents a single point of achievement within a process instance. You can use milestones to flag certain events to trigger other tasks or track the progress of the process.
+
.Milestone node
image::kogito/bpmn/bpmn-milestone.png[Image of Mileston node in process designer]
* *REST API requests as signals*: A REST API request can serve as a signal event to trigger milestones or to create and start ad hoc fragments such as ad hoc processes, ad hoc subprocesses, or tasks. For non-flexible processes, an empty `POST` request for a process triggers the start node, whereas in a flexible process, the request creates the process instance. Similarly for ad hoc tasks, an empty `POST` request instantiates the task node. All ad hoc auto-start fragments with the `AdHoc Autostart` property enabled are started automatically when the process is created.
+
.Example curl request to add comments to a ticket
[source]
----
curl -D -X POST -H 'Content-Type:application/json' -H 'Accept:application/json' http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment
----
+
.Example response (JSON)
[source,json]
----
HTTP/1.1 201 Created
Content-Length: 305
Location: http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment/f3b36cf9-3953-43ae-afe6-2a48fea8a79a
Content-Type: application/json

{
  "id":"b3c75b24-2691-4a76-902c-c9bc29ea076c",
  "supportCase":{
    "product": {
      "name":"Kogito",
      "family":"Middleware"
    },
    "description":"Kogito is not working for some reason.",
    "engineer":"kelly",
    "customer":"Paco the customer",
    "state":"WAITING_FOR_OWNER",
    "comments":null,
    "questionnaire":null
  },
  "supportGroup":"Kogito"
}
----

[id="ref-flex-process-example_{context}"]
=== Flexible process example

[role="_abstract"]
A typical flexible process consists of one or more of the following basic components:

* Optional start event (might or might not be explicit)
* Optional node connections (might or might not connect all nodes)
* Enabled `Ad-Hoc` process property
* One or more subprocesses, typically ad hoc subprocesses
* Ad hoc auto-start fragments, such as ad hoc subprocesses or ad hoc tasks
* Milestones that flag or trigger events
* End event to terminate the process

The following example is a real-world BPMN model scenario that demonstrates how you can use flexible processes for case management. In this scenario, a service desk uses a flexible process for handling customer tickets related to problems or questions about a specific product.

NOTE: This example is based on the `flexible-process-quarkus` application in the https://github.com/kiegroup/kogito-examples[`kogito-examples`] repository in GitHub. However, this example may differ from the exact example source code as {PRODUCT} continues to be developed. Be sure to explore this and other {PRODUCT} examples in GitHub to help you develop your own applications.

.Example `service-desk.bpmn2` flexible process
image::kogito/bpmn/bpmn-flex-process-example.png[Image of `service-desk.bpmn2` example process]

To start the process and generate a ticket, a user provides an initial `supportCase` object in a REST request that contains information about the product, the customer, and the related issue:

.Example REST request to start the process and generate a ticket
[source,json]
----
{
  "supportCase": {
    "customer": "Paco the customer",
    "description": "Kogito is not working for some reason.",
    "product": {
      "family": "Middleware",
      "name": "Kogito"
    }
  }
}
----

After the ticket is generated, the `Triage` ad hoc subprocess is automatically started and the ticket is assigned to a support team and then to a support engineer. If the system cannot determine which team to assign the ticket to, a user assigns the ticket manually to a support engineer.

The decision logic for the `Triage` subprocess is defined in the following `SupportGroup` decision table in the `triage.dmn` Decision Model and Notation (DMN) model:

.Example `SupportGroup` DMN decision table
image::kogito/bpmn/bpmn-flex-process-example-decision-table.png[Image of `SupportGroup` example DMN decision table]

The `Work case` ad hoc subprocess is also automatically started when the process is created. Anyone from the `customer` and `support` groups can add comments. To create a task that can be used to add a comment, a user can send an empty `POST` request as shown in the following example:

.Example curl request
[source]
----
curl -D -X POST -H 'Content-Type:application/json' -H 'Accept:application/json' http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment
----

.Example response (JSON)
[source,json]
----
HTTP/1.1 201 Created
Content-Length: 305
Location: http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment/f3b36cf9-3953-43ae-afe6-2a48fea8a79a
Content-Type: application/json

{
  "id":"b3c75b24-2691-4a76-902c-c9bc29ea076c",
  "supportCase":{
    "product": {
      "name":"Kogito",
      "family":"Middleware"
    },
    "description":"Kogito is not working for some reason.",
    "engineer":"kelly",
    "customer":"Paco the customer",
    "state":"WAITING_FOR_OWNER",
    "comments":null,
    "questionnaire":null
  },
  "supportGroup":"Kogito"
}
----

A user can then use the URL in the `Location` HTTP header when rendering the `form action`, as shown in the following example:

.Example form action for a user comment
[source]
----
<form action="http://localhost:8080/serviceDesk/b3c75b24-2691-4a76-902c-c9bc29ea076c/ReceiveSupportComment/f3b36cf9-3953-43ae-afe6-2a48fea8a79a" method="post">
  <label for="comment">Comment:</label>
  <input type="text" id="comment" name="comment">
</form>
----

After the customer is satisfied with the ticket response and actions, a user clicks a *Resolve Case* button, which sends an empty `POST` request to the service task to set the case to `Resolved` and the process emits a `CaseResolved` event. This event signals the `CaseResolved` milestone, which starts the `Close` ad hoc subprocess that sends, receives, and saves the customer questionnaire and closes the case.

// tag::con-bpmn-process-management-addon[]
[id="con-bpmn-process-management-addon_{context}"]
== {PRODUCT} process management add-on

[role="_abstract"]
{PRODUCT} provides a `process-management-addon` add-on that enables basic REST operations that you can use to manage process instances. These REST operations are supplemental to any other specific REST operations that you have configured in your application.

To configure process management REST capabilities for your {PRODUCT} services, you can add the process management add-on as a dependency in the `pom.xml` file of your {PRODUCT} project:

.Project dependency to enable process management REST operations
[source,xml]
----
<dependency>
  <groupId>org.kie.kogito</groupId>
  <artifactId>process-management-addon</artifactId>
</dependency>
----

The {PRODUCT} process management add-on provides REST support for the following basic operations:

* *Process instances*: Abort an active process instance
* *Node instances*:  Cancel or re-trigger a node instance, or trigger a new node instance
* *Error handling*: Retrieve error details for a process instance, or skip or re-trigger a failed node instance

In addition to exposed REST operations, the process management add-on also provides the following REST exception mappers to generate more meaningful error messages for typical exception types:

* `ProcessInstanceNotFound`
* `NodeInstanceNotFound`
* `NodeNotFound`
* `ProcessInstanceExecutionError`
* `NotAuthorized`
* `InvalidTransition` (for work items)
* `InvalidLifeCyclePhase` (for work items)

These exception mappers produce a valid HTTP error code with JSON payload with the context that caused the exception.

For example, the following is a `ProcessInstanceNotFoundException` error generated at runtime:

.Example error with JSON payload at runtime
[source,json]
----
HTTP code : 404

{
  "processInstanceId" : "c6862071-0f2e-4f21-9bc8-586245a76c3aa",
  "message" : "Process instance with id c6862071-0f2e-4f21-9bc8-586245a76c3aa not found"
}
----

=== REST endpoints for the process management add-on

After you add the `process-management-addon` dependency to your {PRODUCT} project and run your {PRODUCT} services, you can use the following REST endpoints to manage your process and node instances. These REST operations are supplemental to any other specific REST operations that you have configured in your application.

For each endpoint, use a REST client, curl utility, or Swagger UI (if configured for the application) to send requests with the following components:

* *Base URL*: `http://__HOST__:__PORT__/management/processes/{processId}/instances/{processInstanceId}`
* *Path parameters*:
** `{processId}`: The string identifier of the process definition, such as `orders`
** `{processInstanceId}`: The integer identifier of the process instance, such as `ec44f890-d21d-444f-a4ec-cb88589bd79`
** `{nodeId}`: The string identifier of the node, such as `verifyOrders`
** `{nodeInstanceId}`: The integer identifier of the node instance, such as `6e46bec2-0273-46f6-ad7d-2ff156e55a6c`
* *HTTP headers*: For `POST` requests only:
** `accept`: `application/json`
** `content-type`: `application/json`
* *HTTP methods*: `GET`, `POST`, or `DELETE`

==== Process instances

Use the following REST endpoints from the process management add-on to interact with process instances:

Return active node instances for a process instance::
+
--
`[GET] /management/processes/{processId}/instances/{processInstanceId}/nodeInstances`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances`

.Example curl request
[source]
----
curl -X GET localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
{
  "id": "ec44f890-d21d-444f-a4ec-cb88589bd79a",
  "name": "Verify order",
  "nodeInstanceId": "6e46bec2-0273-46f6-ad7d-2ff156e55a6c",
  "parameters": {
    "Locale": "en-UK",
    "TaskName": "Verify order",
    "NodeName": "Verify order",
    "Priority": "1",
    "input1": {
      "orderNumber": "12345",
      "shipped": false,
      "total": 0.8233575052440095
    },
    "Skippable": "true",
    "ActorId": "john"
  },
  "phase": "active",
  "phaseStatus": "Ready",
  "results": {},
  "state": 0
}
----
--

Abort a process instance::
+
--
`[DELETE] /management/processes/{processId}/instances/{processInstanceId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a`

.Example curl request
[source]
----
curl -X DELETE localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Nodes

Use the following REST endpoint from the process management add-on to interact with process nodes:

Return nodes from a process::
+
--
`[GET] /management/processes/{processId}/nodes`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/nodes`

.Example curl request
[source]
----
curl -X GET localhost:8080/management/processes/orders/nodes -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
[
  {
    "name": "End",
    "id": 1,
    "type": "EndNode",
    "uniqueId": "1"
  },
  {
    "name": "End",
    "id": 2,
    "type": "EndNode",
    "uniqueId": "2"
  },
  {
    "name": "Hello2",
    "id": 3,
    "type": "HumanTaskNode",
    "uniqueId": "3"
  },
  {
    "name": "Split",
    "id": 4,
    "type": "Split",
    "uniqueId": "4"
  },
  {
    "name": "End",
    "id": 5,
    "type": "EndNode",
    "uniqueId": "5"
  },
  {
    "name": "End",
    "id": 6,
    "type": "EndNode",
    "uniqueId": "6"
  },
  {
    "name": "Hello1",
    "id": 7,
    "type": "HumanTaskNode",
    "uniqueId": "7"
  },
  {
    "name": "Start",
    "id": 8,
    "type": "StartNode",
    "uniqueId": "8"
  },
  {
    "name": "BoundaryEvent",
    "id": 9,
    "type": "BoundaryEventNode",
    "uniqueId": "9"
  },
  {
    "name": "BoundaryEvent",
    "id": 10,
    "type": "BoundaryEventNode",
    "uniqueId": "10"
  }
]
----
--

==== Node instances

Use the following REST endpoints from the process management add-on to interact with node instances:

Cancel a node instance within a process instance::
+
--
`[DELETE] /management/processes/{processId}/instances/{processInstanceId}/nodeInstances/{nodeInstanceId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c`

.Example curl request
[source]
----
curl -X DELETE localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c -H 'content-type: application/json' -H 'accept: application/json'
----
--

Re-trigger a node instance within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/nodeInstances/{nodeInstanceId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodeInstances/6e46bec2-0273-46f6-ad7d-2ff156e55a6c -H 'content-type: application/json' -H 'accept: application/json'
----
--

Trigger a new instance of a node within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/nodes/{nodeId}`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodes/verifyOrder`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/nodes/verifyOrder -H 'content-type: application/json' -H 'accept: application/json'
----
--

==== Error handling

Use the following REST endpoints from the process management add-on to troubleshoot errors with process and node instances:

NOTE: These endpoints function only when a process instance is in an `ERROR` state.

Return error details for a process instance::
+
--
`[GET] /management/processes/{processId}/instances/{processInstanceId}/error`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/error`

.Example curl request
[source]
----
curl -X GET localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/error -H 'content-type: application/json' -H 'accept: application/json'
----

.Example response (JSON)
[source,json]
----
{
  "processInstanceId" : "ec44f890-d21d-444f-a4ec-cb88589bd79a",
  "message" : "Process instance with id c6862071-0f2e-4f21-9bc8-586245a76c3aa contains no input assignment"
}
----
--

Re-trigger any failed nodes within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/retrigger`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/retrigger`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/retrigger -H 'content-type: application/json' -H 'accept: application/json'
----
--

Skip any failed nodes within a process instance::
+
--
`[POST] /management/processes/{processId}/instances/{processInstanceId}/skip`

.Example REST endpoint
`\http://localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/skip`

.Example curl request
[source]
----
curl -X POST localhost:8080/management/processes/orders/instances/ec44f890-d21d-444f-a4ec-cb88589bd79a/skip -H 'content-type: application/json' -H 'accept: application/json'
----
--
// end::con-bpmn-process-management-addon[]

[id="con-management-console_{context}"]
== {PRODUCT} Management Console

[role="_abstract"]
The {PRODUCT} Management Console is a user interface for viewing the state of all available {PRODUCT} services and managing process instances:

.{PRODUCT} Management Console
image::kogito/bpmn/kogito-management-console.png[Image of Kogito Management Console]

You can use the Management Console to view process, subprocess, and node instance details, abort process instances, and view domain-specific process data.

The Management Console requires your {PRODUCT} services to use the following {PRODUCT} components:

* *{PRODUCT} Data Index Service*: Enables the Management Console to access stored events related to processes and domain data from your {PRODUCT} services. The {PRODUCT} Data Index Service requires Infinispan persistence and Apache Kafka messaging for your {PRODUCT} service. For more information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].
* *{PRODUCT} process management add-on*: Enables the Management Console to interact with the process data from your {PRODUCT} services through the add-on REST endpoint `/management/processes`. If you do not enable this add-on for your {PRODUCT} service, the Management Console provides read-only access to your service data without the ability to modify instances, such as aborting process instances. For more information about the process management add-on, see xref:con-bpmn-process-management-addon_kogito-developing-process-services[].

[id="proc-management-console-using_{context}"]
=== Using the {PRODUCT} Management Console to manage process instances

[role="_abstract"]
You can use the {PRODUCT} Management Console to view and manage process instance details from your {PRODUCT} services. You can run the Management Console for local {PRODUCT} services or add it to your {PRODUCT} infrastructure on {OPENSHIFT}.

.Prerequisites
* A {PRODUCT} Data Index Service instance is configured and running for your {PRODUCT} service. The Data Index Service enables the Management Console to access stored process data. The Data Index Service requires Infinispan persistence and Apache Kafka messaging for your {PRODUCT} service. For information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].
* The `pom.xml` file of your {PRODUCT} project contains the following dependency for the process management add-on. This add-on enables the Management Console to interact with the process data through the add-on REST endpoint `/management/processes`. For more information about the process management add-on, see xref:con-bpmn-process-management-addon_kogito-developing-process-services[].
+
.Project dependency to enable process management REST operations
[source,xml]
----
<dependency>
  <groupId>org.kie.kogito</groupId>
  <artifactId>process-management-addon</artifactId>
</dependency>
----
* The `application.properties` file of your {PRODUCT} project contains the following system properties for the location where the {PRODUCT} service is deployed, such as `\http://localhost:8080`, and for Quarkus Cross-Origin Resource Sharing (CORS) support. These properties enable the Management Console to generate the URLs to execute the REST operations from the process management add-on.
+
.Application properties for REST URLs
[source,subs="+quotes"]
----
kogito.service.url=http://__HOST__:__PORT__
quarkus.http.cors=true
----

.Procedure
. Go to the https://repository.jboss.org/org/kie/kogito/management-console/[`management-console`] artifacts page, select the latest release of the {PRODUCT} Management Console, and download the `management-console-__VERSION__-runner.jar` file to a local directory.
. In a command terminal, navigate to the directory location of the downloaded `management-console-__VERSION__-runner.jar` file and enter the following command to run the Management Console:
+
--
.Running the Management Console
[source,subs="+quotes"]
----
$ java -Dquarkus.http.port=8280 -jar management-console-__VERSION__-runner.jar
----

[NOTE]
====
The default port for the Management Console is 8080, but this example specifies port 8280 to avoid conflicts with the example {PRODUCT} service running at port 8080.

Also, the Management Console uses the default Data Index Service port 8180. If you modified this port in your Data Index Service instance, you must also modify the port in the Management Console properties by using the start-up property `-Dkogito.dataindex.http.url=http://__HOST__:__PORT__` when you run the Management Console.
====

To change the logging level of the Management Console, such as for debugging, you can specify the following start-up properties:

.Modifying Management Console logging level for debugging
[source,subs="+quotes"]
----
$ java  \
  -Dquarkus.log.console.level=DEBUG -Dquarkus.log.category.\"org.kie.kogito\".min-level=DEBUG  \
  -Dquarkus.log.category.\"org.kie.kogito\".level=DEBUG  \
  -Dquarkus.http.port=8280  \
  -jar management-console-__VERSION__-runner.jar
----

In an OpenShift environment, you can use the {PRODUCT} command-line interface (CLI) or the OpenShift web console to add the Management Console to your {PRODUCT} infrastructure:

.Adding the Management Console to your OpenShift infrastructure using the {PRODUCT} CLI
[source,subs="+quotes"]
----
$ kogito install mgmt-console -p __PROJECT_NAME__
----

.{PRODUCT} Management Console instance on OpenShift web console
image::kogito/openshift/kogito-management-console-instance.png[Image of Kogito Management Console instance on OpenShift]
--
. In a web browser, navigate to `http://localhost:8280` to open the Management Console. If you modified the configured Management Console port, use the modified location.
+
--
On OpenShift, navigate to the route URL for the Management Console instance.
--

[id="proc-management-console-structure_{context}"]
=== {PRODUCT} Management Console application

{PRODUCT} Management console has the following sections from the left menu to interact with your process instances and data:

* *Process Instances*: Use this page to view and localize process and subprocess instances by status or business key.
* *Domain Explorer*: Use this page to explore the data that is generated from your process instances in the available {PRODUCT} services, or _domains_.
* *Jobs*: Use this page to view a list of available jobs, to filter jobs by status, and perform actions for individual jobs, such as view details, reschedule, or cancel.

.{PRODUCT} Management Console
image::kogito/bpmn/kogito-management-console.png[Image of Kogito Management Console]

In this example, the Management Console displays data for the `kogito-travel-agency` extended example application in the https://github.com/kiegroup/kogito-examples[`kogito-examples`] repository in GitHub.

Finally, the view that encapsulates the process instance details and the allowed interaccions with a process instance
: the *Process Instance Details* view.
This view is accessed form diferent {PRODUCT} Management console seccions and shows the instance related data and allows
to perform the available actions, depending in each moment of its lifecycle state.

.Process instance details view
image::kogito/bpmn/kogito-management-console-process-details.png[Image of Process Instance details in Management Console]

--
Exploring the different {PRODUCT} Management Console views, will be able to see what kind of information and what actions are
exposed, to interact with your process instances and data.
--

====  Process Instance Details
This view allows to see all the process instance related data and available actions, organized in this different panels:

* Details panel
* Process Variables panel
* Timeline panel
* Node Trigger panel
* Milestones panel
* Jobs panel

===== Details panel
This panel shows the basic Process Instance information and provides links to its Process runtime UI and, in case it has
relationship with other Process instances, links to parent and subprocess instances.

.Process instance details panel
image::kogito/bpmn/kogito-management-console-details-panel.png[Image of process instance details panel]

Here we can find this fiels:

* _Name_. The id of the process definition that is related to this process instance
* _Business key_: Optional Business key associated with the process instance
* _State_: The State of the process instance. Depending on the process lifecycle this state would be: Pending, Active,
Completed, Aborted, Suspended or Error.
* _Id_: The unique identifier of the process instance
* _Endpoint_: As a shortcut to view the process or application UI that triggered a process instance, you can select the *Endpoint* for the specified process instance.

.Process instance details endpoint
image::kogito/bpmn/kogito-management-console-process-details-endpoint.png[Image of process instance details endpoint in Management Console]

* _Start_: Time reference indicating when the instance was started
* _Last Updated_: Time reference indicating when the instance was updated last time
* _End_: Time reference indicating when the instance was completed.
* _Parent Process_: In case the instance has a parent process instance this field allows to navigate to that.
* _Sub Processes_: In case the instance has a sub process instances this field allows to navigate to them.


===== Process Variables panel
The *Process Variables* panel shows the process instance domain data in a tree structure

.Process Variables panel
image::kogito/bpmn/kogito-management-console-process-variable-panel.png[Image of process variables panel  in Management Console]

When mouse pass over the different elements the available actions are displayed:

.Available actions in Process Variables panel
image::kogito/bpmn/kogito-management-console-process-variable-actions.png[Image of process variables panel available actions in Management Console]

Available actions on process variables items:
* _Expand / colapse_: In order to improve visualization this panel allows colapse or expand the groups of items.
* _Add new item_: When this action is selected, an edit popup allows to introduce the new key. Once the new key is instroduced the new item with 'NULL' value is added, ready to be edited with the expected value

.Add new process variable at Process Variables panel
image::kogito/bpmn/kogito-management-console-process-variable-add.png[Steps to add a new variable to a process instance in Management Console]

* _Copy Item_: This action copies the actual value to chipboard
* _Edit Item_: Allows modify the current item value. Once you provide the new value and click the check mark icon or press Enter to apply the change, the new value will be set for the edited variable.
* _Remove Item_: Removes the selected item

The process variable changes won't be permanent until *'Save'* button is presset. Click Save in the upper-right corner to save the changes or click the refresh icon to revert the changes.
When there are any pending change to be saved, the panel will show "Changes are not saved yet".

.Panel showing pending changes and the Save / refresh buttons to persist or revert the changes
image::kogito/bpmn/kogito-management-console-process-variable-save.png[Panel showing pending changes and the Save / refresh buttons to persist or discard changes]


===== Timeline panel

Displays the list of related node instances sorted by their start time. An icon will display the state of each node that could be: *Active*, *Completed* or *Error*.

.Timeline panel showing the related node instances
image::kogito/bpmn/kogito-management-console-process-timeline-panel.png[Image of Timeline panel showing the related node instances]

The available actions on *Active* nodes: _Retrigger Node_ and  _Cancel Node_

.Active Node instance available actions
image::kogito/bpmn/kogito-management-console-process-timeline-active.png[Image of Active Node instance available actions]

The availabble actions on *Error* nodes: _Retry_  and _Skip_

NOTE: The error message is showed as a tooltip over the error icon.

.Error Node instance available actions
image::kogito/bpmn/kogito-management-console-process-timeline-error.png[Image of Active Node instances available actions]

All this actions are connected with the associated *{PRODUCT} Runtime Service* to perform the requested action.

If a node in the timeline is related to a job, you can select the clock icon to view the job details or select the kebab menu for additional job operations,
 depending on the job status.

- _Job Details_. Is always available, even the node have been completed. It will show all job related information

And for nodes with status *Error* or *Active*, extra actions are allowed and will be performed making the request to *{PRODUCT} Job Service*:

- _Job Reschedule_. Allows to change the Expiration Time and, depending of the job periodicity defincion, the Repeat interval or the Repeat limit.
- _Job Cancel_.

.Node instance with timer job associated available actions
image::kogito/bpmn/kogito-management-console-process-timeline-jobs.png[Image of Node instance with timer job associated available actions]

===== Node Trigger panel
--
The *Node Trigger* panel displays a list of all process definition nodes in a dropdown.
When one node is selected, the related information is displayed: Node name, Node Type and Node identifier.
The selected node can be triggered clicking on *Trigger* button.

.Trigger a selected node
image::kogito/bpmn/kogito-management-console-node-trigger-panel.png[Image of node trigger panel in Management Console]
--
===== Milestones panel
--
The *Milestones* panel displays a list of available milestones for the process instance, if applicable.

.Process instance milestones
image::kogito/bpmn/kogito-management-console-milestones-panel.png[Image of milestones panel in Management Console]
--

===== Jobs panel
--
The *Jobs* panel displays a list of available jobs related to the process instance and enables you to view details for each job.

.Jobs panel
image::kogito/bpmn/kogito-management-console-jobs-panel.png[Image of jobs panel in Management Console]

.Job details
image::kogito/bpmn/kogito-management-console-jobs-panel-details.png[Image of jobs panel details in Management Console]

For jobs in *Scheduled* or *Error* state, you can also select the *Reschedule* option to reschedule the job, or *Cancel* to cancel the job.
You can modify the expiration time for one-time jobs, or the expiration time, repeat interval, and repeat limit for periodic jobs.

.Reschedule a job in Scheduled or Error state
image::kogito/bpmn/kogito-management-console-jobs-panel-reschedule.png[Image of jobs reschedule option in Management Console]

.Define job reschedule details
image::kogito/bpmn/kogito-management-console-jobs-reschedule.png[Image of jobs reschedule details in Management Console]
--

==== Process Instances

This section displays the list of process instances and allows to add filters and execute actions on them

.Process instance list section
image::kogito/bpmn/kogito-management-console-process-instance-section.png[Image of process instance list section]

This section allows to:

. Filter Process instances and subprocess list by status and by business key.
. For each process instance:

- Perform available actions on each process instance depending on its status like: *Abort*, *Skip* and *Retry*,
- Navigate to its *Process Instance Details*
- Navigate to it's *{PRODUCT} Runtime service* enpoint.
- In case the status is 'error', see the error message associated and be able to *Skip* and *Abord*
- Expand the process instance showing the subprocess instances

.Process instance expanded expanded show its subprocesses
image::kogito/bpmn/kogito-management-console-process-instance-list-expanded.png[Image of process instance expanded]

- Load elements incrementally (load more). Initially only shows 10 items and allow load more items and configure how much more items to load.

.Load items incrementally
image::kogito/bpmn/kogito-management-console-loadmore.png[Image of load items incrementally]

- Select the check box for multiple instances and use the bulk operation and perform one of the available bulk actions on them at the same time:  *Abort selected*, *Skip selected* and *Retry selected*.

.Multiple process instances selection
image::kogito/bpmn/kogito-management-console-bulk-process-management.png[Image of multiple process instances selection]

.Bulk action operation results
image::kogito/bpmn/kogito-management-console-bulk-process-management-modal.png[Image of bulk action operation results]

For process instances in an error state, you can select the *Error* icon to view error details and skip or retry the process instance. You can also select the process instance name to view the exact node instance in the process *Timeline* where the error occurred and skip or retry the specific node instance.

.Skip or retry a process instance with an error
image::kogito/bpmn/kogito-management-console-process-error.png[Image of process with error in Management Console]

==== Domain Explorer
Use this page to view data that is generated from your process instances in the available {PRODUCT} services, or _domains_, such as the `Travels` and `VisaApplications` domains in this example.

This section allows to explore process instances related to domain data. Provides the ability to localize domain data and to display its related process instances.
This area, has an entry point, ask for the specific domain selection, showing the *Domains List*.

.Domain explorer with available domains
image::kogito/bpmn/kogito-management-console-domain-explorer.png[Image of domain explorer in Management Console]

Once the domain is selected it will be used to set the filters, columns,.. in order to allow to localize domain data and access
to the related process instances

.VisaApplications domain data
image::kogito/bpmn/kogito-management-console-domain-explorer-visa-domain-data.png[Image of filters for VisaApplications domain in Management Console]

===== Manage Domain data table columns
Clicking on *Manage columns*, the user the can also refine which columns for the listed domain data, are displayed based on available attributes, such as
the `approved`, `country`, or `nationality` attributes in this example.
--
.Attributes for refining VisaApplications domain data columns
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-attributes.png[Image of attributes for VisaApplications domain data in Management Console]

When the domain specific data is localized, their related process instances could be navigated expanding the row

.Domain data expanded, displays the related process instances
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-sorted-data.png[Image of Domain data expanded, displays the related process instances]

--
===== Domain data Filters
After the specific domain is selected, the domain explorer toolbar adds the domain specific columns to the filter generation toolbar, to be able to filter the displayed data.
The toolbar allows:

. Select the domain column we want to use for filtering
+
.Select filter field for VisaApplications domain
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-select-filter-field.png[Image of select filter field for VisaApplications domain in Management Console]

. Specify operator to generate filter restriccion
+
.Select filter operator for VisaApplications domain
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-select-filter-operator.png[Image of select filter operator for VisaApplications domain in Management Console]

. Add the value to complete the filter
+
.Sample value to filter VisaApplications domain data
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-enter-filter-text.png[Image of select filter text for VisaApplications domain in Management Console]

. Apply Filter. Generates the filter and adds it to the current applyied filters
+
.Filtered results
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-filter-results.png[Image of filter results for VisaApplications domain in Management Console]

===== Domain data table Sorting
Domain explorer allows to sort the results by any of the vidible columns clicking on the column header

.Sorted results
image::kogito/bpmn/kogito-management-console-domain-explorer-visas-sorting-results.png[Image of sorting results for VisaApplications domain in Management Console]

==== Jobs Management
--
This section shows the list of existing jobs, allow filter them and exposes some related management actions.

.Jobs Management page
image::kogito/bpmn/kogito-management-console-jobs-management.png[Image of Jobs Management page in Management Console]

The list of jobs can be filtered by the status, selecting them and clicking on 'Apply Filter'

.Jobs Management filters
image::kogito/bpmn/kogito-management-console-jobs-management-filter.png[Image of Jobs Management filter in Management Console]

On each job there will be exposed different actions depending on its status

.Job management actions
image::kogito/bpmn/kogito-management-console-jobs-actions.png[Image of Jobs related actions]

- *Details* is available for all status and diplay all the job related data.

.Job details actions
image::kogito/bpmn/kogito-management-console-jobs-details.png[Image of Jobs details]

- For jobs in *Scheduled* or *Error* state, you can also select the *Reschedule* option to reschedule
 or *Cancel* to cancel the job.

When *Reschedule* is selected, the expiration time for one-time jobs, or the expiration time, repeat interval, and repeat limit for periodic jobs can be modified.

.Job reschedule
image::kogito/bpmn/kogito-management-console-jobs-reschedule.png[Image of Jobs reschedule]


This view allows perform bulk cancelation on multiple jobs at the same time. Check the jobs to be canceled,
and click on *Cancel Selected*. The selected jobs will be cancel and the results report will be displayed

.Bulk Cancel operation result
image::kogito/bpmn/kogito-management-console-jobs-management-bulk-cancel.png[Image of Jobs Management bulk cancel operation result in Management Console]
--

[id="proc-management-console-security_{context}"]
=== Enabling {PRODUCT} Management Console security with OpenID Connect

[role="_abstract"]
For Quarkus-based {PRODUCT} services, you can use the https://quarkus.io/guides/security-openid-connect[Quarkus OpenID Connect adapter] with the {PRODUCT} Management Console to enable the console to interact with the {PRODUCT} Data Index Service using bearer token authorization. These tokens are issued by OpenID Connect and OAuth 2.0 compliant authorization servers such as https://www.keycloak.org/about.html[Keycloak].

IMPORTANT: This procedure applies only when you are using a locally cloned copy of the https://github.com/kiegroup/kogito-apps/tree/master/management-console[{PRODUCT} Management Console] repository in GitHub.

.Prerequisites
* You have cloned the https://github.com/kiegroup/kogito-apps/tree/master/management-console[{PRODUCT} Management Console] repository from GitHub.

.Procedure
. In a command terminal, navigate to the local clone of the {PRODUCT} Management Console repository and enter the following command to run the application with security enabled:
+
--
.Run the Management Console with security enabled
[source]
----
mvn clean compile quarkus:dev -Dquarkus.profile=keycloak
----

IMPORTANT: Ensure that the service is not started at the same port as the security server. You can change the port by adding `-Dquarkus.http.port=__PORT_NUMBER__` to the start-up properties.

The {PRODUCT} Management Console contains a Quarkus profile to encapsulate the security configuration, so if the service requires security, you can specify the `quarkus.profile=keycloak` property at build time to enable the needed security. If the `keycloak` Quarkus profile is not added, the OpenID Connect extension is disabled.
--
. Navigate to the `src/main/resources/application.properties` file of the Management Console project and add the following properties:
+
--
.Required security properties in `applications.properties` file
[source]
----
# OpenID Connect configurations
%keycloak.quarkus.oidc.enabled=true
%keycloak.quarkus.oidc.tenant-enabled=true
%keycloak.quarkus.oidc.auth-server-url=http://localhost:8280/auth/realms/kogito
%keycloak.quarkus.oidc.client-id=kogito-console-quarkus
%keycloak.quarkus.oidc.credentials.secret=secret
%keycloak.quarkus.oidc.application-type=web-app
%keycloak.quarkus.oidc.logout.path=/logout
%keycloak.quarkus.oidc.logout.post-logout-path=/

# HTTP security configurations
%keycloak.quarkus.http.auth.permission.authenticated.paths=/*
%keycloak.quarkus.http.auth.permission.authenticated.policy=authenticated
----

NOTE: The `quarkus.oidc.enabled` property enables or disables security at build time, while the `quarkus.oidc.tenant-enabled` property enables or disables security at runtime.

--
. Replace any property definitions with those of your specific environment, especially the following properties:
+
* `quarkus.oidc.auth-server-url`: The base URL of the OpenID Connect (OIDC) server, such as `https://localhost:8280/auth`. All other OIDC server page and service URLs are derived from this URL. If you work with Keycloak OIDC server, ensure that the base URL is in the following format: `https://__HOST__:__PORT__/auth/realms/__KEYCLOAK_REALM__`.
* `quarkus.oidc.client-id`: The client ID of the application. Each application has a client ID that is used to identify the application.
* `quarkus.oidc.credentials.secret`: The client secret for the application.
. In the same `application.properties` file, also configure the resources to be exposed and the required permissions for accessing the resources.
+
NOTE: If you are enabling security at runtime using the `quarkus.oidc.tenant-enabled` property, the `quarkus.http.auth.permission` path and policy must specify how authentication is applied. By default, if security is enabled, the user must be authenticated to access any path.

. Stop and restart the {PRODUCT} Management Console to ensure that the security changes are applied.

[role="_additional-resources"]
.Additional resources
* https://quarkus.io/guides/security[Security Architecture and Guides]
* https://quarkus.io/guides/security-openid-connect#configuring-using-the-application-properties-file[Configuring using the application.properties file]
* https://quarkus.io/guides/security-openid-connect-multitenancy[Using OpenID Connect multi-tenancy]

[id="con-task-console_{context}"]
== {PRODUCT} Task Console

[role="_abstract"]
The {PRODUCT} Task Console is a user interface for viewing and interacting with user tasks in {PRODUCT} process services.

.{PRODUCT} Task Console
image::kogito/bpmn/kogito-task-console.png[Image of Kogito Task Console]

You can use the Task Console to view your list of assigned tasks, view the task details for each task, and move the task to the next phase of the task lifecycle. For more information about the task lifecycle, see xref:con-task-lifecycle_kogito-developing-process-services[].

The Task Console requires your {PRODUCT} services to use the {PRODUCT} Data Index Service. The Data Index Service enables the Task Console to access stored events related to tasks and domain data from your {PRODUCT} services. The {PRODUCT} Data Index Service requires Infinispan persistence and Apache Kafka messaging for your {PRODUCT} service. For more information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].

[id="proc-task-console-using_{context}"]
=== Using the {PRODUCT} Task Console to interact with user tasks

[role="_abstract"]
You can use the {PRODUCT} Task Console to view and interact with user tasks in {PRODUCT} process services. You can run the Task Console for local {PRODUCT} services or add it to your {PRODUCT} infrastructure on {OPENSHIFT}.

.Prerequisites
* A {PRODUCT} Data Index Service instance is configured and running for your {PRODUCT} service. The Data Index Service enables the Task Console to access stored tasks and process data. The Data Index Service requires Infinispan persistence and Apache Kafka messaging for your {PRODUCT} service. For information about the Data Index Service, see {URL_CONFIGURING_KOGITO}#con-data-index-service_kogito-configuring[_{CONFIGURING_KOGITO}_].
* The `application.properties` file of your {PRODUCT} project contains the following system properties for the location where the {PRODUCT} service is deployed, such as `\http://localhost:8080`, and for Quarkus Cross-Origin Resource Sharing (CORS) support.
+
.Application properties for REST URLs
[source,subs="+quotes"]
----
kogito.service.url=http://__HOST__:__PORT__
quarkus.http.cors=true
----

.Procedure
. Go to the https://repository.jboss.org/org/kie/kogito/task-console/[`task-console`] artifacts page, select the latest release of the {PRODUCT} Task Console, and download the `task-console-__VERSION__-runner.jar` file to a local directory.
. In a command terminal, navigate to the directory location of the downloaded `task-console-__VERSION__-runner.jar` file and enter the following command to run the Task Console:
+
--
.Running the Task Console
[source,subs="+quotes"]
----
$ java -Dquarkus.http.port=8280 -jar task-console-__VERSION__-runner.jar
----

[NOTE]
====
The default port for the Task Console is 8080, but this example specifies port 8280 to avoid conflicts with the example {PRODUCT} service running at port 8080.

Also, the Task Console uses the default Data Index Service port 8180. If you modified this port in your Data Index Service instance, you must also modify the port in the Task Console properties by using the start-up property `-Dkogito.dataindex.http.url=http://__HOST__:__PORT__` when you run the Task Console.
====

To change the logging level of the Task Console, such as for debugging, you can specify the following start-up properties:

.Modifying Task Console logging level for debugging
[source,subs="+quotes"]
----
$ java  \
  -Dquarkus.log.console.level=DEBUG -Dquarkus.log.category.\"org.kie.kogito\".min-level=DEBUG  \
  -Dquarkus.log.category.\"org.kie.kogito\".level=DEBUG  \
  -Dquarkus.http.port=8280  \
  -jar task-console-__VERSION__-runner.jar
----

In an OpenShift environment, you can use the {PRODUCT} command-line interface (CLI) or the OpenShift web console to add the Task Console to your {PRODUCT} infrastructure:

.Adding the Task Console to your OpenShift infrastructure using the {PRODUCT} CLI
[source,subs="+quotes"]
----
$ kogito install task-console -p __PROJECT_NAME__
----

.{PRODUCT} Task Console instance on OpenShift web console
image::kogito/openshift/kogito-task-console-instance.png[Image of Kogito Task Console instance on OpenShift]
--
. In a web browser, navigate to `http://localhost:8280` to open the Task Console. If you modified the configured Task Console port, use the modified location.
+
--
On OpenShift, navigate to the route URL for the Task Console instance.

.{PRODUCT} Task Console
image::kogito/bpmn/kogito-task-console.png[Image of Kogito Task Console]

In this example, the Task Console displays data for the `kogito-travel-agency` extended example application in the https://github.com/kiegroup/kogito-examples[`kogito-examples`] repository in GitHub.

The *Task Inbox* page lists the available user tasks that you can interact with. You can use the upper toolbar options to filter the tasks or use the column headers to sort the tasks as needed. You can also search for tasks by the full name or by partial name, such as `Apply`.

.Tasks assigned to the current user
image::kogito/bpmn/kogito-task-console-inbox.png[Image of the tasks assigned to the current user]

.Available task status filters
image::kogito/bpmn/kogito-task-console-filters-status.png[Image of status filtering on *Task Inbox*]

.Applied filters
image::kogito/bpmn/kogito-task-console-filters.png[Image of status and names filtering on *Task Inbox*]
--
. Select a task name to view task details and interact with the task:
+
--
.Task details
image::kogito/bpmn/kogito-task-console-details-page.png[Image of *Task Details* page]

Depending on the current phase of the selected task, you can select from the available actions for that task, such as *Abort*, *Release*, *Skip*, or *Complete*, to move the task to the next phase.

For additional task details, you can select *View details*. This panel lists the task ID, state, owner, related process instance ID, and other helpful information about the task.

.Task details panel
image::kogito/bpmn/kogito-task-console-details-expanded.png[Image of task details panel]
--

[id="proc-task-console-security_{context}"]
=== Enabling {PRODUCT} Task Console security with OpenID Connect

[role="_abstract"]
For Quarkus-based {PRODUCT} services, you can use the https://quarkus.io/guides/security-openid-connect[Quarkus OpenID Connect adapter] with the {PRODUCT} Task Console to enable the console to interact with the {PRODUCT} Data Index Service using bearer token authorization. These tokens are issued by OpenID Connect and OAuth 2.0 compliant authorization servers such as https://www.keycloak.org/about.html[Keycloak].

IMPORTANT: This procedure applies only when you are using a locally cloned copy of the https://github.com/kiegroup/kogito-apps/tree/master/task-console[{PRODUCT} Task Console] repository in GitHub.

.Prerequisites
* You have cloned the https://github.com/kiegroup/kogito-apps/tree/master/task-console[{PRODUCT} Task Console] repository from GitHub.

.Procedure
. In a command terminal, navigate to the local clone of the {PRODUCT} Task Console repository and enter the following command to run the application with security enabled:
+
--
.Run the Task Console with security enabled
[source]
----
mvn clean compile quarkus:dev -Dquarkus.profile=keycloak
----

IMPORTANT: Ensure that the service is not started at the same port as the security server. You can change the port by adding `-Dquarkus.http.port=__PORT_NUMBER__` to the start-up properties.

The {PRODUCT} Task Console contains a Quarkus profile to encapsulate the security configuration, so if the service requires security, you can specify the `quarkus.profile=keycloak` property at build time to enable the needed security. If the `keycloak` Quarkus profile is not added, the OpenID Connect extension is disabled.
--
. Navigate to the `src/main/resources/application.properties` file of the Task Console project and add the following properties:
+
--
.Required security properties in `applications.properties` file
[source]
----
# OpenID Connect configurations
%keycloak.quarkus.oidc.enabled=true
%keycloak.quarkus.oidc.tenant-enabled=true
%keycloak.quarkus.oidc.auth-server-url=http://localhost:8280/auth/realms/kogito
%keycloak.quarkus.oidc.client-id=kogito-console-quarkus
%keycloak.quarkus.oidc.credentials.secret=secret
%keycloak.quarkus.oidc.application-type=web-app
%keycloak.quarkus.oidc.logout.path=/logout
%keycloak.quarkus.oidc.logout.post-logout-path=/

# HTTP security configurations
%keycloak.quarkus.http.auth.permission.authenticated.paths=/*
%keycloak.quarkus.http.auth.permission.authenticated.policy=authenticated
----

NOTE: The `quarkus.oidc.enabled` property enables or disables security at build time, while the `quarkus.oidc.tenant-enabled` property enables or disables security at runtime.

--
. Replace any property definitions with those of your specific environment, especially the following properties:
+
* `quarkus.oidc.auth-server-url`: The base URL of the OpenID Connect (OIDC) server, such as `https://localhost:8280/auth`. All other OIDC server page and service URLs are derived from this URL. If you work with Keycloak OIDC server, ensure that the base URL is in the following format: `https://__HOST__:__PORT__/auth/realms/__KEYCLOAK_REALM__`.
* `quarkus.oidc.client-id`: The client ID of the application. Each application has a client ID that is used to identify the application.
* `quarkus.oidc.credentials.secret`: The client secret for the application.
. In the same `application.properties` file, also configure the resources to be exposed and the required permissions for accessing the resources.
+
NOTE: If you are enabling security at runtime using the `quarkus.oidc.tenant-enabled` property, the `quarkus.http.auth.permission` path and policy must specify how authentication is applied. By default, if security is enabled, the user must be authenticated to access any path.

. Stop and restart the {PRODUCT} Task Console to ensure that the security changes are applied.

[role="_additional-resources"]
.Additional resources
* https://quarkus.io/guides/security[Security Architecture and Guides]
* https://quarkus.io/guides/security-openid-connect#configuring-using-the-application-properties-file[Configuring using the application.properties file]
* https://quarkus.io/guides/security-openid-connect-multitenancy[Using OpenID Connect multi-tenancy]

include::{asciidoc-dir}/dmn/chap-kogito-using-dmn-models.adoc[tags=con-kogito-service-execution]

ifdef::KOGITO-ENT[]
[role="_additional-resources"]
== Additional resources
* {URL_CREATING_RUNNING}[_{CREATING_RUNNING}_]
* {URL_DEPLOYING_ON_OPENSHIFT}[_{DEPLOYING_ON_OPENSHIFT}_]
* {URL_DECISION_SERVICES}[_{DECISION_SERVICES}_]
* {URL_CONFIGURING_KOGITO}[_{CONFIGURING_KOGITO}_]
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
