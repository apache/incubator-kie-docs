[[_drools.testscenarioeditor]]
= Test scenarios

Test scenarios in {PRODUCT} enable you to validate the functionality of business rules and business rule data before deploying them into a production environment. With a test scenario, you use data from your project to set given conditions and expected results based on one or more defined business rules. When you run the scenario, the expected results and actual results of the rule instance are compared. If the expected results match the actual results, the test is successful. If the expected results do not match the actual results, then the test fails.

Test scenarios can be executed one at a time or as a group. The group execution contains all the scenarios from one package. Test scenarios are independent, so one scenario cannot affect or modify the other. You can run test scenarios at any time during project development in {CENTRAL}. You do not have to compile or deploy your decision service to run test scenarios.

All data objects related to a test scenario must be in the same project package as the test scenario. Assets in the same package are imported by default. After you create the necessary data objects and the test scenario, you can use the *Data Objects* tab of the test scenarios designer to verify that all required data objects are listed or to import other existing data objects by adding a *New item*.

== Creating and running a test scenario

You can create test scenarios in {CENTRAL} to test the functionality of business rule data before deployment. A basic test scenario must have at least the following data:

* Related data objects
* *GIVEN* facts
* *EXPECT* results

With this data, the test scenario can validate the expected and actual results for that rule instance based on the defined facts. You can also add a *CALL METHOD* and any available *globals* to a test scenario, but these scenario settings are optional.

.Procedure
. In {CENTRAL}, go to *Menu* -> *Design* -> *Projects* and click the project name.
. Click *Add Asset* -> *Test Scenario*.
. Enter an informative *Test Scenario* name and select the appropriate *Package*. The package that you specify must be the same package where the required data objects and rule assets have been assigned or will be assigned.
+
. Click *Ok* to create the test scenario.
+
The new test scenario is now listed in the *Test Scenarios* panel of the *Project Explorer*,
+
. Click the *Data Objects* tab to verify that all data objects required for the rules that you want to test are listed. If not, click *New item* to import the needed data objects from other packages, or
ifdef::DM,PAM[]
xref:data-objects-create-proc_test-scenarios[create data objects]
endif::[]
ifdef::DROOLS,JBPM,OP[]
xref:_wb.datamodeller[create data objects]
endif::[]
within your package.
. After all data objects are in place, return to the *Model* tab of the test scenarios designer and define the *GIVEN* and *EXPECT* data for the scenario, based on the available data objects.
+
.The test scenarios designer
image::project-data/test-scenario-edit.png[]
+
The *GIVEN* section defines the input facts for the test. For example, if an `Underage` rule in the project declines loan applications for applicants under the age of 21, then the *GIVEN* facts in the test scenario could be `Applicant` with `age` set to some integer less than 21.
+
The *EXPECT* section defines the expected results based on the *GIVEN* input facts. That is, *GIVEN* the input facts, *EXPECT* these other facts to be valid or entire rules to be activated. For example, with the given facts of an applicant under the age of 21 in the scenario, the *EXPECT* results could be `LoanApplication` with `approved` set to `false` (as a result of the underage applicant), or could be the activation of the `Underage` rule as a whole.
+
. Optionally, add a *CALL METHOD* and any *globals* to the test scenario:
+
--
* *CALL METHOD:* Use this to invoke a method from another fact when the rule execution is initiated. Click *CALL METHOD*, select a fact, and click image:project-data/6187.png[] to select the method to invoke. You can invoke any Java class methods (such as methods from an ArrayList) from the Java library or from a JAR that was imported for the project (if applicable).
* *globals:* Use this to add any global variables in the project that you want to validate in the test scenario. Click *globals* to select the variable to be validated, and then in the test scenarios designer, click the global name and define field values to be applied to the global variable. If no global variables are available, then they must be created as new assets in {CENTRAL}. Global variables are named objects that are visible to the {ENGINE} but are different from the objects for facts. Changes in the object of a global do not trigger the re-evaluation of rules.
--
+
. Click *More* at the bottom of the test scenarios designer to add other data blocks to the same scenario file as needed.
. After you have defined all *GIVEN*, *EXPECT*, and other data for the scenario, click *Save* in the test scenarios designer to save your work.
. Click *Run scenario* in the upper-right corner to run this `.scenario` file, or click *Run all scenarios* to run all saved `.scenario` files in the project package (if there are multiple). Although the *Run scenario* option does not require the individual `.scenario` file to be saved, the *Run all scenarios* option does require all `.scenario` files to be saved.
+
If the test fails, address any problems described in the *Reporting* message at the bottom of the window, review all components in the scenario, and try again to validate the scenario until the scenario passes.
+
. Click *Save* in the test scenarios designer to save your work after all changes are complete.

=== Adding GIVEN facts in test scenarios

The *GIVEN* section defines input facts for the test. For example, if an `Underage` rule in the project declines loan applications for applicants under the age of 21, then the *GIVEN* facts in the test scenario could be `Applicant` with `age` set to some integer less than 21.

.Prerequisite
All data objects required for your test scenario have been created or imported and are listed in the *Data Objects* tab of the test scenarios designer.

.Procedure
. In the test scenarios designer, click *GIVEN* to open the *New input* window with the available facts.
+
.Add GIVEN input to the test scenario
image::project-data/test-scenario-facts.png[Add GIVEN input to the test scenario]
+
The list includes the following options, depending on the data objects available in the *Data Objects* tab of the test scenarios designer:

* *Insert a new fact:* Use this to add a fact and modify its field values. Enter a variable for the fact as the *Fact name*.
* *Modify an existing fact:* (Appears only after another fact has been added.) Use this to specify a previously inserted fact to be modified in the {ENGINE} between executions of the scenario.
* *Delete an existing fact:* (Appears only after another fact has been added.) Use this to specify a previously inserted fact to be deleted from the {ENGINE} between executions of the scenario.
* *Activate rule flow group:* Use this to specify a rule flow group to be activated so that all rules within that group can be tested.
+
. Choose a fact for the desired input option and click *Add*. For example, set *Insert a new fact:* to *Applicant* and enter `a` or `app` or any other variable for the *Fact name*.
. Click the fact in the test scenarios designer and select the field to be modified.
+
.Modify a fact field
image::project-data/test-scenario-field.png[Modifying a condition]
+
. Click the edit icon (image:project-data/6191.png[]) and select from the following field values:
+
--
* *Literal value:* Creates an open field in which you enter a specific literal value.
* *Bound variable:* Sets the value of the field to the fact bound to a selected variable. The field type must match the bound variable type.
* *Create new fact:* Enables you to create a new fact and assign it as a field value of the parent fact. Then you can click the child fact in the test scenarios designer and likewise assign field values or nest other facts similarly.
--
+
. Continue adding any other *GIVEN* input data for the scenario and click *Save* in the test scenarios designer to save your work.

=== Adding EXPECT results in test scenarios

The *EXPECT* section defines the expected results based on the *GIVEN* input facts. That is, *GIVEN* the input facts, *EXPECT* other specified facts to be valid or entire rules to be activated. For example, with the given facts of an applicant under the age of 21 in the scenario, the *EXPECT* results could be `LoanApplication` with `approved` set to `false` (as a result of the underage applicant), or could be the activation of the `Underage` rule as a whole.

.Prerequisite
All data objects required for your test scenario have been created or imported and are listed in the *Data Objects* tab of the test scenarios designer.

.Procedure
. In the test scenarios designer, click *EXPECT* to open the *New expectations* window with the available facts.
+
.Add EXPECT results to the test scenario
image::project-data/test-scenario-expected-rules.png[Add EXPECT results to the test scenario]
+
The list includes the following options, depending on the data in the *GIVEN* section and the data objects available in the *Data Objects* tab of the test scenarios designer:

* *Rule:* Use this to specify a particular rule in the project that is expected to be activated as a result of the *GIVEN* input. Type the name of a rule that is expected to be activated or select it from the list of rules, and then in the test scenarios designer, specify the number of times the rule should be activated.
* *Fact value:* Use this to select a fact and define values for it that are expected to be valid as a result of the facts defined in the *GIVEN* section. The facts are listed by the *Fact name* previously defined for the *GIVEN* input.
* *Any fact that matches:* Use this to validate that at least one fact with the specified values exists as a result of the *GIVEN* input.
+
. Choose a fact for the desired expectation (such as *Fact value:* `application`) and click *Add* or *OK*.
. Click the fact in the test scenarios designer and select the field to be added and modified.
+
.Modify a fact field
image::project-data/test-scenario-field-value.png[Modify a fact field]
+
. Set the field values to what is expected to be valid as a result of the *GIVEN* input (such as `approved` | `equals` | `false`).
. Continue adding any other *EXPECT* input data for the scenario and click *Save* in the test scenarios designer to save your work.
. After you have defined and saved all *GIVEN*, *EXPECT*, and other data for the scenario, click *Run scenario* in the upper-right corner to run this `.scenario` file, or click *Run all scenarios* to run all saved `.scenario` files in the project package (if there are multiple). Although the *Run scenario* option does not require the individual `.scenario` file to be saved, the *Run all scenarios* option does require all `.scenario` files to be saved.
+
If the test fails, address any problems described in the *Reporting* message at the bottom of the window, review all components in the scenario, and try again to validate the scenario until the scenario passes.
+
. Click *Save* in the test scenarios designer to save your work after all changes are complete.
