[id='performance-tuning-decision-engine-ref_{context}']

= Performance tuning considerations with the {DECISION_ENGINE}

The following key concepts or suggested practices can help you optimize {DECISION_ENGINE} performance. These concepts are summarized in this section as a convenience and are explained in more detail in the cross-referenced documentation, where applicable. This section will expand or change as needed with new releases of {PRODUCT}.

Use sequential mode for stateless KIE sessions that do not require important {DECISION_ENGINE} updates::
Sequential mode is an advanced rule base configuration in the {DECISION_ENGINE} that enables the {DECISION_ENGINE} to evaluate rules one time in the order that they are listed in the {DECISION_ENGINE} agenda without regard to changes in the working memory. As a result, rule execution may be faster in sequential mode, but important updates may not be applied to your rules. Sequential mode applies to stateless KIE sessions only.
+
--
To enable sequential mode, set the system property `drools.sequential` to `true`.

For more information about sequential mode or other options for enabling it, see xref:phreak-sequential-mode-con_decision-engine[].
--

Use simple operations with event listeners::
Limit the number of event listeners and the type of operations they perform. Use event listeners for simple operations, such as debug logging and setting properties. Complicated operations, such as network calls, in listeners can impede rule execution. After you finish working with a KIE session, remove the attached event listeners so that the session can be cleaned, as shown in the following example:
+
--
.Example event listener removed after use
[source,java]
----
Listener listener = ...;
StatelessKnowledgeSession ksession = createSession();
try {
    ksession.insert(fact);
    ksession.fireAllRules();
    ...
} finally {
    if (session != null) {
        ksession.detachListener(listener);
        ksession.dispose();
    }
}
----

For information about built-in event listeners and debug logging in the {DECISION_ENGINE}, see xref:engine-event-listeners-con_decision-engine[].
--


Configure `LambdaIntrospector` cache size for an executable model build::
You can configure the size of `LambdaIntrospector.methodFingerprintsMap` cache, which is used in an executable model build. The default size of the cache is `32`. When you configure smaller value for the cache size, it reduces memory usage. For example, you can configure system property `drools.lambda.introspector.cache.size` to `0` for minimum memory usage. Note that smaller cache size also slows down the build performance. 


Use lambda externalization for executable model::
Enable lambda externalization to optimize the memory consumption during runtime. It rewrites lambdas that are generated and used in the executable model. This enables you to reuse the same lambda multiple times with all the patterns and the same constraint. When the rete or phreak is instantiated, the executable model becomes garbage collectible. 
+
--
To enable lambda externalization for the executable model, include the following property:

[source]
----
-Ddrools.externaliseCanonicalModelLambda=true
----
--


Configure alpha node range index threshold::
You can configure the threshold of alpha node range index, which is used in rule constraint evaluation. The default value of the threshold is `9` which means alpha node range index is enabled when a precedent node has more than 9 alpha nodes with inequality constraints (e.g. you have more than 9 rules like `Person(age > 10)`, `Person(age > 20)` ...). The default value was decided considering its benefit and overhead. But configuring smaller value for the threshold may have a chance to get better performance depending on your rules. For example, you can configure system property `drools.alphaNodeRangeIndexThreshold` to `6` in order to enable alpha node range index even if you have only 6 alpha nodes with inequality constraints for a precedent node. You can decide the best value based on your benchmark.
